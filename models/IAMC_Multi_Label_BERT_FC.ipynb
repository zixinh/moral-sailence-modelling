{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Multi-Label-BERT_FC-IAMC-Individual.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "PbrIqkb7q0ny"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PbrIqkb7q0ny",
        "colab_type": "text"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jU7fYjAllVwQ",
        "colab_type": "code",
        "outputId": "15b1b3da-f932-4d9a-9ca2-4cde7b455267",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "# install transformers package from Hugging Face transformers package contains \n",
        "# pre-trained BERT model and other useful interfaces\n",
        "!pip install transformers "
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (2.8.0)\n",
            "Requirement already satisfied: tokenizers==0.5.2 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.85)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.38.0)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.12.34)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.38)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n",
            "Requirement already satisfied: botocore<1.16.0,>=1.15.34 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.15.34)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.1)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.34->boto3->transformers) (2.8.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.34->boto3->transformers) (0.15.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8_mQkgPgasW",
        "colab_type": "code",
        "outputId": "fdee444a-0717-47fa-92f1-3ceddf10af3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Check if Colab's GPU is available and set up the GPU device\n",
        "import tensorflow as tf\n",
        "import torch\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('GPU is available')\n",
        "else:\n",
        "    raise SystemError('No GPU device available')\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print('GPU name and type:', torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    print('No GPU available, using CPU')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU is available\n",
            "GPU name and type: Tesla P4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m6X5lLSVrEkj",
        "colab_type": "text"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQiDv4rylYkw",
        "colab_type": "code",
        "outputId": "223b54cd-dd33-4e01-f6eb-af5ac9f62db7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "# dataset pre-processing\n",
        "# load data_extraction.ipynb\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "iamc_ds = pd.read_json('iamc.json')\n",
        "\n",
        "tweets = {}\n",
        "labels = {}\n",
        "count = 1\n",
        "\n",
        "for annotator in iamc_ds:\n",
        "    tweets['annotator' + str(count)] = np.array(list(iamc_ds[annotator][0]))\n",
        "    labels['annotator' + str(count)] = np.array(list(iamc_ds[annotator][1]))\n",
        "    count += 1 \n",
        "\n",
        "print('example 1')\n",
        "print('tweet: ', tweets['annotator1'][0])\n",
        "print('label: ', labels['annotator1'][0])\n",
        "\n",
        "print('')\n",
        "print('example 2')\n",
        "print('tweet: ', tweets['annotator3'][1])\n",
        "print('label: ', labels['annotator3'][1])\n"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "example 1\n",
            "tweet:  Wholeheartedly support these protests ; acts of civil disobedience ; will join when I can! #Ferguson #AllLivesMatter \n",
            "label:  [0 0 1 0 0 0 0 0 0 0 0]\n",
            "\n",
            "example 2\n",
            "tweet:  This Sandra Bland situation man no disrespect rest her soul , but people die everyday in a unjustified matter #AllLivesMatter\n",
            "label:  [0 0 0 0 0 1 0 0 0 0 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6qFUYwuZrd4e",
        "colab_type": "text"
      },
      "source": [
        "# Training Prep"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "omQcPA7UrNVm",
        "colab_type": "text"
      },
      "source": [
        "### Input Tokenization & Encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfQNYUK2sGRO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "8ed9b0e7-eca9-4308-e2d2-88766cbfcfd2"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "\n",
        "# visualize BERT tokenization by an example\n",
        "print('Before:', tweets['annotator1'][0])\n",
        "print('After(words):', tokenizer.tokenize(tweets['annotator1'][0]))\n",
        "print('After(ids):', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(tweets['annotator1'][0])))"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading BERT tokenizer...\n",
            "Before: Wholeheartedly support these protests ; acts of civil disobedience ; will join when I can! #Ferguson #AllLivesMatter \n",
            "After(words): ['whole', '##hearted', '##ly', 'support', 'these', 'protests', ';', 'acts', 'of', 'civil', 'di', '##so', '##bed', '##ience', ';', 'will', 'join', 'when', 'i', 'can', '!', '#', 'ferguson', '#', 'all', '##li', '##ves', '##mat', '##ter']\n",
            "After(ids): [2878, 27693, 2135, 2490, 2122, 8090, 1025, 4490, 1997, 2942, 4487, 6499, 8270, 13684, 1025, 2097, 3693, 2043, 1045, 2064, 999, 1001, 11262, 1001, 2035, 3669, 6961, 18900, 3334]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77-MUinHvdk9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "70cd362d-d131-41f6-92cc-b245328db4d9"
      },
      "source": [
        "from torch.utils.data import TensorDataset, random_split, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "train_data_loaders = {}\n",
        "val_data_loaders = {}\n",
        "test_data_loaders = {}\n",
        "\n",
        "for annotator in tweets:\n",
        "    # input tokenization\n",
        "    tweets_one_anno = tweets[annotator]\n",
        "\n",
        "    # Get the maximum length of the dataset since all input instances have to have a constant length\n",
        "    max_len = 0\n",
        "\n",
        "    for tweet in tweets_one_anno:\n",
        "        max_len = max(max_len, len(tweet.split()))\n",
        "\n",
        "    max_len += 2\n",
        "    print(annotator)\n",
        "    print('Max tweet length:', max_len)\n",
        "\n",
        "    # tokenize all tweets, acquire corresponding token ids and attention masks\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "\n",
        "    # encode input\n",
        "    for tweet in tweets_one_anno:\n",
        "        encoded_dict = tokenizer.encode_plus(tweet, \n",
        "                                            add_special_tokens=True, \n",
        "                                            max_length=max_len,\n",
        "                                            pad_to_max_length=True,\n",
        "                                            return_attention_mask=True,\n",
        "                                            return_tensors='pt'\n",
        "                                            )\n",
        "\n",
        "        input_ids.append(encoded_dict['input_ids'])\n",
        "        attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "    input_ids = torch.cat(input_ids, dim=0)\n",
        "    attention_masks = torch.cat(attention_masks, dim=0)\n",
        "    labels_one_anno = torch.tensor(labels[annotator], dtype=torch.float)\n",
        "\n",
        "    # split the dataset and generate dataloader\n",
        "    dataset = TensorDataset(input_ids, attention_masks, labels_one_anno)\n",
        "\n",
        "    # training 80% validation 10% testing 10%\n",
        "    train_size = int(0.8 * len(dataset))\n",
        "    val_size = int(0.1 * len(dataset))\n",
        "    test_size = len(dataset) - train_size - val_size\n",
        "\n",
        "    print('training dataset size:', train_size)\n",
        "    print('validation dataset size:', val_size)\n",
        "    print('testing dataset size:', test_size)\n",
        "    print('')\n",
        "\n",
        "    train_ds, val_ds, test_ds = random_split(dataset, [train_size, val_size, test_size])\n",
        "\n",
        "    # create a dataloader\n",
        "    batch_size = 32\n",
        "\n",
        "    train_dl = DataLoader(train_ds, \n",
        "                        sampler=RandomSampler(train_ds), \n",
        "                        batch_size=batch_size)\n",
        "    train_data_loaders[annotator] = train_dl\n",
        "\n",
        "    val_dl = DataLoader(val_ds, \n",
        "                        sampler=SequentialSampler(val_ds), \n",
        "                        batch_size=batch_size)\n",
        "    val_data_loaders[annotator] = val_dl\n",
        "\n",
        "    test_dl = DataLoader(test_ds, \n",
        "                        sampler=SequentialSampler(test_ds), \n",
        "                        batch_size=batch_size)\n",
        "    test_data_loaders[annotator] = test_dl\n",
        "    \n"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ERROR! Session/line number was not unique in database. History logging moved to new sessionannotator1\n",
            " 61\n",
            "Max tweet length: 33\n",
            "training dataset size: 6282\n",
            "validation dataset size: 785\n",
            "testing dataset size: 786\n",
            "\n",
            "annotator2\n",
            "Max tweet length: 31\n",
            "training dataset size: 5776\n",
            "validation dataset size: 722\n",
            "testing dataset size: 723\n",
            "\n",
            "annotator3\n",
            "Max tweet length: 33\n",
            "training dataset size: 11582\n",
            "validation dataset size: 1447\n",
            "testing dataset size: 1449\n",
            "\n",
            "annotator4\n",
            "Max tweet length: 33\n",
            "training dataset size: 9034\n",
            "validation dataset size: 1129\n",
            "testing dataset size: 1130\n",
            "\n",
            "annotator5\n",
            "Max tweet length: 29\n",
            "training dataset size: 500\n",
            "validation dataset size: 62\n",
            "testing dataset size: 64\n",
            "\n",
            "annotator6\n",
            "Max tweet length: 33\n",
            "training dataset size: 6394\n",
            "validation dataset size: 799\n",
            "testing dataset size: 800\n",
            "\n",
            "annotator7\n",
            "Max tweet length: 32\n",
            "training dataset size: 731\n",
            "validation dataset size: 91\n",
            "testing dataset size: 92\n",
            "\n",
            "annotator8\n",
            "Max tweet length: 32\n",
            "training dataset size: 3058\n",
            "validation dataset size: 382\n",
            "testing dataset size: 383\n",
            "\n",
            "annotator9\n",
            "Max tweet length: 32\n",
            "training dataset size: 3064\n",
            "validation dataset size: 383\n",
            "testing dataset size: 383\n",
            "\n",
            "annotator10\n",
            "Max tweet length: 28\n",
            "training dataset size: 402\n",
            "validation dataset size: 50\n",
            "testing dataset size: 51\n",
            "\n",
            "annotator11\n",
            "Max tweet length: 31\n",
            "training dataset size: 2936\n",
            "validation dataset size: 367\n",
            "testing dataset size: 367\n",
            "\n",
            "annotator12\n",
            "Max tweet length: 31\n",
            "training dataset size: 2938\n",
            "validation dataset size: 367\n",
            "testing dataset size: 368\n",
            "\n",
            "annotator13\n",
            "Max tweet length: 31\n",
            "training dataset size: 2911\n",
            "validation dataset size: 363\n",
            "testing dataset size: 365\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7wj3u8FVdK_",
        "colab_type": "text"
      },
      "source": [
        "### Building Multi-Label BERT Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HlviX-FpVvVT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import BertModel, BertConfig, BertPreTrainedModel\n",
        "from torch.nn import BCEWithLogitsLoss, Sigmoid\n",
        "\n",
        "class BertForMultiLabelSequenceClassification(BertPreTrainedModel):\n",
        "    \"\"\" \n",
        "    Bert for multi-label classification \n",
        "    \"\"\"\n",
        "    def __init__(self, config, num_labels=11):\n",
        "        super(BertForMultiLabelSequenceClassification, self).__init__(config)\n",
        "        self.num_labels = num_labels\n",
        "        self.bert = BertModel(config)\n",
        "        self.dropout = torch.nn.Dropout(config.hidden_dropout_prob)\n",
        "        self.classifier = torch.nn.Linear(config.hidden_size, num_labels)\n",
        "\n",
        "    \n",
        "    def forward(self, input_ids, token_type_ids=None, attention_mask=None, labels=None):\n",
        "        _, pooled_output = self.bert(input_ids, token_type_ids, attention_mask)\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "        logits = self.classifier(pooled_output)\n",
        "        \n",
        "        if labels is not None:\n",
        "            new_loss = BCEWithLogitsLoss()\n",
        "            loss = new_loss(logits.view(-1, self.num_labels), labels.view(-1, self.num_labels))\n",
        "            return loss, logits\n",
        "        else:\n",
        "            return logits"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSRiQzlJr-Sx",
        "colab_type": "text"
      },
      "source": [
        "### Model Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cxaFYgK0rnSP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2d43ede7-8539-4b1c-f61f-58fe0701aa1b"
      },
      "source": [
        "model = BertForMultiLabelSequenceClassification.from_pretrained(\"bert-base-uncased\", \n",
        "                                                                 output_attentions=False, \n",
        "                                                                 output_hidden_states=False)\n",
        "\n",
        "model.cuda()\n",
        "\n",
        "#visualize\n",
        "params = list(model.named_parameters())\n",
        "\n",
        "for p in params:\n",
        "    print(\"{:<60} {:>15}\".format(p[0], str(tuple(p[1].size()))))\n"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bert.embeddings.word_embeddings.weight                          (30522, 768)\n",
            "bert.embeddings.position_embeddings.weight                        (512, 768)\n",
            "bert.embeddings.token_type_embeddings.weight                        (2, 768)\n",
            "bert.embeddings.LayerNorm.weight                                      (768,)\n",
            "bert.embeddings.LayerNorm.bias                                        (768,)\n",
            "bert.encoder.layer.0.attention.self.query.weight                  (768, 768)\n",
            "bert.encoder.layer.0.attention.self.query.bias                        (768,)\n",
            "bert.encoder.layer.0.attention.self.key.weight                    (768, 768)\n",
            "bert.encoder.layer.0.attention.self.key.bias                          (768,)\n",
            "bert.encoder.layer.0.attention.self.value.weight                  (768, 768)\n",
            "bert.encoder.layer.0.attention.self.value.bias                        (768,)\n",
            "bert.encoder.layer.0.attention.output.dense.weight                (768, 768)\n",
            "bert.encoder.layer.0.attention.output.dense.bias                      (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.weight                (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.bias                  (768,)\n",
            "bert.encoder.layer.0.intermediate.dense.weight                   (3072, 768)\n",
            "bert.encoder.layer.0.intermediate.dense.bias                         (3072,)\n",
            "bert.encoder.layer.0.output.dense.weight                         (768, 3072)\n",
            "bert.encoder.layer.0.output.dense.bias                                (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.weight                          (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.bias                            (768,)\n",
            "bert.encoder.layer.1.attention.self.query.weight                  (768, 768)\n",
            "bert.encoder.layer.1.attention.self.query.bias                        (768,)\n",
            "bert.encoder.layer.1.attention.self.key.weight                    (768, 768)\n",
            "bert.encoder.layer.1.attention.self.key.bias                          (768,)\n",
            "bert.encoder.layer.1.attention.self.value.weight                  (768, 768)\n",
            "bert.encoder.layer.1.attention.self.value.bias                        (768,)\n",
            "bert.encoder.layer.1.attention.output.dense.weight                (768, 768)\n",
            "bert.encoder.layer.1.attention.output.dense.bias                      (768,)\n",
            "bert.encoder.layer.1.attention.output.LayerNorm.weight                (768,)\n",
            "bert.encoder.layer.1.attention.output.LayerNorm.bias                  (768,)\n",
            "bert.encoder.layer.1.intermediate.dense.weight                   (3072, 768)\n",
            "bert.encoder.layer.1.intermediate.dense.bias                         (3072,)\n",
            "bert.encoder.layer.1.output.dense.weight                         (768, 3072)\n",
            "bert.encoder.layer.1.output.dense.bias                                (768,)\n",
            "bert.encoder.layer.1.output.LayerNorm.weight                          (768,)\n",
            "bert.encoder.layer.1.output.LayerNorm.bias                            (768,)\n",
            "bert.encoder.layer.2.attention.self.query.weight                  (768, 768)\n",
            "bert.encoder.layer.2.attention.self.query.bias                        (768,)\n",
            "bert.encoder.layer.2.attention.self.key.weight                    (768, 768)\n",
            "bert.encoder.layer.2.attention.self.key.bias                          (768,)\n",
            "bert.encoder.layer.2.attention.self.value.weight                  (768, 768)\n",
            "bert.encoder.layer.2.attention.self.value.bias                        (768,)\n",
            "bert.encoder.layer.2.attention.output.dense.weight                (768, 768)\n",
            "bert.encoder.layer.2.attention.output.dense.bias                      (768,)\n",
            "bert.encoder.layer.2.attention.output.LayerNorm.weight                (768,)\n",
            "bert.encoder.layer.2.attention.output.LayerNorm.bias                  (768,)\n",
            "bert.encoder.layer.2.intermediate.dense.weight                   (3072, 768)\n",
            "bert.encoder.layer.2.intermediate.dense.bias                         (3072,)\n",
            "bert.encoder.layer.2.output.dense.weight                         (768, 3072)\n",
            "bert.encoder.layer.2.output.dense.bias                                (768,)\n",
            "bert.encoder.layer.2.output.LayerNorm.weight                          (768,)\n",
            "bert.encoder.layer.2.output.LayerNorm.bias                            (768,)\n",
            "bert.encoder.layer.3.attention.self.query.weight                  (768, 768)\n",
            "bert.encoder.layer.3.attention.self.query.bias                        (768,)\n",
            "bert.encoder.layer.3.attention.self.key.weight                    (768, 768)\n",
            "bert.encoder.layer.3.attention.self.key.bias                          (768,)\n",
            "bert.encoder.layer.3.attention.self.value.weight                  (768, 768)\n",
            "bert.encoder.layer.3.attention.self.value.bias                        (768,)\n",
            "bert.encoder.layer.3.attention.output.dense.weight                (768, 768)\n",
            "bert.encoder.layer.3.attention.output.dense.bias                      (768,)\n",
            "bert.encoder.layer.3.attention.output.LayerNorm.weight                (768,)\n",
            "bert.encoder.layer.3.attention.output.LayerNorm.bias                  (768,)\n",
            "bert.encoder.layer.3.intermediate.dense.weight                   (3072, 768)\n",
            "bert.encoder.layer.3.intermediate.dense.bias                         (3072,)\n",
            "bert.encoder.layer.3.output.dense.weight                         (768, 3072)\n",
            "bert.encoder.layer.3.output.dense.bias                                (768,)\n",
            "bert.encoder.layer.3.output.LayerNorm.weight                          (768,)\n",
            "bert.encoder.layer.3.output.LayerNorm.bias                            (768,)\n",
            "bert.encoder.layer.4.attention.self.query.weight                  (768, 768)\n",
            "bert.encoder.layer.4.attention.self.query.bias                        (768,)\n",
            "bert.encoder.layer.4.attention.self.key.weight                    (768, 768)\n",
            "bert.encoder.layer.4.attention.self.key.bias                          (768,)\n",
            "bert.encoder.layer.4.attention.self.value.weight                  (768, 768)\n",
            "bert.encoder.layer.4.attention.self.value.bias                        (768,)\n",
            "bert.encoder.layer.4.attention.output.dense.weight                (768, 768)\n",
            "bert.encoder.layer.4.attention.output.dense.bias                      (768,)\n",
            "bert.encoder.layer.4.attention.output.LayerNorm.weight                (768,)\n",
            "bert.encoder.layer.4.attention.output.LayerNorm.bias                  (768,)\n",
            "bert.encoder.layer.4.intermediate.dense.weight                   (3072, 768)\n",
            "bert.encoder.layer.4.intermediate.dense.bias                         (3072,)\n",
            "bert.encoder.layer.4.output.dense.weight                         (768, 3072)\n",
            "bert.encoder.layer.4.output.dense.bias                                (768,)\n",
            "bert.encoder.layer.4.output.LayerNorm.weight                          (768,)\n",
            "bert.encoder.layer.4.output.LayerNorm.bias                            (768,)\n",
            "bert.encoder.layer.5.attention.self.query.weight                  (768, 768)\n",
            "bert.encoder.layer.5.attention.self.query.bias                        (768,)\n",
            "bert.encoder.layer.5.attention.self.key.weight                    (768, 768)\n",
            "bert.encoder.layer.5.attention.self.key.bias                          (768,)\n",
            "bert.encoder.layer.5.attention.self.value.weight                  (768, 768)\n",
            "bert.encoder.layer.5.attention.self.value.bias                        (768,)\n",
            "bert.encoder.layer.5.attention.output.dense.weight                (768, 768)\n",
            "bert.encoder.layer.5.attention.output.dense.bias                      (768,)\n",
            "bert.encoder.layer.5.attention.output.LayerNorm.weight                (768,)\n",
            "bert.encoder.layer.5.attention.output.LayerNorm.bias                  (768,)\n",
            "bert.encoder.layer.5.intermediate.dense.weight                   (3072, 768)\n",
            "bert.encoder.layer.5.intermediate.dense.bias                         (3072,)\n",
            "bert.encoder.layer.5.output.dense.weight                         (768, 3072)\n",
            "bert.encoder.layer.5.output.dense.bias                                (768,)\n",
            "bert.encoder.layer.5.output.LayerNorm.weight                          (768,)\n",
            "bert.encoder.layer.5.output.LayerNorm.bias                            (768,)\n",
            "bert.encoder.layer.6.attention.self.query.weight                  (768, 768)\n",
            "bert.encoder.layer.6.attention.self.query.bias                        (768,)\n",
            "bert.encoder.layer.6.attention.self.key.weight                    (768, 768)\n",
            "bert.encoder.layer.6.attention.self.key.bias                          (768,)\n",
            "bert.encoder.layer.6.attention.self.value.weight                  (768, 768)\n",
            "bert.encoder.layer.6.attention.self.value.bias                        (768,)\n",
            "bert.encoder.layer.6.attention.output.dense.weight                (768, 768)\n",
            "bert.encoder.layer.6.attention.output.dense.bias                      (768,)\n",
            "bert.encoder.layer.6.attention.output.LayerNorm.weight                (768,)\n",
            "bert.encoder.layer.6.attention.output.LayerNorm.bias                  (768,)\n",
            "bert.encoder.layer.6.intermediate.dense.weight                   (3072, 768)\n",
            "bert.encoder.layer.6.intermediate.dense.bias                         (3072,)\n",
            "bert.encoder.layer.6.output.dense.weight                         (768, 3072)\n",
            "bert.encoder.layer.6.output.dense.bias                                (768,)\n",
            "bert.encoder.layer.6.output.LayerNorm.weight                          (768,)\n",
            "bert.encoder.layer.6.output.LayerNorm.bias                            (768,)\n",
            "bert.encoder.layer.7.attention.self.query.weight                  (768, 768)\n",
            "bert.encoder.layer.7.attention.self.query.bias                        (768,)\n",
            "bert.encoder.layer.7.attention.self.key.weight                    (768, 768)\n",
            "bert.encoder.layer.7.attention.self.key.bias                          (768,)\n",
            "bert.encoder.layer.7.attention.self.value.weight                  (768, 768)\n",
            "bert.encoder.layer.7.attention.self.value.bias                        (768,)\n",
            "bert.encoder.layer.7.attention.output.dense.weight                (768, 768)\n",
            "bert.encoder.layer.7.attention.output.dense.bias                      (768,)\n",
            "bert.encoder.layer.7.attention.output.LayerNorm.weight                (768,)\n",
            "bert.encoder.layer.7.attention.output.LayerNorm.bias                  (768,)\n",
            "bert.encoder.layer.7.intermediate.dense.weight                   (3072, 768)\n",
            "bert.encoder.layer.7.intermediate.dense.bias                         (3072,)\n",
            "bert.encoder.layer.7.output.dense.weight                         (768, 3072)\n",
            "bert.encoder.layer.7.output.dense.bias                                (768,)\n",
            "bert.encoder.layer.7.output.LayerNorm.weight                          (768,)\n",
            "bert.encoder.layer.7.output.LayerNorm.bias                            (768,)\n",
            "bert.encoder.layer.8.attention.self.query.weight                  (768, 768)\n",
            "bert.encoder.layer.8.attention.self.query.bias                        (768,)\n",
            "bert.encoder.layer.8.attention.self.key.weight                    (768, 768)\n",
            "bert.encoder.layer.8.attention.self.key.bias                          (768,)\n",
            "bert.encoder.layer.8.attention.self.value.weight                  (768, 768)\n",
            "bert.encoder.layer.8.attention.self.value.bias                        (768,)\n",
            "bert.encoder.layer.8.attention.output.dense.weight                (768, 768)\n",
            "bert.encoder.layer.8.attention.output.dense.bias                      (768,)\n",
            "bert.encoder.layer.8.attention.output.LayerNorm.weight                (768,)\n",
            "bert.encoder.layer.8.attention.output.LayerNorm.bias                  (768,)\n",
            "bert.encoder.layer.8.intermediate.dense.weight                   (3072, 768)\n",
            "bert.encoder.layer.8.intermediate.dense.bias                         (3072,)\n",
            "bert.encoder.layer.8.output.dense.weight                         (768, 3072)\n",
            "bert.encoder.layer.8.output.dense.bias                                (768,)\n",
            "bert.encoder.layer.8.output.LayerNorm.weight                          (768,)\n",
            "bert.encoder.layer.8.output.LayerNorm.bias                            (768,)\n",
            "bert.encoder.layer.9.attention.self.query.weight                  (768, 768)\n",
            "bert.encoder.layer.9.attention.self.query.bias                        (768,)\n",
            "bert.encoder.layer.9.attention.self.key.weight                    (768, 768)\n",
            "bert.encoder.layer.9.attention.self.key.bias                          (768,)\n",
            "bert.encoder.layer.9.attention.self.value.weight                  (768, 768)\n",
            "bert.encoder.layer.9.attention.self.value.bias                        (768,)\n",
            "bert.encoder.layer.9.attention.output.dense.weight                (768, 768)\n",
            "bert.encoder.layer.9.attention.output.dense.bias                      (768,)\n",
            "bert.encoder.layer.9.attention.output.LayerNorm.weight                (768,)\n",
            "bert.encoder.layer.9.attention.output.LayerNorm.bias                  (768,)\n",
            "bert.encoder.layer.9.intermediate.dense.weight                   (3072, 768)\n",
            "bert.encoder.layer.9.intermediate.dense.bias                         (3072,)\n",
            "bert.encoder.layer.9.output.dense.weight                         (768, 3072)\n",
            "bert.encoder.layer.9.output.dense.bias                                (768,)\n",
            "bert.encoder.layer.9.output.LayerNorm.weight                          (768,)\n",
            "bert.encoder.layer.9.output.LayerNorm.bias                            (768,)\n",
            "bert.encoder.layer.10.attention.self.query.weight                 (768, 768)\n",
            "bert.encoder.layer.10.attention.self.query.bias                       (768,)\n",
            "bert.encoder.layer.10.attention.self.key.weight                   (768, 768)\n",
            "bert.encoder.layer.10.attention.self.key.bias                         (768,)\n",
            "bert.encoder.layer.10.attention.self.value.weight                 (768, 768)\n",
            "bert.encoder.layer.10.attention.self.value.bias                       (768,)\n",
            "bert.encoder.layer.10.attention.output.dense.weight               (768, 768)\n",
            "bert.encoder.layer.10.attention.output.dense.bias                     (768,)\n",
            "bert.encoder.layer.10.attention.output.LayerNorm.weight               (768,)\n",
            "bert.encoder.layer.10.attention.output.LayerNorm.bias                 (768,)\n",
            "bert.encoder.layer.10.intermediate.dense.weight                  (3072, 768)\n",
            "bert.encoder.layer.10.intermediate.dense.bias                        (3072,)\n",
            "bert.encoder.layer.10.output.dense.weight                        (768, 3072)\n",
            "bert.encoder.layer.10.output.dense.bias                               (768,)\n",
            "bert.encoder.layer.10.output.LayerNorm.weight                         (768,)\n",
            "bert.encoder.layer.10.output.LayerNorm.bias                           (768,)\n",
            "bert.encoder.layer.11.attention.self.query.weight                 (768, 768)\n",
            "bert.encoder.layer.11.attention.self.query.bias                       (768,)\n",
            "bert.encoder.layer.11.attention.self.key.weight                   (768, 768)\n",
            "bert.encoder.layer.11.attention.self.key.bias                         (768,)\n",
            "bert.encoder.layer.11.attention.self.value.weight                 (768, 768)\n",
            "bert.encoder.layer.11.attention.self.value.bias                       (768,)\n",
            "bert.encoder.layer.11.attention.output.dense.weight               (768, 768)\n",
            "bert.encoder.layer.11.attention.output.dense.bias                     (768,)\n",
            "bert.encoder.layer.11.attention.output.LayerNorm.weight               (768,)\n",
            "bert.encoder.layer.11.attention.output.LayerNorm.bias                 (768,)\n",
            "bert.encoder.layer.11.intermediate.dense.weight                  (3072, 768)\n",
            "bert.encoder.layer.11.intermediate.dense.bias                        (3072,)\n",
            "bert.encoder.layer.11.output.dense.weight                        (768, 3072)\n",
            "bert.encoder.layer.11.output.dense.bias                               (768,)\n",
            "bert.encoder.layer.11.output.LayerNorm.weight                         (768,)\n",
            "bert.encoder.layer.11.output.LayerNorm.bias                           (768,)\n",
            "bert.pooler.dense.weight                                          (768, 768)\n",
            "bert.pooler.dense.bias                                                (768,)\n",
            "classifier.weight                                                  (11, 768)\n",
            "classifier.bias                                                        (11,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tpcl1aBYaD6y",
        "colab_type": "text"
      },
      "source": [
        "### Optimizer & Learning Rate Scheduler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwbBN5C3aJxb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup, AdamW\n",
        "\n",
        "# set up the optimizer\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr=2e-5,\n",
        "                  eps=1e-8)\n",
        "\n",
        "# set up the lr scheduler\n",
        "epochs = 3\n",
        "total_steps = len(train_dl) * epochs\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                            num_warmup_steps=0,\n",
        "                                            num_training_steps=total_steps)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QVHPS3_nbOM-",
        "colab_type": "text"
      },
      "source": [
        "### Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tkoALr0NbZjN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "from sklearn.metrics import hamming_loss, accuracy_score\n",
        "\n",
        "def get_accuracy_hamming_loss(preds, labels):\n",
        "    preds = preds >= 0.5\n",
        "\n",
        "    return 1 - hamming_loss(preds, labels)\n",
        "\n",
        "def get_accuracy_exact_match(preds, labels):\n",
        "    preds = preds >= 0.5\n",
        "\n",
        "    return accuracy_score(preds, labels)\n",
        "\n",
        "# correct labels out of cases where prediction and labels are not both 0\n",
        "def get_accuracy_none_zero(preds, labels):\n",
        "    preds = preds >= 0.5\n",
        "\n",
        "    total = []\n",
        "    for i in range(len(preds)):\n",
        "        suM = 0\n",
        "        for j in range(len(preds[i])):\n",
        "            correct = 0\n",
        "            #correct\n",
        "            if preds[i][j] == 1 and labels[i][j]== 1 :\n",
        "                suM += 1\n",
        "                correct += 1\n",
        "            #missed \n",
        "            elif labels[i][j]== 1 and preds[i][j] == 0:\n",
        "                suM += 1\n",
        "            elif labels[i][j]== 0 and preds[i][j] == 1:\n",
        "                suM += 1\n",
        "        \n",
        "        if suM != 0:\n",
        "            total.append(correct/suM)\n",
        "\n",
        "    return np.mean(total)\n",
        "                \n",
        "\n",
        "# take a time in seconds and returns a string hh:mm:ss\n",
        "def format_time(elapsed):\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-MYO6-Fsr2cJ",
        "colab_type": "text"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ue5J6TPYFZDw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "429aa603-8e7c-4e69-a6a5-80d21091a856"
      },
      "source": [
        "import random\n",
        "\n",
        "seed_val = 1\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "training_stats = {}\n",
        "\n",
        "for annotator in tweets:\n",
        "    training_stats[annotator] = []\n",
        "    total_t0 = time.time() \n",
        "\n",
        "    train_dl = train_data_loaders[annotator]\n",
        "    val_dl = val_data_loaders[annotator]\n",
        "    print(\"***************************************\")\n",
        "    print('Training ', annotator.upper())\n",
        "\n",
        "    # initialize BERT weights\n",
        "    model.init_weights()\n",
        "    for epoch_i in range(0, epochs):\n",
        "        print(\"\")\n",
        "        print('======= Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "        print(\"\")\n",
        "\n",
        "        t0 = time.time()\n",
        "        total_train_loss = 0\n",
        "        model.train()\n",
        "\n",
        "        for step, batch in enumerate(train_dl):\n",
        "            # periodically update elapsed time\n",
        "            if step % 40 == 0 and not step == 0:\n",
        "                elapsed = format_time(time.time() - t0)\n",
        "\n",
        "                print('Batch {:>5,} of {:>5,}. Elapsed: {:}.'.format(step, \n",
        "                                                                    len(train_dl), \n",
        "                                                                    elapsed))\n",
        "            # unpack current batch's input & labels   \n",
        "            cur_input_ids = batch[0].to(device)\n",
        "            cur_input_mask = batch[1].to(device)\n",
        "            cur_labels = batch[2].to(device)\n",
        "\n",
        "            # clear previously calculated gradients\n",
        "            model.zero_grad()\n",
        "\n",
        "            # perform a forward pass\n",
        "            # logits = classifications, before activation function e.x. softmax\n",
        "            loss, logits = model(cur_input_ids, \n",
        "                                token_type_ids=None,\n",
        "                                attention_mask=cur_input_mask,\n",
        "                                labels=cur_labels)\n",
        "                    \n",
        "            # accumulate training loss\n",
        "            total_train_loss += loss.item()\n",
        "\n",
        "            # perform a backward pass to calculate the gradients of params\n",
        "            loss.backward()\n",
        "\n",
        "            # clip the gradients if it is not in [-1,1]\n",
        "            # torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "            # update weights\n",
        "            optimizer.step()\n",
        "\n",
        "            # update lr\n",
        "            scheduler.step()\n",
        "\n",
        "        # calculate stats after 1 epoch of training\n",
        "        avg_train_loss = total_train_loss / len(train_dl)\n",
        "        training_time = format_time(time.time() - t0)\n",
        "\n",
        "        print(\"\")\n",
        "        print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "        print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "\n",
        "        # validation \n",
        "        print(\"\")\n",
        "        print(\"Validating...\")\n",
        "\n",
        "        t0 = time.time()\n",
        "\n",
        "        model.eval()\n",
        "\n",
        "        total_eval_accuracy_hamming_loss = 0\n",
        "        total_eval_accuracy_exact_match = 0\n",
        "        total_eval_loss = 0\n",
        "        nb_eval_steps = 0\n",
        "\n",
        "        for batch in val_dl:\n",
        "            \n",
        "            # unpack current batch's input and labels\n",
        "            cur_input_ids = batch[0].to(device)\n",
        "            cur_input_mask = batch[1].to(device)\n",
        "            cur_labels = batch[2].to(device)\n",
        "\n",
        "            # no need to calculate and trace gradient\n",
        "            with torch.no_grad():\n",
        "                loss, logits = model(cur_input_ids,\n",
        "                                    token_type_ids=None,\n",
        "                                    attention_mask=cur_input_mask,\n",
        "                                    labels=cur_labels)\n",
        "                        \n",
        "            # no need to calculate prediction & labels in gpu\n",
        "            # good practice when involves with large-scale dataset\n",
        "            logits = logits.detach().cpu().numpy()\n",
        "            label_ids = cur_labels.to('cpu')\n",
        "            \n",
        "            # calculate this batch's accuracy & loss and accumulate with other \n",
        "            # batches' accuracies & loss\n",
        "            total_eval_accuracy_hamming_loss += get_accuracy_hamming_loss(logits, label_ids)\n",
        "            total_eval_accuracy_exact_match += get_accuracy_exact_match(logits, label_ids)\n",
        "            \n",
        "            total_eval_loss += loss.item()\n",
        "\n",
        "        # average out loss and accuracy across all batches\n",
        "        avg_val_accuracy_hamming_loss = total_eval_accuracy_hamming_loss / len(val_dl)\n",
        "        avg_val_accuracy_exact_match = total_eval_accuracy_exact_match / len(val_dl)\n",
        "        avg_val_loss = total_eval_loss / len(val_dl)\n",
        "        validation_time = format_time(time.time() - t0)\n",
        "\n",
        "        print(\"Loss: {0:.2f}, Time elapsed: {1:}\".format(avg_val_loss, validation_time))\n",
        "        print(\"==== Accuracy ====\")\n",
        "        print(\"Hamming Loss:\", avg_val_accuracy_hamming_loss)\n",
        "        print(\"Exact Match\", avg_val_accuracy_exact_match)\n",
        "\n",
        "        # record all statistics for this epoch\n",
        "        training_stats[annotator].append({\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur': avg_val_accuracy_hamming_loss,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        })\n",
        "\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Training for {0:} Completed. Training took {1:}\".format(annotator, format_time(time.time() - total_t0)))\n",
        "    print(\"***************************************\")\n",
        "    print(\"\")\n",
        "\n",
        "\n",
        "print(\"Training Completed for ALL Annotators\")"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "***************************************\n",
            "Training  ANNOTATOR1\n",
            "\n",
            "======= Epoch 1 / 3 ========\n",
            "\n",
            "Batch    40 of   197. Elapsed: 0:00:11.\n",
            "Batch    80 of   197. Elapsed: 0:00:21.\n",
            "Batch   120 of   197. Elapsed: 0:00:32.\n",
            "Batch   160 of   197. Elapsed: 0:00:42.\n",
            "\n",
            "  Average training loss: 0.69\n",
            "  Training epcoh took: 0:00:52\n",
            "\n",
            "Validating...\n",
            "Loss: 0.69, Time elapsed: 0:00:02\n",
            "==== Accuracy ====\n",
            "Hamming Loss: 0.8896991978609627\n",
            "Exact Match 0.0025\n",
            "\n",
            "======= Epoch 2 / 3 ========\n",
            "\n",
            "Batch    40 of   197. Elapsed: 0:00:10.\n",
            "Batch    80 of   197. Elapsed: 0:00:21.\n",
            "Batch   120 of   197. Elapsed: 0:00:31.\n",
            "Batch   160 of   197. Elapsed: 0:00:42.\n",
            "\n",
            "  Average training loss: 0.69\n",
            "  Training epcoh took: 0:00:52\n",
            "\n",
            "Validating...\n",
            "Loss: 0.69, Time elapsed: 0:00:02\n",
            "==== Accuracy ====\n",
            "Hamming Loss: 0.8896991978609627\n",
            "Exact Match 0.0025\n",
            "\n",
            "======= Epoch 3 / 3 ========\n",
            "\n",
            "Batch    40 of   197. Elapsed: 0:00:11.\n",
            "Batch    80 of   197. Elapsed: 0:00:21.\n",
            "Batch   120 of   197. Elapsed: 0:00:32.\n",
            "Batch   160 of   197. Elapsed: 0:00:42.\n",
            "\n",
            "  Average training loss: 0.69\n",
            "  Training epcoh took: 0:00:52\n",
            "\n",
            "Validating...\n",
            "Loss: 0.69, Time elapsed: 0:00:02\n",
            "==== Accuracy ====\n",
            "Hamming Loss: 0.8896991978609627\n",
            "Exact Match 0.0025\n",
            "\n",
            "Training for annotator1 Completed. Training took 0:02:40\n",
            "***************************************\n",
            "\n",
            "***************************************\n",
            "Training  ANNOTATOR2\n",
            "\n",
            "======= Epoch 1 / 3 ========\n",
            "\n",
            "Batch    40 of   181. Elapsed: 0:00:10.\n",
            "Batch    80 of   181. Elapsed: 0:00:20.\n",
            "Batch   120 of   181. Elapsed: 0:00:30.\n",
            "Batch   160 of   181. Elapsed: 0:00:40.\n",
            "\n",
            "  Average training loss: 0.67\n",
            "  Training epcoh took: 0:00:45\n",
            "\n",
            "Validating...\n",
            "Loss: 0.67, Time elapsed: 0:00:02\n",
            "==== Accuracy ====\n",
            "Hamming Loss: 0.9008975625823451\n",
            "Exact Match 0.005434782608695652\n",
            "\n",
            "======= Epoch 2 / 3 ========\n",
            "\n",
            "Batch    40 of   181. Elapsed: 0:00:10.\n",
            "Batch    80 of   181. Elapsed: 0:00:20.\n",
            "Batch   120 of   181. Elapsed: 0:00:30.\n",
            "Batch   160 of   181. Elapsed: 0:00:40.\n",
            "\n",
            "  Average training loss: 0.67\n",
            "  Training epcoh took: 0:00:45\n",
            "\n",
            "Validating...\n",
            "Loss: 0.67, Time elapsed: 0:00:02\n",
            "==== Accuracy ====\n",
            "Hamming Loss: 0.9008975625823451\n",
            "Exact Match 0.005434782608695652\n",
            "\n",
            "======= Epoch 3 / 3 ========\n",
            "\n",
            "Batch    40 of   181. Elapsed: 0:00:10.\n",
            "Batch    80 of   181. Elapsed: 0:00:20.\n",
            "Batch   120 of   181. Elapsed: 0:00:30.\n",
            "Batch   160 of   181. Elapsed: 0:00:40.\n",
            "\n",
            "  Average training loss: 0.67\n",
            "  Training epcoh took: 0:00:45\n",
            "\n",
            "Validating...\n",
            "Loss: 0.67, Time elapsed: 0:00:02\n",
            "==== Accuracy ====\n",
            "Hamming Loss: 0.9008975625823451\n",
            "Exact Match 0.005434782608695652\n",
            "\n",
            "Training for annotator2 Completed. Training took 0:02:19\n",
            "***************************************\n",
            "\n",
            "***************************************\n",
            "Training  ANNOTATOR3\n",
            "\n",
            "======= Epoch 1 / 3 ========\n",
            "\n",
            "Batch    40 of   362. Elapsed: 0:00:10.\n",
            "Batch    80 of   362. Elapsed: 0:00:21.\n",
            "Batch   120 of   362. Elapsed: 0:00:31.\n",
            "Batch   160 of   362. Elapsed: 0:00:42.\n",
            "Batch   200 of   362. Elapsed: 0:00:52.\n",
            "Batch   240 of   362. Elapsed: 0:01:03.\n",
            "Batch   280 of   362. Elapsed: 0:01:13.\n",
            "Batch   320 of   362. Elapsed: 0:01:24.\n",
            "Batch   360 of   362. Elapsed: 0:01:34.\n",
            "\n",
            "  Average training loss: 0.70\n",
            "  Training epcoh took: 0:01:35\n",
            "\n",
            "Validating...\n",
            "Loss: 0.70, Time elapsed: 0:00:03\n",
            "==== Accuracy ====\n",
            "Hamming Loss: 0.8771527385657821\n",
            "Exact Match 0.0\n",
            "\n",
            "======= Epoch 2 / 3 ========\n",
            "\n",
            "Batch    40 of   362. Elapsed: 0:00:10.\n",
            "Batch    80 of   362. Elapsed: 0:00:21.\n",
            "Batch   120 of   362. Elapsed: 0:00:32.\n",
            "Batch   160 of   362. Elapsed: 0:00:42.\n",
            "Batch   200 of   362. Elapsed: 0:00:53.\n",
            "Batch   240 of   362. Elapsed: 0:01:03.\n",
            "Batch   280 of   362. Elapsed: 0:01:14.\n",
            "Batch   320 of   362. Elapsed: 0:01:24.\n",
            "Batch   360 of   362. Elapsed: 0:01:35.\n",
            "\n",
            "  Average training loss: 0.70\n",
            "  Training epcoh took: 0:01:35\n",
            "\n",
            "Validating...\n",
            "Loss: 0.70, Time elapsed: 0:00:03\n",
            "==== Accuracy ====\n",
            "Hamming Loss: 0.8771527385657821\n",
            "Exact Match 0.0\n",
            "\n",
            "======= Epoch 3 / 3 ========\n",
            "\n",
            "Batch    40 of   362. Elapsed: 0:00:10.\n",
            "Batch    80 of   362. Elapsed: 0:00:21.\n",
            "Batch   120 of   362. Elapsed: 0:00:31.\n",
            "Batch   160 of   362. Elapsed: 0:00:42.\n",
            "Batch   200 of   362. Elapsed: 0:00:52.\n",
            "Batch   240 of   362. Elapsed: 0:01:03.\n",
            "Batch   280 of   362. Elapsed: 0:01:13.\n",
            "Batch   320 of   362. Elapsed: 0:01:24.\n",
            "Batch   360 of   362. Elapsed: 0:01:34.\n",
            "\n",
            "  Average training loss: 0.70\n",
            "  Training epcoh took: 0:01:35\n",
            "\n",
            "Validating...\n",
            "Loss: 0.70, Time elapsed: 0:00:03\n",
            "==== Accuracy ====\n",
            "Hamming Loss: 0.8771527385657821\n",
            "Exact Match 0.0\n",
            "\n",
            "Training for annotator3 Completed. Training took 0:04:55\n",
            "***************************************\n",
            "\n",
            "***************************************\n",
            "Training  ANNOTATOR4\n",
            "\n",
            "======= Epoch 1 / 3 ========\n",
            "\n",
            "Batch    40 of   283. Elapsed: 0:00:10.\n",
            "Batch    80 of   283. Elapsed: 0:00:21.\n",
            "Batch   120 of   283. Elapsed: 0:00:32.\n",
            "Batch   160 of   283. Elapsed: 0:00:42.\n",
            "Batch   200 of   283. Elapsed: 0:00:53.\n",
            "Batch   240 of   283. Elapsed: 0:01:03.\n",
            "Batch   280 of   283. Elapsed: 0:01:14.\n",
            "\n",
            "  Average training loss: 0.64\n",
            "  Training epcoh took: 0:01:14\n",
            "\n",
            "Validating...\n",
            "Loss: 0.63, Time elapsed: 0:00:03\n",
            "==== Accuracy ====\n",
            "Hamming Loss: 0.8894325196408529\n",
            "Exact Match 0.0\n",
            "\n",
            "======= Epoch 2 / 3 ========\n",
            "\n",
            "Batch    40 of   283. Elapsed: 0:00:10.\n",
            "Batch    80 of   283. Elapsed: 0:00:21.\n",
            "Batch   120 of   283. Elapsed: 0:00:31.\n",
            "Batch   160 of   283. Elapsed: 0:00:42.\n",
            "Batch   200 of   283. Elapsed: 0:00:53.\n",
            "Batch   240 of   283. Elapsed: 0:01:03.\n",
            "Batch   280 of   283. Elapsed: 0:01:14.\n",
            "\n",
            "  Average training loss: 0.64\n",
            "  Training epcoh took: 0:01:14\n",
            "\n",
            "Validating...\n",
            "Loss: 0.63, Time elapsed: 0:00:03\n",
            "==== Accuracy ====\n",
            "Hamming Loss: 0.8894325196408529\n",
            "Exact Match 0.0\n",
            "\n",
            "======= Epoch 3 / 3 ========\n",
            "\n",
            "Batch    40 of   283. Elapsed: 0:00:10.\n",
            "Batch    80 of   283. Elapsed: 0:00:21.\n",
            "Batch   120 of   283. Elapsed: 0:00:32.\n",
            "Batch   160 of   283. Elapsed: 0:00:42.\n",
            "Batch   200 of   283. Elapsed: 0:00:53.\n",
            "Batch   240 of   283. Elapsed: 0:01:03.\n",
            "Batch   280 of   283. Elapsed: 0:01:14.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-85-6be2f2f4e042>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;31m# perform a backward pass to calculate the gradients of params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0;31m# clip the gradients if it is not in [-1,1]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Xpcd9gUwjqb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "db1b2054-7f19-4245-ded4-47c2c0281113"
      },
      "source": [
        "# Display training stats\n",
        "# Display numbers with two decimal\n",
        "pd.set_option('precision', 2)\n",
        "\n",
        "for annotator in tweets:\n",
        "    df_stats = pd.DataFrame(data=training_stats[annotator])\n",
        "    df_stats = df_stats.set_index('epoch')\n",
        "    display(df_stats)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Valid. Loss</th>\n",
              "      <th>Valid. Accur</th>\n",
              "      <th>Training Time</th>\n",
              "      <th>Validation Time</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>epoch</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.69</td>\n",
              "      <td>0.69</td>\n",
              "      <td>0.87</td>\n",
              "      <td>0:01:35</td>\n",
              "      <td>0:00:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.69</td>\n",
              "      <td>0.69</td>\n",
              "      <td>0.87</td>\n",
              "      <td>0:01:35</td>\n",
              "      <td>0:00:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.69</td>\n",
              "      <td>0.69</td>\n",
              "      <td>0.87</td>\n",
              "      <td>0:01:35</td>\n",
              "      <td>0:00:03</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Training Loss  Valid. Loss  Valid. Accur Training Time Validation Time\n",
              "epoch                                                                        \n",
              "1               0.69         0.69          0.87       0:01:35         0:00:03\n",
              "2               0.69         0.69          0.87       0:01:35         0:00:03\n",
              "3               0.69         0.69          0.87       0:01:35         0:00:03"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zdKwFWsQsZ-5",
        "colab_type": "text"
      },
      "source": [
        "# Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3hvIeuts3ysN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "bb50193e-7e08-4139-a7aa-f9c905313796"
      },
      "source": [
        "model.eval()\n",
        "\n",
        "for annotator in tweets:\n",
        "    total_accuracy_test = 0\n",
        "    test_dl = test_data_loaders[annotator]\n",
        "\n",
        "    for batch in test_dl:\n",
        "        # unpack current batch's input and labels\n",
        "        cur_input_ids = batch[0].to(device)\n",
        "        cur_input_mask = batch[1].to(device)\n",
        "        cur_labels = batch[2].to(device)\n",
        "\n",
        "        # no need to calculate and trace gradient\n",
        "        with torch.no_grad():\n",
        "            loss, logits = model(cur_input_ids,\n",
        "                                token_type_ids=None,\n",
        "                                attention_mask=cur_input_mask,\n",
        "                                labels=cur_labels)\n",
        "                        \n",
        "        # no need to calculate prediction & labels in gpu\n",
        "        # good practice when involves with large-scale dataset\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = cur_labels.to('cpu')\n",
        "            \n",
        "        # calculate this batch's accuracy & loss and accumulate with other \n",
        "        # batches' accuracies & loss\n",
        "        total_accuracy_test += get_accuracy_hamming_loss(logits, label_ids)\n",
        "            \n",
        "\n",
        "    print('Testing Accuracy for {}: {:.2f}'.format(annotator, total_accuracy_test/len(test_dl)))\n",
        "\n",
        "print('Testing Completed')\n"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicting labels for 1,472 test sentences...\n",
            "Testing Accuracy: 0.87\n",
            "Testing Completed\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}