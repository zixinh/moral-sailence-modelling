{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT_FC.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f95ab9cd641547979771a8224f06877b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_18d988cc4e5e401ba6294d8d59907224",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_50c11fe944aa4a7bb022809a2218d7ce",
              "IPY_MODEL_86f6a69039224dc79d1bfd27146821a0"
            ]
          }
        },
        "18d988cc4e5e401ba6294d8d59907224": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "50c11fe944aa4a7bb022809a2218d7ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_3a84da7586744669b4333345ac5a5e7a",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3d89232f719f485ba3b2768e01d32610"
          }
        },
        "86f6a69039224dc79d1bfd27146821a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_dbfc96cc9c2441c7b5e5176547d51b0d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 337kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_36351d1ac0f9453a89825e8a6ceff34f"
          }
        },
        "3a84da7586744669b4333345ac5a5e7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3d89232f719f485ba3b2768e01d32610": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dbfc96cc9c2441c7b5e5176547d51b0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "36351d1ac0f9453a89825e8a6ceff34f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PbrIqkb7q0ny",
        "colab_type": "text"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jU7fYjAllVwQ",
        "colab_type": "code",
        "outputId": "b13c93ea-97bb-43a9-d098-02b9b17b5b0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 666
        }
      },
      "source": [
        "# install transformers package from Hugging Face transformers package contains \n",
        "# pre-trained BERT model and other useful interfaces\n",
        "!pip install transformers "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/a0/32e3a4501ef480f7ea01aac329a716132f32f7911ef1c2fac228acc57ca7/transformers-2.6.0-py3-none-any.whl (540kB)\n",
            "\r\u001b[K     |▋                               | 10kB 29.7MB/s eta 0:00:01\r\u001b[K     |█▏                              | 20kB 34.9MB/s eta 0:00:01\r\u001b[K     |█▉                              | 30kB 39.4MB/s eta 0:00:01\r\u001b[K     |██▍                             | 40kB 40.5MB/s eta 0:00:01\r\u001b[K     |███                             | 51kB 31.8MB/s eta 0:00:01\r\u001b[K     |███▋                            | 61kB 33.0MB/s eta 0:00:01\r\u001b[K     |████▎                           | 71kB 26.8MB/s eta 0:00:01\r\u001b[K     |████▉                           | 81kB 25.9MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 92kB 26.2MB/s eta 0:00:01\r\u001b[K     |██████                          | 102kB 25.2MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 112kB 25.2MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 122kB 25.2MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 133kB 25.2MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 143kB 25.2MB/s eta 0:00:01\r\u001b[K     |█████████                       | 153kB 25.2MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 163kB 25.2MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 174kB 25.2MB/s eta 0:00:01\r\u001b[K     |███████████                     | 184kB 25.2MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 194kB 25.2MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 204kB 25.2MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 215kB 25.2MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 225kB 25.2MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 235kB 25.2MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 245kB 25.2MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 256kB 25.2MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 266kB 25.2MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 276kB 25.2MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 286kB 25.2MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 296kB 25.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 307kB 25.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 317kB 25.2MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 327kB 25.2MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 337kB 25.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 348kB 25.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 358kB 25.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 368kB 25.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 378kB 25.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 389kB 25.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 399kB 25.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 409kB 25.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 419kB 25.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 430kB 25.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 440kB 25.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 450kB 25.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 460kB 25.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 471kB 25.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 481kB 25.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 491kB 25.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 501kB 25.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 512kB 25.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 522kB 25.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 532kB 25.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 542kB 25.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.38.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 65.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Collecting tokenizers==0.5.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/3f/73c881ea4723e43c1e9acf317cf407fab3a278daab3a69c98dcac511c04f/tokenizers-0.5.2-cp36-cp36m-manylinux1_x86_64.whl (3.7MB)\n",
            "\u001b[K     |████████████████████████████████| 3.7MB 61.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/b4/7a41d630547a4afd58143597d5a49e07bfd4c42914d8335b2a5657efc14b/sacremoses-0.0.38.tar.gz (860kB)\n",
            "\u001b[K     |████████████████████████████████| 870kB 21.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.12.26)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.5)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
            "Requirement already satisfied: botocore<1.16.0,>=1.15.26 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.15.26)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.26->boto3->transformers) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.26->boto3->transformers) (2.8.1)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.38-cp36-none-any.whl size=884628 sha256=877785d7f788d7c104497fc916ee5dcec6a38d194aa0f9fd972757160ef42717\n",
            "  Stored in directory: /root/.cache/pip/wheels/6d/ec/1a/21b8912e35e02741306f35f66c785f3afe94de754a0eaf1422\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sentencepiece, tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.38 sentencepiece-0.1.85 tokenizers-0.5.2 transformers-2.6.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8_mQkgPgasW",
        "colab_type": "code",
        "outputId": "05d2a295-b86d-4bce-8737-e703748e4c76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 114
        }
      },
      "source": [
        "# Check if Colab's GPU is available and set up the GPU device\n",
        "import tensorflow as tf\n",
        "import torch\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('GPU is available')\n",
        "else:\n",
        "    raise SystemError('No GPU device available')\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print('GPU name and type:', torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    print('No GPU available, using CPU')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will switch to TensorFlow 2.x on the 27th of March, 2020.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now\n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "GPU is available\n",
            "GPU name and type: Tesla P4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m6X5lLSVrEkj",
        "colab_type": "text"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQiDv4rylYkw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# dataset pre-processing\n",
        "# load data_extraction.ipynb\n",
        "#### TO-DO fill in tweets & labels\n",
        "\n",
        "tweets = None\n",
        "labels = None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6qFUYwuZrd4e",
        "colab_type": "text"
      },
      "source": [
        "# Training Prep"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "omQcPA7UrNVm",
        "colab_type": "text"
      },
      "source": [
        "### Input Tokenization & Encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfQNYUK2sGRO",
        "colab_type": "code",
        "outputId": "ccc139ec-6101-4016-997f-59c5fa84e3a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83,
          "referenced_widgets": [
            "f95ab9cd641547979771a8224f06877b",
            "18d988cc4e5e401ba6294d8d59907224",
            "50c11fe944aa4a7bb022809a2218d7ce",
            "86f6a69039224dc79d1bfd27146821a0",
            "3a84da7586744669b4333345ac5a5e7a",
            "3d89232f719f485ba3b2768e01d32610",
            "dbfc96cc9c2441c7b5e5176547d51b0d",
            "36351d1ac0f9453a89825e8a6ceff34f"
          ]
        }
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "\n",
        "# visualize BERT tokenization by an example\n",
        "print('Before:', tweets[0])\n",
        "print('After(words):', tokenizer.tokenize(tweets[0]))\n",
        "print('After(ids):', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(tweets[0])))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading BERT tokenizer...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f95ab9cd641547979771a8224f06877b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=231508, style=ProgressStyle(description_wid…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77-MUinHvdk9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get the maximum length of the dataset since all input instances have to have a constant length\n",
        "max_len = 0\n",
        "\n",
        "for tweet in tweets:\n",
        "    max_len = max(max_len, len(tweet))\n",
        "\n",
        "max_len += 2\n",
        "print('Max tweet length:', max_len)\n",
        "\n",
        "\n",
        "# tokenize all tweets, acquire corresponding token ids and attention masks\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "for tweet in tweets:\n",
        "    encoded_dict = tokenizer.encode_plus(tweet, \n",
        "                                         add_special_tokens=True, \n",
        "                                         max_length=max_len,\n",
        "                                         pad_to_max_length=True,\n",
        "                                         return_attention_mask=True,\n",
        "                                         return_tensors='pt'\n",
        "                                         )\n",
        "    \n",
        "\n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)\n",
        "\n",
        "# visualize tweet, tokenized ids and attention masks\n",
        "print('Original tweet: ', tweets[0])\n",
        "print('Token IDs:', input_ids[0])\n",
        "print('Attention Mask:', attention_masks[0])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5LCo4ZmmrnnA",
        "colab_type": "text"
      },
      "source": [
        "### Training & Validation Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-K9bBXNtsIqf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import TensorDataset, random_split, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "\n",
        "# training 80% validation 10% testing 10%\n",
        "train_size = int(0.8 * len(dataset))\n",
        "val_size = int(0.1 * len(dataset))\n",
        "test_size = len(dataset) - train_size - val_size\n",
        "\n",
        "print('training dataset size:', train_size)\n",
        "print('validation dataset size:', val_size)\n",
        "print('testing dataset size:', test_size)\n",
        "\n",
        "train_ds, val_ds, test_ds = random_split(dataset, [train_size, val_size, test_size])\n",
        "\n",
        "# create a dataloader\n",
        "batch_size = 32\n",
        "\n",
        "train_dl = DataLoader(train_ds, \n",
        "                      sampler=RandomSampler(train_ds), \n",
        "                      batch_size=batch_size)\n",
        "\n",
        "val_dl = DataLoader(val_ds, \n",
        "                    sampler=SequentialSampler(val_ds), \n",
        "                    batch_size=batch_size)\n",
        "\n",
        "test_dl = DataLoader(test_ds, \n",
        "                    sampler=SequentialSampler(test_ds), \n",
        "                    batch_size=batch_size)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSRiQzlJr-Sx",
        "colab_type": "text"
      },
      "source": [
        "### Model Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cxaFYgK0rnSP",
        "colab_type": "code",
        "outputId": "8287950c-12be-4df9-8327-19c82301fb0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from transformers import BertForSequenceClassification, BertConfig\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", \n",
        "                                                      num_labels=11, \n",
        "                                                      output_attentions=False, \n",
        "                                                      output_hidden_states=False)\n",
        "\n",
        "model.cuda()\n",
        "\n",
        "#visualize\n",
        "params = list(model.named_parameters())\n",
        "\n",
        "for p in params:\n",
        "    print(\"{:<60} {:>15}\".format(p[0], str(tuple(p[1].size()))))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bert.embeddings.word_embeddings.weight                          (30522, 768)\n",
            "bert.embeddings.position_embeddings.weight                        (512, 768)\n",
            "bert.embeddings.token_type_embeddings.weight                        (2, 768)\n",
            "bert.embeddings.LayerNorm.weight                                      (768,)\n",
            "bert.embeddings.LayerNorm.bias                                        (768,)\n",
            "bert.encoder.layer.0.attention.self.query.weight                  (768, 768)\n",
            "bert.encoder.layer.0.attention.self.query.bias                        (768,)\n",
            "bert.encoder.layer.0.attention.self.key.weight                    (768, 768)\n",
            "bert.encoder.layer.0.attention.self.key.bias                          (768,)\n",
            "bert.encoder.layer.0.attention.self.value.weight                  (768, 768)\n",
            "bert.encoder.layer.0.attention.self.value.bias                        (768,)\n",
            "bert.encoder.layer.0.attention.output.dense.weight                (768, 768)\n",
            "bert.encoder.layer.0.attention.output.dense.bias                      (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.weight                (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.bias                  (768,)\n",
            "bert.encoder.layer.0.intermediate.dense.weight                   (3072, 768)\n",
            "bert.encoder.layer.0.intermediate.dense.bias                         (3072,)\n",
            "bert.encoder.layer.0.output.dense.weight                         (768, 3072)\n",
            "bert.encoder.layer.0.output.dense.bias                                (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.weight                          (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.bias                            (768,)\n",
            "bert.encoder.layer.1.attention.self.query.weight                  (768, 768)\n",
            "bert.encoder.layer.1.attention.self.query.bias                        (768,)\n",
            "bert.encoder.layer.1.attention.self.key.weight                    (768, 768)\n",
            "bert.encoder.layer.1.attention.self.key.bias                          (768,)\n",
            "bert.encoder.layer.1.attention.self.value.weight                  (768, 768)\n",
            "bert.encoder.layer.1.attention.self.value.bias                        (768,)\n",
            "bert.encoder.layer.1.attention.output.dense.weight                (768, 768)\n",
            "bert.encoder.layer.1.attention.output.dense.bias                      (768,)\n",
            "bert.encoder.layer.1.attention.output.LayerNorm.weight                (768,)\n",
            "bert.encoder.layer.1.attention.output.LayerNorm.bias                  (768,)\n",
            "bert.encoder.layer.1.intermediate.dense.weight                   (3072, 768)\n",
            "bert.encoder.layer.1.intermediate.dense.bias                         (3072,)\n",
            "bert.encoder.layer.1.output.dense.weight                         (768, 3072)\n",
            "bert.encoder.layer.1.output.dense.bias                                (768,)\n",
            "bert.encoder.layer.1.output.LayerNorm.weight                          (768,)\n",
            "bert.encoder.layer.1.output.LayerNorm.bias                            (768,)\n",
            "bert.encoder.layer.2.attention.self.query.weight                  (768, 768)\n",
            "bert.encoder.layer.2.attention.self.query.bias                        (768,)\n",
            "bert.encoder.layer.2.attention.self.key.weight                    (768, 768)\n",
            "bert.encoder.layer.2.attention.self.key.bias                          (768,)\n",
            "bert.encoder.layer.2.attention.self.value.weight                  (768, 768)\n",
            "bert.encoder.layer.2.attention.self.value.bias                        (768,)\n",
            "bert.encoder.layer.2.attention.output.dense.weight                (768, 768)\n",
            "bert.encoder.layer.2.attention.output.dense.bias                      (768,)\n",
            "bert.encoder.layer.2.attention.output.LayerNorm.weight                (768,)\n",
            "bert.encoder.layer.2.attention.output.LayerNorm.bias                  (768,)\n",
            "bert.encoder.layer.2.intermediate.dense.weight                   (3072, 768)\n",
            "bert.encoder.layer.2.intermediate.dense.bias                         (3072,)\n",
            "bert.encoder.layer.2.output.dense.weight                         (768, 3072)\n",
            "bert.encoder.layer.2.output.dense.bias                                (768,)\n",
            "bert.encoder.layer.2.output.LayerNorm.weight                          (768,)\n",
            "bert.encoder.layer.2.output.LayerNorm.bias                            (768,)\n",
            "bert.encoder.layer.3.attention.self.query.weight                  (768, 768)\n",
            "bert.encoder.layer.3.attention.self.query.bias                        (768,)\n",
            "bert.encoder.layer.3.attention.self.key.weight                    (768, 768)\n",
            "bert.encoder.layer.3.attention.self.key.bias                          (768,)\n",
            "bert.encoder.layer.3.attention.self.value.weight                  (768, 768)\n",
            "bert.encoder.layer.3.attention.self.value.bias                        (768,)\n",
            "bert.encoder.layer.3.attention.output.dense.weight                (768, 768)\n",
            "bert.encoder.layer.3.attention.output.dense.bias                      (768,)\n",
            "bert.encoder.layer.3.attention.output.LayerNorm.weight                (768,)\n",
            "bert.encoder.layer.3.attention.output.LayerNorm.bias                  (768,)\n",
            "bert.encoder.layer.3.intermediate.dense.weight                   (3072, 768)\n",
            "bert.encoder.layer.3.intermediate.dense.bias                         (3072,)\n",
            "bert.encoder.layer.3.output.dense.weight                         (768, 3072)\n",
            "bert.encoder.layer.3.output.dense.bias                                (768,)\n",
            "bert.encoder.layer.3.output.LayerNorm.weight                          (768,)\n",
            "bert.encoder.layer.3.output.LayerNorm.bias                            (768,)\n",
            "bert.encoder.layer.4.attention.self.query.weight                  (768, 768)\n",
            "bert.encoder.layer.4.attention.self.query.bias                        (768,)\n",
            "bert.encoder.layer.4.attention.self.key.weight                    (768, 768)\n",
            "bert.encoder.layer.4.attention.self.key.bias                          (768,)\n",
            "bert.encoder.layer.4.attention.self.value.weight                  (768, 768)\n",
            "bert.encoder.layer.4.attention.self.value.bias                        (768,)\n",
            "bert.encoder.layer.4.attention.output.dense.weight                (768, 768)\n",
            "bert.encoder.layer.4.attention.output.dense.bias                      (768,)\n",
            "bert.encoder.layer.4.attention.output.LayerNorm.weight                (768,)\n",
            "bert.encoder.layer.4.attention.output.LayerNorm.bias                  (768,)\n",
            "bert.encoder.layer.4.intermediate.dense.weight                   (3072, 768)\n",
            "bert.encoder.layer.4.intermediate.dense.bias                         (3072,)\n",
            "bert.encoder.layer.4.output.dense.weight                         (768, 3072)\n",
            "bert.encoder.layer.4.output.dense.bias                                (768,)\n",
            "bert.encoder.layer.4.output.LayerNorm.weight                          (768,)\n",
            "bert.encoder.layer.4.output.LayerNorm.bias                            (768,)\n",
            "bert.encoder.layer.5.attention.self.query.weight                  (768, 768)\n",
            "bert.encoder.layer.5.attention.self.query.bias                        (768,)\n",
            "bert.encoder.layer.5.attention.self.key.weight                    (768, 768)\n",
            "bert.encoder.layer.5.attention.self.key.bias                          (768,)\n",
            "bert.encoder.layer.5.attention.self.value.weight                  (768, 768)\n",
            "bert.encoder.layer.5.attention.self.value.bias                        (768,)\n",
            "bert.encoder.layer.5.attention.output.dense.weight                (768, 768)\n",
            "bert.encoder.layer.5.attention.output.dense.bias                      (768,)\n",
            "bert.encoder.layer.5.attention.output.LayerNorm.weight                (768,)\n",
            "bert.encoder.layer.5.attention.output.LayerNorm.bias                  (768,)\n",
            "bert.encoder.layer.5.intermediate.dense.weight                   (3072, 768)\n",
            "bert.encoder.layer.5.intermediate.dense.bias                         (3072,)\n",
            "bert.encoder.layer.5.output.dense.weight                         (768, 3072)\n",
            "bert.encoder.layer.5.output.dense.bias                                (768,)\n",
            "bert.encoder.layer.5.output.LayerNorm.weight                          (768,)\n",
            "bert.encoder.layer.5.output.LayerNorm.bias                            (768,)\n",
            "bert.encoder.layer.6.attention.self.query.weight                  (768, 768)\n",
            "bert.encoder.layer.6.attention.self.query.bias                        (768,)\n",
            "bert.encoder.layer.6.attention.self.key.weight                    (768, 768)\n",
            "bert.encoder.layer.6.attention.self.key.bias                          (768,)\n",
            "bert.encoder.layer.6.attention.self.value.weight                  (768, 768)\n",
            "bert.encoder.layer.6.attention.self.value.bias                        (768,)\n",
            "bert.encoder.layer.6.attention.output.dense.weight                (768, 768)\n",
            "bert.encoder.layer.6.attention.output.dense.bias                      (768,)\n",
            "bert.encoder.layer.6.attention.output.LayerNorm.weight                (768,)\n",
            "bert.encoder.layer.6.attention.output.LayerNorm.bias                  (768,)\n",
            "bert.encoder.layer.6.intermediate.dense.weight                   (3072, 768)\n",
            "bert.encoder.layer.6.intermediate.dense.bias                         (3072,)\n",
            "bert.encoder.layer.6.output.dense.weight                         (768, 3072)\n",
            "bert.encoder.layer.6.output.dense.bias                                (768,)\n",
            "bert.encoder.layer.6.output.LayerNorm.weight                          (768,)\n",
            "bert.encoder.layer.6.output.LayerNorm.bias                            (768,)\n",
            "bert.encoder.layer.7.attention.self.query.weight                  (768, 768)\n",
            "bert.encoder.layer.7.attention.self.query.bias                        (768,)\n",
            "bert.encoder.layer.7.attention.self.key.weight                    (768, 768)\n",
            "bert.encoder.layer.7.attention.self.key.bias                          (768,)\n",
            "bert.encoder.layer.7.attention.self.value.weight                  (768, 768)\n",
            "bert.encoder.layer.7.attention.self.value.bias                        (768,)\n",
            "bert.encoder.layer.7.attention.output.dense.weight                (768, 768)\n",
            "bert.encoder.layer.7.attention.output.dense.bias                      (768,)\n",
            "bert.encoder.layer.7.attention.output.LayerNorm.weight                (768,)\n",
            "bert.encoder.layer.7.attention.output.LayerNorm.bias                  (768,)\n",
            "bert.encoder.layer.7.intermediate.dense.weight                   (3072, 768)\n",
            "bert.encoder.layer.7.intermediate.dense.bias                         (3072,)\n",
            "bert.encoder.layer.7.output.dense.weight                         (768, 3072)\n",
            "bert.encoder.layer.7.output.dense.bias                                (768,)\n",
            "bert.encoder.layer.7.output.LayerNorm.weight                          (768,)\n",
            "bert.encoder.layer.7.output.LayerNorm.bias                            (768,)\n",
            "bert.encoder.layer.8.attention.self.query.weight                  (768, 768)\n",
            "bert.encoder.layer.8.attention.self.query.bias                        (768,)\n",
            "bert.encoder.layer.8.attention.self.key.weight                    (768, 768)\n",
            "bert.encoder.layer.8.attention.self.key.bias                          (768,)\n",
            "bert.encoder.layer.8.attention.self.value.weight                  (768, 768)\n",
            "bert.encoder.layer.8.attention.self.value.bias                        (768,)\n",
            "bert.encoder.layer.8.attention.output.dense.weight                (768, 768)\n",
            "bert.encoder.layer.8.attention.output.dense.bias                      (768,)\n",
            "bert.encoder.layer.8.attention.output.LayerNorm.weight                (768,)\n",
            "bert.encoder.layer.8.attention.output.LayerNorm.bias                  (768,)\n",
            "bert.encoder.layer.8.intermediate.dense.weight                   (3072, 768)\n",
            "bert.encoder.layer.8.intermediate.dense.bias                         (3072,)\n",
            "bert.encoder.layer.8.output.dense.weight                         (768, 3072)\n",
            "bert.encoder.layer.8.output.dense.bias                                (768,)\n",
            "bert.encoder.layer.8.output.LayerNorm.weight                          (768,)\n",
            "bert.encoder.layer.8.output.LayerNorm.bias                            (768,)\n",
            "bert.encoder.layer.9.attention.self.query.weight                  (768, 768)\n",
            "bert.encoder.layer.9.attention.self.query.bias                        (768,)\n",
            "bert.encoder.layer.9.attention.self.key.weight                    (768, 768)\n",
            "bert.encoder.layer.9.attention.self.key.bias                          (768,)\n",
            "bert.encoder.layer.9.attention.self.value.weight                  (768, 768)\n",
            "bert.encoder.layer.9.attention.self.value.bias                        (768,)\n",
            "bert.encoder.layer.9.attention.output.dense.weight                (768, 768)\n",
            "bert.encoder.layer.9.attention.output.dense.bias                      (768,)\n",
            "bert.encoder.layer.9.attention.output.LayerNorm.weight                (768,)\n",
            "bert.encoder.layer.9.attention.output.LayerNorm.bias                  (768,)\n",
            "bert.encoder.layer.9.intermediate.dense.weight                   (3072, 768)\n",
            "bert.encoder.layer.9.intermediate.dense.bias                         (3072,)\n",
            "bert.encoder.layer.9.output.dense.weight                         (768, 3072)\n",
            "bert.encoder.layer.9.output.dense.bias                                (768,)\n",
            "bert.encoder.layer.9.output.LayerNorm.weight                          (768,)\n",
            "bert.encoder.layer.9.output.LayerNorm.bias                            (768,)\n",
            "bert.encoder.layer.10.attention.self.query.weight                 (768, 768)\n",
            "bert.encoder.layer.10.attention.self.query.bias                       (768,)\n",
            "bert.encoder.layer.10.attention.self.key.weight                   (768, 768)\n",
            "bert.encoder.layer.10.attention.self.key.bias                         (768,)\n",
            "bert.encoder.layer.10.attention.self.value.weight                 (768, 768)\n",
            "bert.encoder.layer.10.attention.self.value.bias                       (768,)\n",
            "bert.encoder.layer.10.attention.output.dense.weight               (768, 768)\n",
            "bert.encoder.layer.10.attention.output.dense.bias                     (768,)\n",
            "bert.encoder.layer.10.attention.output.LayerNorm.weight               (768,)\n",
            "bert.encoder.layer.10.attention.output.LayerNorm.bias                 (768,)\n",
            "bert.encoder.layer.10.intermediate.dense.weight                  (3072, 768)\n",
            "bert.encoder.layer.10.intermediate.dense.bias                        (3072,)\n",
            "bert.encoder.layer.10.output.dense.weight                        (768, 3072)\n",
            "bert.encoder.layer.10.output.dense.bias                               (768,)\n",
            "bert.encoder.layer.10.output.LayerNorm.weight                         (768,)\n",
            "bert.encoder.layer.10.output.LayerNorm.bias                           (768,)\n",
            "bert.encoder.layer.11.attention.self.query.weight                 (768, 768)\n",
            "bert.encoder.layer.11.attention.self.query.bias                       (768,)\n",
            "bert.encoder.layer.11.attention.self.key.weight                   (768, 768)\n",
            "bert.encoder.layer.11.attention.self.key.bias                         (768,)\n",
            "bert.encoder.layer.11.attention.self.value.weight                 (768, 768)\n",
            "bert.encoder.layer.11.attention.self.value.bias                       (768,)\n",
            "bert.encoder.layer.11.attention.output.dense.weight               (768, 768)\n",
            "bert.encoder.layer.11.attention.output.dense.bias                     (768,)\n",
            "bert.encoder.layer.11.attention.output.LayerNorm.weight               (768,)\n",
            "bert.encoder.layer.11.attention.output.LayerNorm.bias                 (768,)\n",
            "bert.encoder.layer.11.intermediate.dense.weight                  (3072, 768)\n",
            "bert.encoder.layer.11.intermediate.dense.bias                        (3072,)\n",
            "bert.encoder.layer.11.output.dense.weight                        (768, 3072)\n",
            "bert.encoder.layer.11.output.dense.bias                               (768,)\n",
            "bert.encoder.layer.11.output.LayerNorm.weight                         (768,)\n",
            "bert.encoder.layer.11.output.LayerNorm.bias                           (768,)\n",
            "bert.pooler.dense.weight                                          (768, 768)\n",
            "bert.pooler.dense.bias                                                (768,)\n",
            "classifier.weight                                                  (11, 768)\n",
            "classifier.bias                                                        (11,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tpcl1aBYaD6y",
        "colab_type": "text"
      },
      "source": [
        "### Optimizer & Learning Rate Scheduler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwbBN5C3aJxb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup, AdamW\n",
        "\n",
        "# set up the optimizer\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr=2e-5,\n",
        "                  eps=1e-8)\n",
        "\n",
        "# set up the lr scheduler\n",
        "epochs = 3\n",
        "total_steps = len(train_dl) * epochs\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                            num_warmup_steps=0,\n",
        "                                            num_training_steps=total_steps)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QVHPS3_nbOM-",
        "colab_type": "text"
      },
      "source": [
        "### Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tkoALr0NbZjN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import time\n",
        "import datetime\n",
        "\n",
        "# calculate accuracy\n",
        "# TO-DO\n",
        "def get_accuracy(preds, labels):\n",
        "    return None\n",
        "\n",
        "# take a time in seconds and returns a string hh:mm:ss\n",
        "def format_time(elapsed):\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-MYO6-Fsr2cJ",
        "colab_type": "text"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RtvWruZIZSRC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "\n",
        "seed_val = 1\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "training_stats = []\n",
        "\n",
        "total_t0 = time.time() \n",
        "\n",
        "for epoch_i in range(0, epochs):\n",
        "    print(\"\")\n",
        "    print('======= Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print(\"\")\n",
        "\n",
        "    t0 = time.time()\n",
        "    total_train_loss = 0\n",
        "    model.train()\n",
        "\n",
        "    for step, batch in enumerate(train_dl):\n",
        "        # periodically update elapsed time\n",
        "        ## TO-DO, change progess update param\n",
        "        if step % 50 == 0 and not step == 0:\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "\n",
        "            print('Batch {:>5,} of {:>5,}. Elapsed: {:}.'.format(step, \n",
        "                                                                 len(train_dl), \n",
        "                                                                 elapsed))\n",
        "        # unpack current batch's input & labels   \n",
        "        cur_input_ids = batch[0].to(device)\n",
        "        cur_input_mask = batch[1].to(device)\n",
        "        cur_labels = batch[2].to(device)\n",
        "\n",
        "        # clear previously calculated gradients\n",
        "        model.zero_grad()\n",
        "\n",
        "        # perform a forward pass\n",
        "        # logits = classifications, before activation function e.x. softmax\n",
        "        loss, logits = model(cur_input_ids, \n",
        "                             token_type_ids=None,\n",
        "                             attention_mask=cur_input_mask,\n",
        "                             labels=cur_labels)\n",
        "        \n",
        "        # accumulate training loss\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        # perform a backward pass to calculate the gradients of params\n",
        "        loss.backward()\n",
        "\n",
        "        # clip the gradients if it is not in [-1,1]\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # update weights\n",
        "        optimizer.step()\n",
        "\n",
        "        # update lr\n",
        "        scheduler.step()\n",
        "\n",
        "    # calculate stats after 1 epoch of training\n",
        "    avg_train_loss = total_train_loss / len(train_dl)\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "\n",
        "    # validation \n",
        "    print(\"\")\n",
        "    print(\"Validating...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    for batch in validation_dl:\n",
        "        \n",
        "        # unpack current batch's input and labels\n",
        "        cur_input_ids = batch[0].to(device)\n",
        "        cur_input_mask = batch[1].to(device)\n",
        "        cur_labels = batch[2].to(device)\n",
        "\n",
        "        # no need to calculate and trace gradient\n",
        "        with torch.no_grad():\n",
        "            (loss, logits) = model(cur_input_ids,\n",
        "                                   token_type_ids=None,\n",
        "                                   attention_mask=cur_input_mask,\n",
        "                                   labels=cur_labels)\n",
        "                    \n",
        "        # no need to calculate prediction & labels in gpu\n",
        "        # good practice when involves with large-scale dataset\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = cur_labels.to('cpu')\n",
        "\n",
        "        # calculate this batch's accuracy & loss and accumulate with other \n",
        "        # batches' accuracies & loss\n",
        "        total_eval_accuracy += get_accuracy(logits, label_ids)\n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "    # average out loss and accuracy across all batches\n",
        "    avg_val_accuracy = total_eval_accuracy / len(validation_dl)\n",
        "    avg_val_loss = total_eval_loss / len(validation_dl)\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\n",
        "        \"Average Accuracy: {0:.2f}, Loss: {1:.2f}, Time elapsed: {2:.2f}\".format(\n",
        "            avg_val_accuracy, avg_val_loss, validation_time\n",
        "        )\n",
        "    )\n",
        "\n",
        "    # record all statistics for this epoch\n",
        "    training_stats.append({\n",
        "        'epoch': epoch_i + 1,\n",
        "        'Training Loss': avg_train_loss,\n",
        "        'Valid. Loss': avg_val_loss,\n",
        "        'Valid. Accur': avg_val_accuracy,\n",
        "        'Training Time': training_time,\n",
        "        'Validation Time': validation_time\n",
        "    })\n",
        "\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training Completed. Training took {:}\".format(format_time(time.time() - total_t0)))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Xpcd9gUwjqb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Display training stats\n",
        "from pandas as pd\n",
        "\n",
        "# Display numbers with two decimal\n",
        "pd.set_option('precision', 2)\n",
        "\n",
        "df_stats = pd.DataFrame(data=training_stats)\n",
        "df_stats = df_stats.set_index('epoch')\n",
        "\n",
        "df_stats"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0urcVvr-1Gl6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Visualize training stats\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "sns.set(style='darkgrid')\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12, 6)\n",
        "\n",
        "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
        "plt.plot(df_stats['Validation Loss'], 'g-o', label=\"Validation\")\n",
        "\n",
        "plt.title(\"Training & Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "\n",
        "### TO_DO: change epoch number\n",
        "plt.xticks([1,2,3,4])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zdKwFWsQsZ-5",
        "colab_type": "text"
      },
      "source": [
        "# Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3hvIeuts3ysN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Predicting labels for {:,} test sentences...'.format(len(test_dl)))\n",
        "\n",
        "model.eval()\n",
        "\n",
        "total_accuracy_test = 0\n",
        "\n",
        "for batch in test_dl:\n",
        "    # add batch to GPU\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "\n",
        "    cur_input_ids, cur_input_mask, cur_labels = batch\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(cur_input_ids, \n",
        "                        token_type_ids=None, \n",
        "                        attention_mask=cur_input_mask)\n",
        "    logits = outputs[0]\n",
        "\n",
        "    # Move logits and labels to CPU\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "    total_accuracy_test += get_accuracy(logits, label_ids)\n",
        "\n",
        "print('Testing Accuracy: {:.2f}'.format(total_accuracy_test/len(test_dl)))\n",
        "print('Testing Completed')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxDhqDy-se3y",
        "colab_type": "text"
      },
      "source": [
        "# Conclusion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8kHkquMmVNr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}