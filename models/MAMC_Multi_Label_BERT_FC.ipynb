{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Multi-Label-BERT_FC-MAMC.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "PbrIqkb7q0ny"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "cb4277d206d74aee869c8e84e4987a30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2e748c25237e401d849c06a1421e571b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d20056a320a64c06aafcd8765166f10e",
              "IPY_MODEL_07e23b8e39604e209cf0858ddad7531f"
            ]
          }
        },
        "2e748c25237e401d849c06a1421e571b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d20056a320a64c06aafcd8765166f10e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_84e1f62234364f8c830b71b1cebcc5f8",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_48e09559add34c118020409728bf676e"
          }
        },
        "07e23b8e39604e209cf0858ddad7531f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8276b7c76a6a49a48676bf861e4bd7b9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 254kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e48c644eb1c54c46999fdfad3b170ba5"
          }
        },
        "84e1f62234364f8c830b71b1cebcc5f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "48e09559add34c118020409728bf676e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8276b7c76a6a49a48676bf861e4bd7b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e48c644eb1c54c46999fdfad3b170ba5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "de006970aaad42f0bf0927fcb5a76f6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c2cbb53a9c374d789d2667aad5b0bd97",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_6c869030a2f0400399e722b0fe047fe4",
              "IPY_MODEL_4608d1ae4c7a4f8281dbc9c5a21128c5"
            ]
          }
        },
        "c2cbb53a9c374d789d2667aad5b0bd97": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6c869030a2f0400399e722b0fe047fe4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_71aaee4c4a854814b3c7221031cf3f16",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 361,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 361,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0f8863d183024abba379afb877db7dea"
          }
        },
        "4608d1ae4c7a4f8281dbc9c5a21128c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_378ae743900c48ad8e8e19be7d89591f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 361/361 [00:02&lt;00:00, 146B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ebd9ba4893a64f5282bfd367e127b3a0"
          }
        },
        "71aaee4c4a854814b3c7221031cf3f16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0f8863d183024abba379afb877db7dea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "378ae743900c48ad8e8e19be7d89591f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ebd9ba4893a64f5282bfd367e127b3a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9a3950dc52114bc7a12a0b45a66e1251": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8b4e7d43d03e4826a3bdd01187576308",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f17100eccd56437abb259ce2cccbba76",
              "IPY_MODEL_ea0a68edafcd4b2a8fa44d6d0be60f0e"
            ]
          }
        },
        "8b4e7d43d03e4826a3bdd01187576308": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f17100eccd56437abb259ce2cccbba76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_44b668e1b2204aaebeeb5db2ae1e68b3",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a7f28be7fe1a4f0f9dc40c5d43fdacac"
          }
        },
        "ea0a68edafcd4b2a8fa44d6d0be60f0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_25f08c73551b444b97f1139a4c454b19",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [00:40&lt;00:00, 10.8MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cfaf5ca73faa4d1599209a4df7ac1dc9"
          }
        },
        "44b668e1b2204aaebeeb5db2ae1e68b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a7f28be7fe1a4f0f9dc40c5d43fdacac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "25f08c73551b444b97f1139a4c454b19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cfaf5ca73faa4d1599209a4df7ac1dc9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PbrIqkb7q0ny",
        "colab_type": "text"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jU7fYjAllVwQ",
        "colab_type": "code",
        "outputId": "3aac704d-fa39-42a3-b7d2-a78472652c51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 683
        }
      },
      "source": [
        "# install transformers package from Hugging Face transformers package contains \n",
        "# pre-trained BERT model and other useful interfaces\n",
        "!pip install transformers "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/78/92cedda05552398352ed9784908b834ee32a0bd071a9b32de287327370b7/transformers-2.8.0-py3-none-any.whl (563kB)\n",
            "\r\u001b[K     |▋                               | 10kB 26.6MB/s eta 0:00:01\r\u001b[K     |█▏                              | 20kB 32.4MB/s eta 0:00:01\r\u001b[K     |█▊                              | 30kB 37.7MB/s eta 0:00:01\r\u001b[K     |██▎                             | 40kB 38.3MB/s eta 0:00:01\r\u001b[K     |███                             | 51kB 17.4MB/s eta 0:00:01\r\u001b[K     |███▌                            | 61kB 15.3MB/s eta 0:00:01\r\u001b[K     |████                            | 71kB 14.5MB/s eta 0:00:01\r\u001b[K     |████▋                           | 81kB 13.9MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 92kB 13.6MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 102kB 13.6MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 112kB 13.6MB/s eta 0:00:01\r\u001b[K     |███████                         | 122kB 13.6MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 133kB 13.6MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 143kB 13.6MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 153kB 13.6MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 163kB 13.6MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 174kB 13.6MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 184kB 13.6MB/s eta 0:00:01\r\u001b[K     |███████████                     | 194kB 13.6MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 204kB 13.6MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 215kB 13.6MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 225kB 13.6MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 235kB 13.6MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 245kB 13.6MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 256kB 13.6MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 266kB 13.6MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 276kB 13.6MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 286kB 13.6MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 296kB 13.6MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 307kB 13.6MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 317kB 13.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 327kB 13.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 337kB 13.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 348kB 13.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 358kB 13.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 368kB 13.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 378kB 13.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 389kB 13.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 399kB 13.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 409kB 13.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 419kB 13.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 430kB 13.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 440kB 13.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 450kB 13.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 460kB 13.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 471kB 13.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 481kB 13.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 491kB 13.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 501kB 13.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 512kB 13.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 522kB 13.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 532kB 13.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 542kB 13.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 552kB 13.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 563kB 13.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 573kB 13.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting tokenizers==0.5.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/3f/73c881ea4723e43c1e9acf317cf407fab3a278daab3a69c98dcac511c04f/tokenizers-0.5.2-cp36-cp36m-manylinux1_x86_64.whl (3.7MB)\n",
            "\u001b[K     |████████████████████████████████| 3.7MB 45.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.38.0)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 19.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.2)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/b4/7a41d630547a4afd58143597d5a49e07bfd4c42914d8335b2a5657efc14b/sacremoses-0.0.38.tar.gz (860kB)\n",
            "\u001b[K     |████████████████████████████████| 870kB 47.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.12.34)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.5)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
            "Requirement already satisfied: botocore<1.16.0,>=1.15.34 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.15.34)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.34->boto3->transformers) (2.8.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.34->boto3->transformers) (0.15.2)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.38-cp36-none-any.whl size=884628 sha256=aaaf2b64ff2801f415daf82332db5d21029693bc10387d701845a45ed8fa8b56\n",
            "  Stored in directory: /root/.cache/pip/wheels/6d/ec/1a/21b8912e35e02741306f35f66c785f3afe94de754a0eaf1422\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sentencepiece, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.38 sentencepiece-0.1.85 tokenizers-0.5.2 transformers-2.8.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8_mQkgPgasW",
        "colab_type": "code",
        "outputId": "6c02c235-1ec3-4173-d2d0-dd3c5060fffb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Check if Colab's GPU is available and set up the GPU device\n",
        "import tensorflow as tf\n",
        "import torch\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('GPU is available')\n",
        "else:\n",
        "    raise SystemError('No GPU device available')\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print('GPU name and type:', torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    print('No GPU available, using CPU')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU is available\n",
            "GPU name and type: Tesla P4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m6X5lLSVrEkj",
        "colab_type": "text"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQiDv4rylYkw",
        "colab_type": "code",
        "outputId": "9d92ac98-9f27-49e1-d2ce-82cfbaa5a585",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "# dataset pre-processing\n",
        "# load data_extraction.ipynb\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "iamc_ds = pd.read_json('iamc.json')\n",
        "tweets = []\n",
        "labels = []\n",
        "\n",
        "for annotator in iamc_ds:\n",
        "    tweets.extend(list(iamc_ds[annotator][0]))\n",
        "    labels.extend(list(iamc_ds[annotator][1]))\n",
        "\n",
        "tweets = np.array(tweets)\n",
        "labels = np.array(labels)\n",
        "\n",
        "print('example 1')\n",
        "print('tweet: ', tweets[0])\n",
        "print('label: ', labels[0])\n",
        "\n",
        "print('')\n",
        "print('example 2')\n",
        "print('tweet: ', tweets[1])\n",
        "print('label: ', labels[1])\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "example 1\n",
            "tweet:  wholeheartedli support protest ; act civil disobedi ; join !\n",
            "label:  [0 0 1 0 0 0 0 0 0 0 0]\n",
            "\n",
            "example 2\n",
            "tweet:  sandra bland situat man disrespect rest soul , peopl die everyday unjustifi matter\n",
            "label:  [0 0 0 0 1 1 0 0 0 0 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6qFUYwuZrd4e",
        "colab_type": "text"
      },
      "source": [
        "# Training Prep"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "omQcPA7UrNVm",
        "colab_type": "text"
      },
      "source": [
        "### Input Tokenization & Encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfQNYUK2sGRO",
        "colab_type": "code",
        "outputId": "98212476-c438-4177-e716-1733afa566ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134,
          "referenced_widgets": [
            "cb4277d206d74aee869c8e84e4987a30",
            "2e748c25237e401d849c06a1421e571b",
            "d20056a320a64c06aafcd8765166f10e",
            "07e23b8e39604e209cf0858ddad7531f",
            "84e1f62234364f8c830b71b1cebcc5f8",
            "48e09559add34c118020409728bf676e",
            "8276b7c76a6a49a48676bf861e4bd7b9",
            "e48c644eb1c54c46999fdfad3b170ba5"
          ]
        }
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "\n",
        "# visualize BERT tokenization by an example\n",
        "print('Before:', tweets[0])\n",
        "print('After(words):', tokenizer.tokenize(tweets[0]))\n",
        "print('After(ids):', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(tweets[0])))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading BERT tokenizer...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cb4277d206d74aee869c8e84e4987a30",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=231508, style=ProgressStyle(description_wid…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Before: wholeheartedli support protest ; act civil disobedi ; join !\n",
            "After(words): ['whole', '##hearted', '##li', 'support', 'protest', ';', 'act', 'civil', 'di', '##so', '##bed', '##i', ';', 'join', '!']\n",
            "After(ids): [2878, 27693, 3669, 2490, 6186, 1025, 2552, 2942, 4487, 6499, 8270, 2072, 1025, 3693, 999]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77-MUinHvdk9",
        "colab_type": "code",
        "outputId": "1979e6ab-40b7-477e-d927-13e750995a13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "# Get the maximum length of the dataset since all input instances have to have a constant length\n",
        "max_len = 0\n",
        "\n",
        "for tweet in tweets:\n",
        "    max_len = max(max_len, len(tweet.split()))\n",
        "\n",
        "max_len += 2\n",
        "print('Max tweet length:', max_len)\n",
        "\n",
        "\n",
        "# tokenize all tweets, acquire corresponding token ids and attention masks\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "for tweet in tweets:\n",
        "    encoded_dict = tokenizer.encode_plus(tweet, \n",
        "                                         add_special_tokens=True, \n",
        "                                         max_length=max_len,\n",
        "                                         pad_to_max_length=True,\n",
        "                                         return_attention_mask=True,\n",
        "                                         return_tensors='pt'\n",
        "                                         )\n",
        "    \n",
        "\n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels, dtype=torch.float)\n",
        "\n",
        "# visualize tweet, tokenized ids and attention masks\n",
        "print('Original tweet: ', tweets[0])\n",
        "print('Token IDs:', input_ids[0])\n",
        "print('Attention Mask:', attention_masks[0])\n",
        "print('Labels:', labels[0])\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max tweet length: 70\n",
            "Original tweet:  wholeheartedli support protest ; act civil disobedi ; join !\n",
            "Token IDs: tensor([  101,  2878, 27693,  3669,  2490,  6186,  1025,  2552,  2942,  4487,\n",
            "         6499,  8270,  2072,  1025,  3693,   999,   102,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])\n",
            "Attention Mask: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
            "Labels: tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5LCo4ZmmrnnA",
        "colab_type": "text"
      },
      "source": [
        "### Training & Validation Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-K9bBXNtsIqf",
        "colab_type": "code",
        "outputId": "f5bab699-0fc8-4dcf-8f9a-de51d7289692",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "from torch.utils.data import TensorDataset, random_split, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "\n",
        "# training 80% validation 10% testing 10%\n",
        "train_size = int(0.8 * len(dataset))\n",
        "val_size = int(0.1 * len(dataset))\n",
        "test_size = len(dataset) - train_size - val_size\n",
        "\n",
        "print('training dataset size:', train_size)\n",
        "print('validation dataset size:', val_size)\n",
        "print('testing dataset size:', test_size)\n",
        "\n",
        "train_ds, val_ds, test_ds = random_split(dataset, [train_size, val_size, test_size])\n",
        "\n",
        "# create a dataloader\n",
        "batch_size = 32\n",
        "\n",
        "train_dl = DataLoader(train_ds, \n",
        "                      sampler=RandomSampler(train_ds), \n",
        "                      batch_size=batch_size)\n",
        "\n",
        "val_dl = DataLoader(val_ds, \n",
        "                    sampler=SequentialSampler(val_ds), \n",
        "                    batch_size=batch_size)\n",
        "\n",
        "test_dl = DataLoader(test_ds, \n",
        "                    sampler=SequentialSampler(test_ds), \n",
        "                    batch_size=batch_size)\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training dataset size: 55612\n",
            "validation dataset size: 6951\n",
            "testing dataset size: 6953\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7wj3u8FVdK_",
        "colab_type": "text"
      },
      "source": [
        "### Building Multi-Label BERT Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HlviX-FpVvVT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import BertModel, BertConfig, BertPreTrainedModel\n",
        "from torch.nn import BCEWithLogitsLoss, Sigmoid\n",
        "\n",
        "class BertForMultiLabelSequenceClassification(BertPreTrainedModel):\n",
        "    \"\"\" \n",
        "    Bert for multi-label classification \n",
        "    \"\"\"\n",
        "    def __init__(self, config, num_labels=11):\n",
        "        super(BertForMultiLabelSequenceClassification, self).__init__(config)\n",
        "        self.num_labels = num_labels\n",
        "        self.bert = BertModel(config)\n",
        "        self.dropout = torch.nn.Dropout(config.hidden_dropout_prob)\n",
        "        self.classifier = torch.nn.Linear(config.hidden_size, num_labels)\n",
        "\n",
        "    \n",
        "    def forward(self, input_ids, token_type_ids=None, attention_mask=None, labels=None):\n",
        "        _, pooled_output = self.bert(input_ids, token_type_ids, attention_mask)\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "        logits = self.classifier(pooled_output)\n",
        "        \n",
        "        if labels is not None:\n",
        "            new_loss = BCEWithLogitsLoss()\n",
        "            loss = new_loss(logits.view(-1, self.num_labels), labels.view(-1, self.num_labels))\n",
        "            return loss, logits\n",
        "        else:\n",
        "            return logits"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSRiQzlJr-Sx",
        "colab_type": "text"
      },
      "source": [
        "### Model Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cxaFYgK0rnSP",
        "colab_type": "code",
        "outputId": "231072b2-2dbd-483e-89e9-db70a5f68ab7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "de006970aaad42f0bf0927fcb5a76f6a",
            "c2cbb53a9c374d789d2667aad5b0bd97",
            "6c869030a2f0400399e722b0fe047fe4",
            "4608d1ae4c7a4f8281dbc9c5a21128c5",
            "71aaee4c4a854814b3c7221031cf3f16",
            "0f8863d183024abba379afb877db7dea",
            "378ae743900c48ad8e8e19be7d89591f",
            "ebd9ba4893a64f5282bfd367e127b3a0",
            "9a3950dc52114bc7a12a0b45a66e1251",
            "8b4e7d43d03e4826a3bdd01187576308",
            "f17100eccd56437abb259ce2cccbba76",
            "ea0a68edafcd4b2a8fa44d6d0be60f0e",
            "44b668e1b2204aaebeeb5db2ae1e68b3",
            "a7f28be7fe1a4f0f9dc40c5d43fdacac",
            "25f08c73551b444b97f1139a4c454b19",
            "cfaf5ca73faa4d1599209a4df7ac1dc9"
          ]
        }
      },
      "source": [
        "model = BertForMultiLabelSequenceClassification.from_pretrained(\"bert-base-uncased\", \n",
        "                                                                 output_attentions=False, \n",
        "                                                                 output_hidden_states=False)\n",
        "\n",
        "model.cuda()\n",
        "\n",
        "#visualize\n",
        "params = list(model.named_parameters())\n",
        "\n",
        "for p in params:\n",
        "    print(\"{:<60} {:>15}\".format(p[0], str(tuple(p[1].size()))))\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "de006970aaad42f0bf0927fcb5a76f6a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=361, style=ProgressStyle(description_width=…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9a3950dc52114bc7a12a0b45a66e1251",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=440473133, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "bert.embeddings.word_embeddings.weight                          (30522, 768)\n",
            "bert.embeddings.position_embeddings.weight                        (512, 768)\n",
            "bert.embeddings.token_type_embeddings.weight                        (2, 768)\n",
            "bert.embeddings.LayerNorm.weight                                      (768,)\n",
            "bert.embeddings.LayerNorm.bias                                        (768,)\n",
            "bert.encoder.layer.0.attention.self.query.weight                  (768, 768)\n",
            "bert.encoder.layer.0.attention.self.query.bias                        (768,)\n",
            "bert.encoder.layer.0.attention.self.key.weight                    (768, 768)\n",
            "bert.encoder.layer.0.attention.self.key.bias                          (768,)\n",
            "bert.encoder.layer.0.attention.self.value.weight                  (768, 768)\n",
            "bert.encoder.layer.0.attention.self.value.bias                        (768,)\n",
            "bert.encoder.layer.0.attention.output.dense.weight                (768, 768)\n",
            "bert.encoder.layer.0.attention.output.dense.bias                      (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.weight                (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.bias                  (768,)\n",
            "bert.encoder.layer.0.intermediate.dense.weight                   (3072, 768)\n",
            "bert.encoder.layer.0.intermediate.dense.bias                         (3072,)\n",
            "bert.encoder.layer.0.output.dense.weight                         (768, 3072)\n",
            "bert.encoder.layer.0.output.dense.bias                                (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.weight                          (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.bias                            (768,)\n",
            "bert.encoder.layer.1.attention.self.query.weight                  (768, 768)\n",
            "bert.encoder.layer.1.attention.self.query.bias                        (768,)\n",
            "bert.encoder.layer.1.attention.self.key.weight                    (768, 768)\n",
            "bert.encoder.layer.1.attention.self.key.bias                          (768,)\n",
            "bert.encoder.layer.1.attention.self.value.weight                  (768, 768)\n",
            "bert.encoder.layer.1.attention.self.value.bias                        (768,)\n",
            "bert.encoder.layer.1.attention.output.dense.weight                (768, 768)\n",
            "bert.encoder.layer.1.attention.output.dense.bias                      (768,)\n",
            "bert.encoder.layer.1.attention.output.LayerNorm.weight                (768,)\n",
            "bert.encoder.layer.1.attention.output.LayerNorm.bias                  (768,)\n",
            "bert.encoder.layer.1.intermediate.dense.weight                   (3072, 768)\n",
            "bert.encoder.layer.1.intermediate.dense.bias                         (3072,)\n",
            "bert.encoder.layer.1.output.dense.weight                         (768, 3072)\n",
            "bert.encoder.layer.1.output.dense.bias                                (768,)\n",
            "bert.encoder.layer.1.output.LayerNorm.weight                          (768,)\n",
            "bert.encoder.layer.1.output.LayerNorm.bias                            (768,)\n",
            "bert.encoder.layer.2.attention.self.query.weight                  (768, 768)\n",
            "bert.encoder.layer.2.attention.self.query.bias                        (768,)\n",
            "bert.encoder.layer.2.attention.self.key.weight                    (768, 768)\n",
            "bert.encoder.layer.2.attention.self.key.bias                          (768,)\n",
            "bert.encoder.layer.2.attention.self.value.weight                  (768, 768)\n",
            "bert.encoder.layer.2.attention.self.value.bias                        (768,)\n",
            "bert.encoder.layer.2.attention.output.dense.weight                (768, 768)\n",
            "bert.encoder.layer.2.attention.output.dense.bias                      (768,)\n",
            "bert.encoder.layer.2.attention.output.LayerNorm.weight                (768,)\n",
            "bert.encoder.layer.2.attention.output.LayerNorm.bias                  (768,)\n",
            "bert.encoder.layer.2.intermediate.dense.weight                   (3072, 768)\n",
            "bert.encoder.layer.2.intermediate.dense.bias                         (3072,)\n",
            "bert.encoder.layer.2.output.dense.weight                         (768, 3072)\n",
            "bert.encoder.layer.2.output.dense.bias                                (768,)\n",
            "bert.encoder.layer.2.output.LayerNorm.weight                          (768,)\n",
            "bert.encoder.layer.2.output.LayerNorm.bias                            (768,)\n",
            "bert.encoder.layer.3.attention.self.query.weight                  (768, 768)\n",
            "bert.encoder.layer.3.attention.self.query.bias                        (768,)\n",
            "bert.encoder.layer.3.attention.self.key.weight                    (768, 768)\n",
            "bert.encoder.layer.3.attention.self.key.bias                          (768,)\n",
            "bert.encoder.layer.3.attention.self.value.weight                  (768, 768)\n",
            "bert.encoder.layer.3.attention.self.value.bias                        (768,)\n",
            "bert.encoder.layer.3.attention.output.dense.weight                (768, 768)\n",
            "bert.encoder.layer.3.attention.output.dense.bias                      (768,)\n",
            "bert.encoder.layer.3.attention.output.LayerNorm.weight                (768,)\n",
            "bert.encoder.layer.3.attention.output.LayerNorm.bias                  (768,)\n",
            "bert.encoder.layer.3.intermediate.dense.weight                   (3072, 768)\n",
            "bert.encoder.layer.3.intermediate.dense.bias                         (3072,)\n",
            "bert.encoder.layer.3.output.dense.weight                         (768, 3072)\n",
            "bert.encoder.layer.3.output.dense.bias                                (768,)\n",
            "bert.encoder.layer.3.output.LayerNorm.weight                          (768,)\n",
            "bert.encoder.layer.3.output.LayerNorm.bias                            (768,)\n",
            "bert.encoder.layer.4.attention.self.query.weight                  (768, 768)\n",
            "bert.encoder.layer.4.attention.self.query.bias                        (768,)\n",
            "bert.encoder.layer.4.attention.self.key.weight                    (768, 768)\n",
            "bert.encoder.layer.4.attention.self.key.bias                          (768,)\n",
            "bert.encoder.layer.4.attention.self.value.weight                  (768, 768)\n",
            "bert.encoder.layer.4.attention.self.value.bias                        (768,)\n",
            "bert.encoder.layer.4.attention.output.dense.weight                (768, 768)\n",
            "bert.encoder.layer.4.attention.output.dense.bias                      (768,)\n",
            "bert.encoder.layer.4.attention.output.LayerNorm.weight                (768,)\n",
            "bert.encoder.layer.4.attention.output.LayerNorm.bias                  (768,)\n",
            "bert.encoder.layer.4.intermediate.dense.weight                   (3072, 768)\n",
            "bert.encoder.layer.4.intermediate.dense.bias                         (3072,)\n",
            "bert.encoder.layer.4.output.dense.weight                         (768, 3072)\n",
            "bert.encoder.layer.4.output.dense.bias                                (768,)\n",
            "bert.encoder.layer.4.output.LayerNorm.weight                          (768,)\n",
            "bert.encoder.layer.4.output.LayerNorm.bias                            (768,)\n",
            "bert.encoder.layer.5.attention.self.query.weight                  (768, 768)\n",
            "bert.encoder.layer.5.attention.self.query.bias                        (768,)\n",
            "bert.encoder.layer.5.attention.self.key.weight                    (768, 768)\n",
            "bert.encoder.layer.5.attention.self.key.bias                          (768,)\n",
            "bert.encoder.layer.5.attention.self.value.weight                  (768, 768)\n",
            "bert.encoder.layer.5.attention.self.value.bias                        (768,)\n",
            "bert.encoder.layer.5.attention.output.dense.weight                (768, 768)\n",
            "bert.encoder.layer.5.attention.output.dense.bias                      (768,)\n",
            "bert.encoder.layer.5.attention.output.LayerNorm.weight                (768,)\n",
            "bert.encoder.layer.5.attention.output.LayerNorm.bias                  (768,)\n",
            "bert.encoder.layer.5.intermediate.dense.weight                   (3072, 768)\n",
            "bert.encoder.layer.5.intermediate.dense.bias                         (3072,)\n",
            "bert.encoder.layer.5.output.dense.weight                         (768, 3072)\n",
            "bert.encoder.layer.5.output.dense.bias                                (768,)\n",
            "bert.encoder.layer.5.output.LayerNorm.weight                          (768,)\n",
            "bert.encoder.layer.5.output.LayerNorm.bias                            (768,)\n",
            "bert.encoder.layer.6.attention.self.query.weight                  (768, 768)\n",
            "bert.encoder.layer.6.attention.self.query.bias                        (768,)\n",
            "bert.encoder.layer.6.attention.self.key.weight                    (768, 768)\n",
            "bert.encoder.layer.6.attention.self.key.bias                          (768,)\n",
            "bert.encoder.layer.6.attention.self.value.weight                  (768, 768)\n",
            "bert.encoder.layer.6.attention.self.value.bias                        (768,)\n",
            "bert.encoder.layer.6.attention.output.dense.weight                (768, 768)\n",
            "bert.encoder.layer.6.attention.output.dense.bias                      (768,)\n",
            "bert.encoder.layer.6.attention.output.LayerNorm.weight                (768,)\n",
            "bert.encoder.layer.6.attention.output.LayerNorm.bias                  (768,)\n",
            "bert.encoder.layer.6.intermediate.dense.weight                   (3072, 768)\n",
            "bert.encoder.layer.6.intermediate.dense.bias                         (3072,)\n",
            "bert.encoder.layer.6.output.dense.weight                         (768, 3072)\n",
            "bert.encoder.layer.6.output.dense.bias                                (768,)\n",
            "bert.encoder.layer.6.output.LayerNorm.weight                          (768,)\n",
            "bert.encoder.layer.6.output.LayerNorm.bias                            (768,)\n",
            "bert.encoder.layer.7.attention.self.query.weight                  (768, 768)\n",
            "bert.encoder.layer.7.attention.self.query.bias                        (768,)\n",
            "bert.encoder.layer.7.attention.self.key.weight                    (768, 768)\n",
            "bert.encoder.layer.7.attention.self.key.bias                          (768,)\n",
            "bert.encoder.layer.7.attention.self.value.weight                  (768, 768)\n",
            "bert.encoder.layer.7.attention.self.value.bias                        (768,)\n",
            "bert.encoder.layer.7.attention.output.dense.weight                (768, 768)\n",
            "bert.encoder.layer.7.attention.output.dense.bias                      (768,)\n",
            "bert.encoder.layer.7.attention.output.LayerNorm.weight                (768,)\n",
            "bert.encoder.layer.7.attention.output.LayerNorm.bias                  (768,)\n",
            "bert.encoder.layer.7.intermediate.dense.weight                   (3072, 768)\n",
            "bert.encoder.layer.7.intermediate.dense.bias                         (3072,)\n",
            "bert.encoder.layer.7.output.dense.weight                         (768, 3072)\n",
            "bert.encoder.layer.7.output.dense.bias                                (768,)\n",
            "bert.encoder.layer.7.output.LayerNorm.weight                          (768,)\n",
            "bert.encoder.layer.7.output.LayerNorm.bias                            (768,)\n",
            "bert.encoder.layer.8.attention.self.query.weight                  (768, 768)\n",
            "bert.encoder.layer.8.attention.self.query.bias                        (768,)\n",
            "bert.encoder.layer.8.attention.self.key.weight                    (768, 768)\n",
            "bert.encoder.layer.8.attention.self.key.bias                          (768,)\n",
            "bert.encoder.layer.8.attention.self.value.weight                  (768, 768)\n",
            "bert.encoder.layer.8.attention.self.value.bias                        (768,)\n",
            "bert.encoder.layer.8.attention.output.dense.weight                (768, 768)\n",
            "bert.encoder.layer.8.attention.output.dense.bias                      (768,)\n",
            "bert.encoder.layer.8.attention.output.LayerNorm.weight                (768,)\n",
            "bert.encoder.layer.8.attention.output.LayerNorm.bias                  (768,)\n",
            "bert.encoder.layer.8.intermediate.dense.weight                   (3072, 768)\n",
            "bert.encoder.layer.8.intermediate.dense.bias                         (3072,)\n",
            "bert.encoder.layer.8.output.dense.weight                         (768, 3072)\n",
            "bert.encoder.layer.8.output.dense.bias                                (768,)\n",
            "bert.encoder.layer.8.output.LayerNorm.weight                          (768,)\n",
            "bert.encoder.layer.8.output.LayerNorm.bias                            (768,)\n",
            "bert.encoder.layer.9.attention.self.query.weight                  (768, 768)\n",
            "bert.encoder.layer.9.attention.self.query.bias                        (768,)\n",
            "bert.encoder.layer.9.attention.self.key.weight                    (768, 768)\n",
            "bert.encoder.layer.9.attention.self.key.bias                          (768,)\n",
            "bert.encoder.layer.9.attention.self.value.weight                  (768, 768)\n",
            "bert.encoder.layer.9.attention.self.value.bias                        (768,)\n",
            "bert.encoder.layer.9.attention.output.dense.weight                (768, 768)\n",
            "bert.encoder.layer.9.attention.output.dense.bias                      (768,)\n",
            "bert.encoder.layer.9.attention.output.LayerNorm.weight                (768,)\n",
            "bert.encoder.layer.9.attention.output.LayerNorm.bias                  (768,)\n",
            "bert.encoder.layer.9.intermediate.dense.weight                   (3072, 768)\n",
            "bert.encoder.layer.9.intermediate.dense.bias                         (3072,)\n",
            "bert.encoder.layer.9.output.dense.weight                         (768, 3072)\n",
            "bert.encoder.layer.9.output.dense.bias                                (768,)\n",
            "bert.encoder.layer.9.output.LayerNorm.weight                          (768,)\n",
            "bert.encoder.layer.9.output.LayerNorm.bias                            (768,)\n",
            "bert.encoder.layer.10.attention.self.query.weight                 (768, 768)\n",
            "bert.encoder.layer.10.attention.self.query.bias                       (768,)\n",
            "bert.encoder.layer.10.attention.self.key.weight                   (768, 768)\n",
            "bert.encoder.layer.10.attention.self.key.bias                         (768,)\n",
            "bert.encoder.layer.10.attention.self.value.weight                 (768, 768)\n",
            "bert.encoder.layer.10.attention.self.value.bias                       (768,)\n",
            "bert.encoder.layer.10.attention.output.dense.weight               (768, 768)\n",
            "bert.encoder.layer.10.attention.output.dense.bias                     (768,)\n",
            "bert.encoder.layer.10.attention.output.LayerNorm.weight               (768,)\n",
            "bert.encoder.layer.10.attention.output.LayerNorm.bias                 (768,)\n",
            "bert.encoder.layer.10.intermediate.dense.weight                  (3072, 768)\n",
            "bert.encoder.layer.10.intermediate.dense.bias                        (3072,)\n",
            "bert.encoder.layer.10.output.dense.weight                        (768, 3072)\n",
            "bert.encoder.layer.10.output.dense.bias                               (768,)\n",
            "bert.encoder.layer.10.output.LayerNorm.weight                         (768,)\n",
            "bert.encoder.layer.10.output.LayerNorm.bias                           (768,)\n",
            "bert.encoder.layer.11.attention.self.query.weight                 (768, 768)\n",
            "bert.encoder.layer.11.attention.self.query.bias                       (768,)\n",
            "bert.encoder.layer.11.attention.self.key.weight                   (768, 768)\n",
            "bert.encoder.layer.11.attention.self.key.bias                         (768,)\n",
            "bert.encoder.layer.11.attention.self.value.weight                 (768, 768)\n",
            "bert.encoder.layer.11.attention.self.value.bias                       (768,)\n",
            "bert.encoder.layer.11.attention.output.dense.weight               (768, 768)\n",
            "bert.encoder.layer.11.attention.output.dense.bias                     (768,)\n",
            "bert.encoder.layer.11.attention.output.LayerNorm.weight               (768,)\n",
            "bert.encoder.layer.11.attention.output.LayerNorm.bias                 (768,)\n",
            "bert.encoder.layer.11.intermediate.dense.weight                  (3072, 768)\n",
            "bert.encoder.layer.11.intermediate.dense.bias                        (3072,)\n",
            "bert.encoder.layer.11.output.dense.weight                        (768, 3072)\n",
            "bert.encoder.layer.11.output.dense.bias                               (768,)\n",
            "bert.encoder.layer.11.output.LayerNorm.weight                         (768,)\n",
            "bert.encoder.layer.11.output.LayerNorm.bias                           (768,)\n",
            "bert.pooler.dense.weight                                          (768, 768)\n",
            "bert.pooler.dense.bias                                                (768,)\n",
            "classifier.weight                                                  (11, 768)\n",
            "classifier.bias                                                        (11,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tpcl1aBYaD6y",
        "colab_type": "text"
      },
      "source": [
        "### Optimizer & Learning Rate Scheduler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwbBN5C3aJxb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup, AdamW\n",
        "\n",
        "# set up the optimizer\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr=2e-5,\n",
        "                  eps=1e-8)\n",
        "\n",
        "# set up the lr scheduler\n",
        "epochs = 3\n",
        "total_steps = len(train_dl) * epochs\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                            num_warmup_steps=0,\n",
        "                                            num_training_steps=total_steps)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QVHPS3_nbOM-",
        "colab_type": "text"
      },
      "source": [
        "### Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tkoALr0NbZjN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "from sklearn.metrics import hamming_loss, accuracy_score\n",
        "\n",
        "def get_accuracy_hamming_loss(preds, labels):\n",
        "    preds = preds >= 0.5\n",
        "\n",
        "    return 1 - hamming_loss(preds, labels)\n",
        "\n",
        "def get_accuracy_exact_match(preds, labels):\n",
        "    preds = preds >= 0.5\n",
        "\n",
        "    return accuracy_score(preds, labels)\n",
        "\n",
        "# correct labels out of cases where prediction and labels are not both 0\n",
        "def get_accuracy_none_zero(preds, labels):\n",
        "    preds = preds >= 0.5\n",
        "\n",
        "    total = []\n",
        "    for i in range(len(preds)):\n",
        "        suM = 0\n",
        "        for j in range(len(preds[i])):\n",
        "            correct = 0\n",
        "            #correct\n",
        "            if preds[i][j] == 1 and labels[i][j]== 1 :\n",
        "                suM += 1\n",
        "                correct += 1\n",
        "            #missed \n",
        "            elif labels[i][j]== 1 and preds[i][j] == 0:\n",
        "                suM += 1\n",
        "            elif labels[i][j]== 0 and preds[i][j] == 1:\n",
        "                suM += 1\n",
        "        \n",
        "        if suM != 0:\n",
        "            total.append(correct/suM)\n",
        "\n",
        "    return np.mean(total)\n",
        "                \n",
        "\n",
        "# take a time in seconds and returns a string hh:mm:ss\n",
        "def format_time(elapsed):\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-MYO6-Fsr2cJ",
        "colab_type": "text"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RtvWruZIZSRC",
        "colab_type": "code",
        "outputId": "ee3377ef-cc2c-4954-f879-53df674cae55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        }
      },
      "source": [
        "import random\n",
        "\n",
        "seed_val = 1\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "training_stats = []\n",
        "\n",
        "total_t0 = time.time() \n",
        "\n",
        "# initialize BERT weights\n",
        "model.init_weights()\n",
        "\n",
        "for epoch_i in range(0, epochs):\n",
        "    print(\"\")\n",
        "    print('======= Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print(\"\")\n",
        "\n",
        "    t0 = time.time()\n",
        "    total_train_loss = 0\n",
        "    model.train()\n",
        "\n",
        "    for step, batch in enumerate(train_dl):\n",
        "        # periodically update elapsed time\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "\n",
        "            print('Batch {:>5,} of {:>5,}. Elapsed: {:}.'.format(step, \n",
        "                                                                 len(train_dl), \n",
        "                                                                 elapsed))\n",
        "        # unpack current batch's input & labels   \n",
        "        cur_input_ids = batch[0].to(device)\n",
        "        cur_input_mask = batch[1].to(device)\n",
        "        cur_labels = batch[2].to(device)\n",
        "\n",
        "        # clear previously calculated gradients\n",
        "        model.zero_grad()\n",
        "\n",
        "        # perform a forward pass\n",
        "        # logits = classifications, before activation function e.x. softmax\n",
        "        loss, logits = model(cur_input_ids, \n",
        "                             token_type_ids=None,\n",
        "                             attention_mask=cur_input_mask,\n",
        "                             labels=cur_labels)\n",
        "                \n",
        "        # accumulate training loss\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        # perform a backward pass to calculate the gradients of params\n",
        "        loss.backward()\n",
        "\n",
        "        # clip the gradients if it is not in [-1,1]\n",
        "        # torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # update weights\n",
        "        optimizer.step()\n",
        "\n",
        "        # update lr\n",
        "        scheduler.step()\n",
        "\n",
        "    # calculate stats after 1 epoch of training\n",
        "    avg_train_loss = total_train_loss / len(train_dl)\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "\n",
        "    # validation \n",
        "    print(\"\")\n",
        "    print(\"Validating...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    total_eval_accuracy_hamming_loss = 0\n",
        "    total_eval_accuracy_exact_match = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    for batch in val_dl:\n",
        "        \n",
        "        # unpack current batch's input and labels\n",
        "        cur_input_ids = batch[0].to(device)\n",
        "        cur_input_mask = batch[1].to(device)\n",
        "        cur_labels = batch[2].to(device)\n",
        "\n",
        "        # no need to calculate and trace gradient\n",
        "        with torch.no_grad():\n",
        "            loss, logits = model(cur_input_ids,\n",
        "                                   token_type_ids=None,\n",
        "                                   attention_mask=cur_input_mask,\n",
        "                                   labels=cur_labels)\n",
        "                    \n",
        "        # no need to calculate prediction & labels in gpu\n",
        "        # good practice when involves with large-scale dataset\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = cur_labels.to('cpu')\n",
        "        \n",
        "        # calculate this batch's accuracy & loss and accumulate with other \n",
        "        # batches' accuracies & loss\n",
        "        total_eval_accuracy_hamming_loss += get_accuracy_hamming_loss(logits, label_ids)\n",
        "        total_eval_accuracy_exact_match += get_accuracy_exact_match(logits, label_ids)\n",
        "        \n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "    # average out loss and accuracy across all batches\n",
        "    avg_val_accuracy_hamming_loss = total_eval_accuracy_hamming_loss / len(val_dl)\n",
        "    avg_val_accuracy_exact_match = total_eval_accuracy_exact_match / len(val_dl)\n",
        "    avg_val_loss = total_eval_loss / len(val_dl)\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"Loss: {0:.2f}, Time elapsed: {1:}\".format(avg_val_loss, validation_time))\n",
        "    print(\"==== Accuracy ====\")\n",
        "    print(\"Hamming Loss:\", avg_val_accuracy_hamming_loss)\n",
        "    print(\"Exact Match\", avg_val_accuracy_exact_match)\n",
        "\n",
        "\n",
        "    # record all statistics for this epoch\n",
        "    training_stats.append({\n",
        "        'epoch': epoch_i + 1,\n",
        "        'Training Loss': avg_train_loss,\n",
        "        'Valid. Loss': avg_val_loss,\n",
        "        'Valid. Accur': avg_val_accuracy_hamming_loss,\n",
        "        'Training Time': training_time,\n",
        "        'Validation Time': validation_time\n",
        "    })\n",
        "\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training Completed. Training took {:}\".format(format_time(time.time() - total_t0)))\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======= Epoch 1 / 3 ========\n",
            "\n",
            "Batch    40 of 1,738. Elapsed: 0:00:18.\n",
            "Batch    80 of 1,738. Elapsed: 0:00:36.\n",
            "Batch   120 of 1,738. Elapsed: 0:00:53.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-7d1edca0df00>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;31m# accumulate training loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0mtotal_train_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;31m# perform a backward pass to calculate the gradients of params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Xpcd9gUwjqb",
        "colab_type": "code",
        "outputId": "db1b2054-7f19-4245-ded4-47c2c0281113",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "# Display training stats\n",
        "# Display numbers with two decimal\n",
        "pd.set_option('precision', 2)\n",
        "\n",
        "df_stats = pd.DataFrame(data=training_stats)\n",
        "df_stats = df_stats.set_index('epoch')\n",
        "\n",
        "df_stats"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Valid. Loss</th>\n",
              "      <th>Valid. Accur</th>\n",
              "      <th>Training Time</th>\n",
              "      <th>Validation Time</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>epoch</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.69</td>\n",
              "      <td>0.69</td>\n",
              "      <td>0.87</td>\n",
              "      <td>0:01:35</td>\n",
              "      <td>0:00:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.69</td>\n",
              "      <td>0.69</td>\n",
              "      <td>0.87</td>\n",
              "      <td>0:01:35</td>\n",
              "      <td>0:00:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.69</td>\n",
              "      <td>0.69</td>\n",
              "      <td>0.87</td>\n",
              "      <td>0:01:35</td>\n",
              "      <td>0:00:03</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Training Loss  Valid. Loss  Valid. Accur Training Time Validation Time\n",
              "epoch                                                                        \n",
              "1               0.69         0.69          0.87       0:01:35         0:00:03\n",
              "2               0.69         0.69          0.87       0:01:35         0:00:03\n",
              "3               0.69         0.69          0.87       0:01:35         0:00:03"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0urcVvr-1Gl6",
        "colab_type": "code",
        "outputId": "88ffbb3c-4b5e-48b4-85c5-6c7652ef31c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        }
      },
      "source": [
        "# Visualize training stats\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "sns.set(style='darkgrid')\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12, 6)\n",
        "\n",
        "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
        "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
        "\n",
        "plt.title(\"Training & Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "\n",
        "### TO_DO: change epoch number\n",
        "plt.xticks([i + 1 for i in range(epochs)])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAw8AAAGaCAYAAABJ6H8PAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nOzdeUCU1f4/8PesMAwgwgwqoEgaS2yi\npZl+80qSmPuKVppZtC+KWnpv3rZb1+uGWtmiZWouCUIupNVVs2ua/hTTa4LXaBMRRZBlZoDZnt8f\nMI8MAzgoOmDv1z825znPM2cGG+fN+ZzzSARBEEBERERERHQVUlcPgIiIiIiI2gaGByIiIiIicgrD\nAxEREREROYXhgYiIiIiInMLwQERERERETmF4ICIiIiIipzA8EBG5WH5+PsLCwvDOO+9c8zXmzJmD\nsLCwFhzVraux9zssLAxz5sxx6hrvvPMOwsLCkJ+f3+Ljy8jIQFhYGA4dOtTi1yYiul5yVw+AiKi1\nac6X8N27dyMoKOgGjqbtMRgM+OCDD/Dll1/i4sWL8PX1Ra9evfDMM8+gW7duTl3jhRdewFdffYUv\nvvgCERERDfYRBAH33XcfysvLsX//fri7u7fky7ihDh06hMOHD+ORRx6Bt7e3q4fjID8/H/fddx8e\neugh/P3vf3f1cIioFWF4ICKqZ8GCBXaPjx49is8//xxJSUno1auX3TFfX9/rfr7AwECcOHECMpns\nmq/x5ptv4vXXX7/usbSEV155BVlZWRg2bBh69+6NoqIi7NmzB8ePH3c6PIwbNw5fffUVtmzZglde\neaXBPj/88APOnTuHpKSkFgkOJ06cgFR6cybkDx8+jHfffRejR492CA8jR47E0KFDoVAobspYiIia\ng+GBiKiekSNH2j22WCz4/PPP0aNHD4dj9el0Onh6ejbr+SQSCdzc3Jo9zrpayxfNyspK7Nq1C/37\n98fixYvF9ueeew5Go9Hp6/Tv3x+dOnXC9u3b8dJLL0GpVDr0ycjIAFATNFrC9f4MWopMJruuIElE\ndCNxzQMR0TWKj4/H5MmTcerUKTz22GPo1asXRowYAaAmRKSmpmL8+PHo06cPoqKikJCQgEWLFqGy\nstLuOg3V4Ndt27t3L8aOHYvo6Gj0798f//rXv2A2m+2u0dCaB1tbRUUFXn31VfTt2xfR0dGYOHEi\njh8/7vB6Ll++jLlz56JPnz6Ii4vDlClTcOrUKUyePBnx8fFOvScSiQQSiaTBMNNQAGiMVCrF6NGj\nUVpaij179jgc1+l0+PrrrxEaGoqYmJhmvd+NaWjNg9VqxYcffoj4+HhER0dj2LBh2LZtW4Pn5+Xl\n4bXXXsPQoUMRFxeH2NhYjBkzBmlpaXb95syZg3fffRcAcN999yEsLMzu59/YmoeSkhK8/vrrGDBg\nAKKiojBgwAC8/vrruHz5sl0/2/kHDx7Exx9/jEGDBiEqKgqDBw9GZmamU+9Fc+Tm5uLZZ59Fnz59\nEB0djQceeAArV66ExWKx63f+/HnMnTsXAwcORFRUFPr27YuJEyfajclqteLTTz/F8OHDERcXh549\ne2Lw4MH461//CpPJ1OJjJ6Lm48wDEdF1KCgowCOPPILExETcf//9MBgMAIALFy4gPT0d999/P4YN\nGwa5XI7Dhw9j1apVyMnJwccff+zU9fft24cNGzZg4sSJGDt2LHbv3o1PPvkE7dq1w1NPPeXUNR57\n7DH4+vri2WefRWlpKVavXo0nnngCu3fvFmdJjEYjHn30UeTk5GDMmDGIjo7G6dOn8eijj6Jdu3ZO\nvx/u7u4YNWoUtmzZgh07dmDYsGFOn1vfmDFj8P777yMjIwOJiYl2x7KyslBVVYWxY8cCaLn3u75/\n/vOfWLt2Le666y5MnToVxcXFeOONN9C5c2eHvocPH8aRI0fwl7/8BUFBQeIszCuvvIKSkhI8+eST\nAICkpCTodDp88803mDt3Ltq3bw+g6bU2FRUVmDRpEn7//XeMHTsWd9xxB3JycrBx40b88MMPSEtL\nc5jxSk1NRVVVFZKSkqBUKrFx40bMmTMHXbp0cSi/u1b//e9/MXnyZMjlcjz00EPQaDTYu3cvFi1a\nhNzcXHH2yWw249FHH8WFCxfw4IMPomvXrtDpdDh9+jSOHDmC0aNHAwDef/99LF++HAMHDsTEiRMh\nk8mQn5+PPXv2wGg0tpoZNqI/NYGIiJq0ZcsWITQ0VNiyZYtd+8CBA4XQ0FBh8+bNDudUV1cLRqPR\noT01NVUIDQ0Vjh8/LradPXtWCA0NFZYvX+7QFhsbK5w9e1Zst1qtwtChQ4V+/frZXffll18WQkND\nG2x79dVX7dq//PJLITQ0VNi4caPY9tlnnwmhoaHCihUr7Pra2gcOHOjwWhpSUVEhJCcnC1FRUcId\nd9whZGVlOXVeY6ZMmSJEREQIFy5csGufMGGCEBkZKRQXFwuCcP3vtyAIQmhoqPDyyy+Lj/Py8oSw\nsDBhypQpgtlsFttPnjwphIWFCaGhoXY/G71e7/D8FotFePjhh4WePXvajW/58uUO59vY/r798MMP\nYtuSJUuE0NBQ4bPPPrPra/v5pKamOpw/cuRIobq6WmwvLCwUIiMjhRkzZjg8Z3229+j1119vsl9S\nUpIQEREh5OTkiG1Wq1V44YUXhNDQUOHAgQOCIAhCTk6OEBoaKnz00UdNXm/UqFHCkCFDrjo+InId\nli0REV0HHx8fjBkzxqFdqVSKvyU1m80oKytDSUkJ7rnnHgBosGyoIffdd5/dbk4SiQR9+vRBUVER\n9Hq9U9eYOnWq3eO7774bAPD777+LbXv37oVMJsOUKVPs+o4fPx5eXl5OPY/VasWLL76I3Nxc7Ny5\nE/feey9mzZqF7du32/WbN28eIiMjnVoDMW7cOFgsFnzxxRdiW15eHn788UfEx8eLC9Zb6v2ua/fu\n3RAEAY8++qjdGoTIyEj069fPob+Hh4f439XV1bh8+TJKS0vRr18/6HQ6/PLLL80eg80333wDX19f\nJCUl2bUnJSXB19cX//73vx3OefDBB+1KxTp06ICQkBD89ttv1zyOuoqLi3Hs2DHEx8cjPDxcbJdI\nJHj66afFcQMQ/w4dOnQIxcXFjV7T09MTFy5cwJEjR1pkjETU8li2RER0HTp37tzo4tb169dj06ZN\n+Pnnn2G1Wu2OlZWVOX39+nx8fAAApaWlUKvVzb6GrUymtLRUbMvPz4e/v7/D9ZRKJYKCglBeXn7V\n59m9ezf279+PhQsXIigoCMuWLcNzzz2Hl156CWazWSxNOX36NKKjo51aA3H//ffD29sbGRkZeOKJ\nJwAAW7ZsAQCxZMmmJd7vus6ePQsAuO222xyOdevWDfv377dr0+v1ePfdd7Fz506cP3/e4Rxn3sPG\n5OfnIyoqCnK5/T/bcrkcXbt2xalTpxzOaezvzrlz5655HPXHBADdu3d3OHbbbbdBKpWK72FgYCCe\neuopfPTRR+jfvz8iIiJw9913IzExETExMeJ5KSkpePbZZ/HQQw/B398fvXv3xl/+8hcMHjy4WWtm\niOjGYXggIroOKpWqwfbVq1dj/vz56N+/P6ZMmQJ/f38oFApcuHABc+bMgSAITl2/qV13rvcazp7v\nLNsC37vuugtATfB499138fTTT2Pu3Lkwm80IDw/H8ePH8dZbbzl1TTc3NwwbNgwbNmxAdnY2YmNj\nsW3bNnTs2BH/93//J/Zrqff7esycORPffvstJkyYgLvuugs+Pj6QyWTYt28fPv30U4dAc6PdrG1n\nnTVjxgyMGzcO3377LY4cOYL09HR8/PHHePzxxzF79mwAQFxcHL755hvs378fhw4dwqFDh7Bjxw68\n//772LBhgxicich1GB6IiG6ArVu3IjAwECtXrrT7Evfdd9+5cFSNCwwMxMGDB6HX6+1mH0wmE/Lz\n8526kZntdZ47dw6dOnUCUBMgVqxYgaeeegrz5s1DYGAgQkNDMWrUKKfHNm7cOGzYsAEZGRkoKytD\nUVERnnrqKbv39Ua837bf3P/yyy/o0qWL3bG8vDy7x+Xl5fj2228xcuRIvPHGG3bHDhw44HBtiUTS\n7LH8+uuvMJvNdrMPZrMZv/32W4OzDDearZzu559/djj2yy+/wGq1Ooyrc+fOmDx5MiZPnozq6mo8\n9thjWLVqFaZNmwY/Pz8AgFqtxuDBgzF48GAANTNKb7zxBtLT0/H444/f4FdFRFfTun4tQUR0i5BK\npZBIJHa/8TabzVi5cqULR9W4+Ph4WCwWrF271q598+bNqKiocOoaAwYMAFCzy0/d9Qxubm5YsmQJ\nvL29kZ+fj8GDBzuU3zQlMjISERER+PLLL7F+/XpIJBKHezvciPc7Pj4eEokEq1evttt29KeffnII\nBLbAUn+G4+LFiw5btQJX1kc4W041aNAglJSUOFxr8+bNKCkpwaBBg5y6Tkvy8/NDXFwc9u7di//9\n739iuyAI+OijjwAACQkJAGp2i6q/1aqbm5tYEmZ7H0pKShyeJzIy0q4PEbkWZx6IiG6AxMRELF68\nGMnJyUhISIBOp8OOHTua9aX5Zho/fjw2bdqEpUuX4o8//hC3at21axeCg4Md7ivRkH79+mHcuHFI\nT0/H0KFDMXLkSHTs2BFnz57F1q1bAdR8EXzvvffQrVs3DBkyxOnxjRs3Dm+++Sb+85//oHfv3g6/\n0b4R73e3bt3w0EMP4bPPPsMjjzyC+++/H8XFxVi/fj3Cw8Pt1hl4enqiX79+2LZtG9zd3REdHY1z\n587h888/R1BQkN36EgCIjY0FACxatAjDhw+Hm5sbbr/9doSGhjY4lscffxy7du3CG2+8gVOnTiEi\nIgI5OTlIT09HSEjIDfuN/MmTJ7FixQqHdrlcjieeeAJ/+9vfMHnyZDz00EN48MEHodVqsXfvXuzf\nvx/Dhg1D3759AdSUtM2bNw/3338/QkJCoFarcfLkSaSnpyM2NlYMEQ888AB69OiBmJgY+Pv7o6io\nCJs3b4ZCocDQoUNvyGskouZpnf+KERG1cY899hgEQUB6ejreeustaLVaDBkyBGPHjsUDDzzg6uE5\nUCqVWLNmDRYsWIDdu3dj586diImJwaeffoq//e1vqKqqcuo6b731Fnr37o1Nmzbh448/hslkQmBg\nIBITEzFt2jQolUokJSVh9uzZ8PLyQv/+/Z267vDhw7FgwQJUV1c7LJQGbtz7/be//Q0ajQabN2/G\nggUL0LVrV/z973/H77//7rBIeeHChVi8eDH27NmDzMxMdO3aFTNmzIBcLsfcuXPt+vbq1QuzZs3C\npk2bMG/ePJjNZjz33HONhgcvLy9s3LgRy5cvx549e5CRkQE/Pz9MnDgRzz//fLPvau6s48ePN7hT\nlVKpxBNPPIHo6Ghs2rQJy5cvx8aNG2EwGNC5c2fMmjUL06ZNE/uHhYUhISEBhw8fxvbt22G1WtGp\nUyc8+eSTdv2mTZuGffv2Yd26daioqICfnx9iY2Px5JNP2u3oRESuIxFuxioyIiJqkywWC+6++27E\nxMRc843WiIjo1sE1D0REBAANzi5s2rQJ5eXlDd7XgIiI/nxYtkRERACAV155BUajEXFxcVAqlTh2\n7Bh27NiB4OBgTJgwwdXDIyKiVoBlS0REBAD44osvsH79evz2228wGAzw8/PDgAED8OKLL0Kj0bh6\neERE1AowPBARERERkVO45oGIiIiIiJzC8EBERERERE7hguk25vJlPazWm1tp5ufnieJi3U19TiKi\nlsLPMCJqq1zx+SWVStC+vbrR4wwPbYzVKtz08GB7XiKitoqfYUTUVrW2zy+WLRERERERkVMYHoiI\niIiIyCkMD0RERERE5BSGByIiIiIicgrDAxEREREROYXhgYiIiIiInMLwQERERERETmF4ICIiIiIi\npzA8EBERERGRU3iHaSIiIiKiVuTgT4XI2JeHkvJq+Hq7YcyAbugb2dHVwwLA8EBERERE1Goc/KkQ\na3bmwmi2AgCKy6uxZmcuALSKAMGyJSIiIiIiFzNUmXAmvxQbvvmfGBxsjGYrMvbluWhk9jjzQERE\nRER0k1RWm3Hukh4Fl/Q4V6RHwSUdzl3So1RnbPK84vLqmzTCpjE8EBERERG1sCqjGQWXDDh3SVcT\nFGoDQ0mdEKBUSNHJT407uvoiUKtGoEaNT3fmNhgk/LzdbubwG8XwQERERER0japNFpwvts0i1ISE\nc0V6FJdXiX0Ucik6+XogrLMPAjRqBGo8EaBVQ9POHVKJxO564wd2t1vzAABKuRRjBnS7aa+pKQwP\nRERERERXYTJbcL7YYFdydO6SDpdKqyDU9pHLJOjoq0b3oHa4VxOAQE3NbILWRwWpVNLk9W1si6K5\n2xIRERERUStnMltxocSAfFu5Ue2MwsXSSgi1KUEmlaCjrwe6dvRGv6hONbMJWjX826sgk17/fkR9\nIzuib2RHaLVeKCqquO7rtSSGByIiIiL60zFbakKCOJNQ++eFkkpYa1OCVCJBB18Vgvw90eeODrUh\nwRMd2qsgl/05Ny1leCAiIiKiW5bFasXFy5V2axIKLulRWGKAxVoTEiQSwN9HhQCNGr3C/MVyow6+\nHlDI/5whoTEMD0RERETU5lmtAopKK2sWLIvrEnQoLDHAbKkNCQA0Pu4I1Hiix+2a2sXLanTy84BC\nLnPtC2gjGB6IiIiIqM2wCgIulVWhoHbB8rlLehQU6XG+xABTnR2KNO3cEaBRI/o2P3FNQic/NdwU\nDAnXg+GBiIiIiFodqyCgpKzKbk3CuUt6nC/Ww2i6EhJ8vd0QoFEjomv7K9ugajzgruTX3BuB7yoR\nERERuYwgCLhcUS3eH0Fcl1CsR7XRIvbz8VQiUKPGgNhA8YZqARo1VG78Onsz8d0mIiIiohtOEASU\n6ox1Fi3rxFmFyuorIcFbXRMS/i+6EwLqhAS1u8KFoycbhgciIiIiajGCIKDcYEJBkU4sNbKtSzBU\nm8V+nioFgrRq9I3sKAaEQK0nPFUMCa0ZwwMRERERXZMKQ81MQn69bVB1lSaxj9pdjkCNGr3v6HAl\nJGjU8FYrXThyulYMD0RERETUJF2l6Uo4qN3lqOCSHuWGKyFB5VYTEnqGamtCglaNoNqQIJFIXDh6\nakkMD0REREQEADBUmWtDgs5ul6MynVHs466UIUCjRkx3DYJqQ0KgxhM+ngwJfwYMD0RERER/MpXV\nZhQU22YRrpQbXa6oFvsoFVIE+KkRFeJbu/1pTbmRr7cbQ8KfGMMDERER0S2q2mipCQm126Dadjkq\nLr8SEhTympAQ3qU9ArVX1iT4tXOHlCGB6mF4ICIiImrjjCYLzhcb7O64fO6SHsVlVRBq+8hlUnTy\n88DtQT4YUBsQArRqaNupIJUyJJBzXBoejEYjli1bhq1bt6K8vBzh4eGYMWMG+vbt69T527dvx5o1\na/Dzzz9DqVQiNDQUL730EmJiYsQ+eXl5WLx4MQ4fPgyLxYKYmBjMnj0bUVFRdtdKTU3F/v37kZ+f\nj8rKSgQGBmLo0KGYNm0aPDw8xH6HDh3ClClTGhzPl19+iW7dutm1ZWdnY+HChTh16hQ8PT0xZMgQ\nzJw5EyqVytm3iYiIiAgAYDLXhIS6Oxudu6RH0eVKMSTIpBJ09PPAbQHe6B/TCYEaTwRq1dD6uEMm\nlbp0/NT2uTQ8zJkzB19//TWmTJmC4OBgZGZmIjk5GevWrUNcXFyT56ampmLVqlUYMWIEkpKSYDAY\nkJubi6KiIrFPfn4+Jk2aBKVSiccffxwqlQoZGRmYPHky0tLS0L17d7HvyZMn0aNHD4wcORLu7u7I\nzc3Fhx9+iEOHDmHt2rUOtX2PPPIIIiMj7do6dOhg9zgnJwdTp05F9+7dMWfOHBQWFuKTTz5Bfn4+\nPvjgg2t924iIiOgWZ7ZYUVhiEMuNCi7pkX9Jj4uXDRBqU4JMKoF/exW6+Hva3SvBv70KchlDAt0Y\nLgsPJ06cQFZWFubOnYupU6cCAEaNGoVhw4Zh0aJFWL9+faPnZmdn48MPP8Q777yDhISERvutXLkS\nBoMBaWlpCA4OBgBMmDABQ4YMwZIlS7BixQqx78cff+xwfufOnTF//nycPHkS0dHRdsd69+6NQYMG\nNfkalyxZAh8fH6xbtw5qtRoAEBQUhFdeeQUHDx50eoaFiIiIbk1mixUXL1eKMwjnam+sdvFyJSzW\nmpQgkQAd2nsgSKNG73B/cV1CR18PhgS66VwWHnbt2gWFQoHx48eLbW5ubhg3bhxSU1Nx8eJF+Pv7\nN3ju2rVrER0djYSEBFitVlRWVopfzuvKzs5GVFSUGBwAQKVSIT4+Hps3b4ZOp4Onp2ejYwwICAAA\nVFRUNHhcp9PB3d0dcrnj26jT6XDgwAE89thjdmMbOXIk3n77bezcuZPhgYiI6E/CahVwsbRSDAe2\nsFBYbLgSEgBo26vs75WgUaOTnwcUcplrXwBRLZeFh5ycHISEhDh86Y+JiYEgCMjJyWk0PBw8eBBD\nhw7FkiVLsG7dOhgMBgQGBmL69OkYMWKE2M9oNMLX19fhfHd3d5hMJpw5c8auPMpisaCsrEw8tnTp\nUnh5eTmsjwCA2bNnw2AwQC6Xo0+fPnj55ZcRFhYmHj99+jTMZrPDuUqlEhEREcjJyXHujSIiIqI2\nw2oVUFRWKS5YtoWE88UGmC1WsZ+mnTsCNWrEdPNDoKbmPgkd/TzgpmBIoNbNZeGhqKjIYY0AAGi1\nWgDAxYsXGzyvrKwMpaWlyMrKgkwmw6xZs+Dj44P169dj9uzZUKlUYilTSEgIjh07BoPBYLfoOTs7\nu8HnyMvLw/Dhw8XHISEhWLFiBby9vcU2hUKBwYMH495770X79u1x+vRpfPLJJ3jwwQeRnp6OkJAQ\n8fXVfT31X+OPP/549TeJiIiIWiWrIKC4rOpKQKhdl3C+WA+j+UpI8PN2Q4DGE5FdfcVyowA/NdyU\nDAnUNrksPFRVVUGhUDi0u7m5AQCqq6sdjgGAwWAAAJSWlmLz5s2IjY0FACQkJCAhIQHvvfeeGB4m\nTZqEvXv3IiUlBS+88AJUKhU2bNiAkydPimOoKygoCKtXr4bBYMDx48fx/fffQ6/X2/Xp2bMnevbs\nKT6+7777EB8fj7Fjx+Ldd9/F4sWL7a6tVCobfI31n9tZfn6Nl1ndSFqtl0uel4ioJfAzjK6VIAgo\nKq3EH4UV+KOwAr8XluOPCxXIv1CBKqNF7OfXzh1dOnghLtwfXTp4oUtHL3Tu4AUPd8fvOkTN0do+\nv1wWHmylQ/XZQoMtRNRnaw8KChKDA1DzJX3w4MFYu3Yt9Ho91Go1BgwYgHnz5mHx4sUYPXo0ACA4\nOBjTp0/HwoULHUqmPDw8cM899wAABg0ahIiICDzzzDPIzMxEeHh4o68lPDwcffv2xQ8//GD3+oCa\n0qmGXqPteHMVF+tgtQpX79iCtFovFBU1vO6DiKi142cYOUMQBJTqjDX3SahTclRwSW8XEtp5KhGo\nUddugaquvfOyR4MhQV9RBX3Ftf2ykAhwzeeXVCpp8pfVLgsPWq22wdIkW7lPY+sdfHx8oFQqodFo\nHI5pNBoIggCdTicGg4cffhhjxozB6dOnoVAoEBERgfT0dACwW0jdkEGDBkEqlSIrK6vJ8AAAnTp1\nsgsPtnKlulvH1n2Njb0+IiIiunEEQUCZ3mh3IzXbuoTKarPYz9tDgQCNGv2iOiFAqxYXL3uqOJNA\nf24uCw/h4eFYt26dOEtgc/z4cfF4Q6RSKSIiInDhwgWHY4WFhZDJZGjXrp1du4eHh93C6AMHDkCr\n1Trc0K0+k8kEi8XS6G5LdZ09exbt27cXH4eGhkIul+PkyZO4//77xXaj0YicnBy7tRVERETU8spt\nIcF2Q7XanY70VVdCgqeqJiTcfUcHBGjUCKpdl+Dl4Vh2TEQuDA+JiYn45JNPkJaWJt7nwWg0IiMj\nAz179hQXUxcUFKCystLui35iYiL+9a9/4fvvv0e/fv0A1GyNunPnTsTFxTVZEpSdnY1vvvkG06dP\nh7T2Los6nQ5KpdJhfUJ6ejoEQbC7GVxJSYnDDk5HjhzBoUOHMGrUKLHNy8sLffv2xdatW/Hkk0+K\nAWnr1q0wGAxITExs7ltGREREDdBVmnCuSFfnXgk1f+oqr5RHe7jJEaBV485w/9pyIzUCtJ7w9lA4\n3AiWiBonEQTh5hbQ1/Hiiy9i9+7deOSRR9ClSxdkZmbi5MmTWLNmDXr16gUAmDx5Mg4fPozTp0+L\n51VWVmLMmDG4cOECpk6dCm9vb2zZsgW//vqr3bl//PEHZs6cifj4eGg0Gpw5cwaff/45YmNjsWrV\nKjEsHDp0CDNnzsSQIUPQtWtXWCwWHD16FF999RXuuOMObNq0Sew7ZcoUqFQqxMXFoX379uI1vby8\nkJ6eLt4bAgB++uknTJw4EbfffjvGjx+PwsJCrF69Gn369MHKlSuv6T3jmgcioubhZ9itw1BlqgkH\ndXY3OndJj3L9lfWF7kpZTTjQqhGg8RTLjXw8lQwJ1Oa0xjUPLg0P1dXVWLp0KbZv346ysjKEhYUh\nJSVFXLQMNBwegJp1AwsWLMC+fftQVVWFyMhIpKSk4K677hL7XL58GX/9619x4sQJlJWVISAgACNG\njEBycrLdguzCwkIsX74cR44cwcWLF2GxWNClSxckJCQgOTnZrqxq7dq12L59O/744w/odDr4+vqi\nf//+eP755+2Cg82RI0ewaNEinDp1Cp6ennjggQeQkpJit3VsczA8EBE1Dz/D2p7KanO9LVBryo1K\ndVdCgptShgC/K2sRAmvXJbT3cmNIoFsGwwNdN4YHIqLm4WdY61VlNKPgkgHnLl0pOSq4pEdJ+ZXt\n2pVyKTrVlhmJQUGjhm87d0gZEugW1xrDg8vWPBAREdGfQ7XJgvPF9qVG54r0KC6/so2pXCZFgJ8H\nQjv7XNkCVauGhiGBqFVheKBGHfypEBn78lBSXg1fbzeMGdANfSM7unpYRETUSpnMFpwvNtiVHJ27\npMOl0irY5szlMgk6+nqgW6A37u0RIM4oaH1UkEoZEohaO4YHatDBnwqxZmcujGYrAKC4vBprduYC\nAAMEEdGfnMlsxYUSA/Jt5Vqv17EAACAASURBVEa1MwoXSythK4aWSWtCQteO3jX3Sqhdl+DfXgVZ\n7W6HRNT2MDxQgzL25YnBwcZotmLDN/+DVCKBm0IGN6UM7koZ3BQ1fypr/5TL+I8CEdGtwGypCQl2\n90q4pMeFkkpYa1OCVCJBB18Vgvw90af2XgmBGjU6+Hrw3wOiWxDDAzWouM5itbr0VWZ8uO2nJs+V\nSSU1oaI2WNjChS1wOAYPud2xhgKJm0LG6WwiohvEYrXi4uVKuzUJBZf0KCwxwFK7SYdEAvj7qBCg\nUaNXmLY2JHiio68HFHKGBKI/C4YHapCft1uDAcLH0w2zJvZAtcmCaqMFVbV/Ojw2WlBlMqPaZK19\nbMZlXfWVviYLqowWNGevL6Vcah8+6ocRuwAih5vC1l8uhhl3hQzKOn2Vcim39COiPw2rVUBRaaV4\nr4SakiMdCksMMFtqQwIAjY87AjWeiO2uEbdA7ejrAaVC5toXQEQux/BADRozoJvdmgeg5sv7+IHd\nEKBRN3Gm8wRBgMlsRZXJAmOd4OEQSOr8ty101Dw2o8pkQbneaBdejCbr1Z+8lgRoOIDYQkidx+6K\nOrMnShncFfIGz2XpFhG5mlUQcKmsCgW1C5bPXdKjoEiP8yUGmOp8rvt5uyNQq0b0bX7imoROfmq4\nMSQQUSMYHqhBtkXRN3K3JYlEAqWipjQJ13bPvAZZrQKqTRYYTXUCSSMBpMpY288urJihrzSjpLy6\nJqDUHrP9Vs4ZMmnT60LqH7vyuLaESyGt+e96pVws3SKiugRBQHF5lf0WqJf0OF+st/tFiq+3GwI0\nakR0bS+WG3Xy84DKjV8DiKh5eJO4NoY3iXMds8VqFzTqB48qY93ZD/vHjqVd5msq3VLIpVfChK0M\nq97jhku55HBTSq/MltSZSVEqWLpFt7Zb4TNMEARcrqgW748grkso1qPaaBH7+Xgqa2+k5olAbc0N\n1QL81PBwZ0ggaot4kziiNkwuk0Iuk8LDXdFi1xQEAWaL1T5o2K0baXhNiRhcah9XGEyorrvGxGS5\n+pPXkgB260DqrwtpNJDYlXbJHfrKZRKGEqJmEgQBpTpjnUXLOnFtQmX1lf+vvdU1IaF/dKcrd13W\nqqFuwc8nIqKGMDwQuZBEIoFCLoNCLoNXS5ZuCQKMDa4TqfPf9R7Xn0nRV5lRUlFtdw2zxfn1JPVL\nt5QK+3Uh9uVa9rtx2e3EZddXyv3h6ZYgCALKDSYUFOnEUiPbugRDtVns56lSIFCjxt2RHREkhgRP\neKoYEojINRgeiG5BUokE7ko53JUt+7+4rXSr2mRFVW3pVf01JY3uwFUbQMr0Rly8bF/qZW1G7Zat\ndKtu+Vb9/266tMsWSKRwU8prj7N0i26cCkPNTEJ+vW1QdZUmsY/aXY4AjRq97+hwZSZBo4a3WunC\nkRMROWJ4ICKnXSndAgC3FrlmTemWUBsmzFfdArjaZKm3JXBNm67M5HCus2ylW1ffYavhEi6xdKt2\ne2DbwneWbv256CpNV8JB7S5HBZf0KDdcCQkqNzkCNWr0DNXWhITabVDbqZX8u0JEbQLDAxG5VE3p\nlgQKubRFSzGsggCTySouUK8py7LW3H+kifKturMkhmozLldU2/U1mZtXuuWww1YT9yepv+WvfSmX\nnKVbrYShylwbEnR2d14u0xnFPm5KGQI1asR01yCwdhYhQKNGey83hgQiatMYHojoliSVSMQZA7Rg\n6YfFakW10SrOlBjrlHBV1ZkdaWoHrjK90eFeJs0p3ZLLpHZbADdUrtVoaVf9tSW1pVsKhRRSfqm1\nU1ltRkGxbRbhSrnR5YorN9BUKqQI8FMjqquvOIsQqPGErzdDAhHdmhgeiIiaQSaVwsNdWrv1ZcuX\nbtmXaZmd34HLZIG+0mT32Gi0oDkbO191dqSZpV22Gya66kv0wZ8KnbpXTbXRUhMSardBte1yVFx+\nJSQo5FJ08vNAeBcfBGo9xTUJfu3cGbqI6E+F4YGIyMVudOmW4zoRc+3sSdNrTKqMFlRVm1Gqq7Yr\n7WpO6ZZtBsjZHbYaCiANzaRcrXTr4E+FWLMzF8basRaXV2PNzlwUl1bCt517nXUJehSXVYkhSy6T\noKOvGrcH+WCArdxIq4a2nYo3aSQiAm8S1+bwJnFE5Gq2u7g3fud2c4PlW03dXLHaZIGlGZ9tdUu3\nHLf4leHYmUtNLpqXSSXo6Odht7NRgEYN//YqrikholaDN4kjIqI2TyqVQOUmh8qt5bcCbvxO7bZA\nYr1SztXADlxi6VYTweHNx/ugQ3sV5DKGBCKi5mJ4ICKiVkEuk8JT1TKlW7NXfG+3ZsHGz9sNgRr1\ndV+fiOjPir92ISKiW86YAd2glNv/E6eUSzFmQDcXjYiI6NbAmQciIrrl2HZVcma3JSIich7DAxER\n3ZL6RnZE38iO3PSBiKgFsWyJiIiIiIicwvBAREREREROYXggIiIiIiKnuHTNg9FoxLJly7B161aU\nl5cjPDwcM2bMQN++fZ06f/v27VizZg1+/vlnKJVKhIaG4qWXXkJMTIzYJy8vD4sXL8bhw4dhsVgQ\nExOD2bNnIyoqyu5aqamp2L9/P/Lz81FZWYnAwEAMHToU06ZNg4eHh9jvxIkTyMzMxKFDh1BQUAAf\nHx/ExcVh+vTpCA4Otrvm5MmTcfjwYYdxP/DAA0hNTW3OW0VERERE5HIuDQ9z5szB119/jSlTpiA4\nOBiZmZlITk7GunXrEBcX1+S5qampWLVqFUaMGIGkpCQYDAbk5uaiqKhI7JOfn49JkyZBqVTi8ccf\nh0qlQkZGBiZPnoy0tDR0795d7Hvy5En06NEDI0eOhLu7O3Jzc/Hhhx/i0KFDWLt2LSQSCQBg1apV\nyM7ORmJiIsLCwlBUVIT169dj1KhRSE9PR7du9tsABgQEYPr06XZtgYGB1/vWERERERHddBJBEARX\nPPGJEycwfvx4zJ07F1OnTgUAVFdXY9iwYfD398f69esbPTc7OxsPPvgg3nnnHSQkJDTa79VXX8WW\nLVuQlZUlzgpUVlZiyJAhuOOOO7BixYomx7h69WrMnz8f6enpiI6OFp87KioKSqVS7Pfbb79h+PDh\nGDp0KObPny+2T548GeXl5di6detV3w9nFRfrYLXe3B8ZdyohoraMn2FE1Fa54vNLKpXAz8+z8eM3\ncSx2du3aBYVCgfHjx4ttbm5uGDduHI4ePYqLFy82eu7atWsRHR2NhIQEWK1W6PX6BvvZvujXLSdS\nqVSIj4/Hd999B51O1+QYAwICAAAVFVd+aD179rQLDgDQtWtX3H777cjLy2vwOmazudExEhERERG1\nFS4LDzk5OQgJCYFarbZrj4mJgSAIyMnJafTcgwcPIjo6GkuWLEGvXr3Qs2dPxMfHY9u2bXb9jEYj\n3NzcHM53d3eHyWTCmTNn7NotFgtKSkpw4cIF7N+/H0uXLoWXl5fD+oj6BEHApUuX0L59e4djeXl5\n6NGjB3r27In+/fvjgw8+gNVqbfJ6REREREStkcvWPBQVFaFDhw4O7VqtFgAanXkoKytDaWkpsrKy\nIJPJMGvWLPj4+GD9+vWYPXs2VCqVWMoUEhKCY8eOwWAw2C16zs7ObvA58vLyMHz4cPFxSEgIVqxY\nAW9v7yZfy7Zt23DhwgXMmDHDrr1z587o06cPwsLCoNPpsGPHDqSmpqKgoABvvPFGk9ckIiIiImpt\nXBYeqqqqoFAoHNptMwXV1dUNnmcwGAAApaWl2Lx5M2JjYwEACQkJSEhIwHvvvSeGh0mTJmHv3r1I\nSUnBCy+8AJVKhQ0bNuDkyZPiGOoKCgrC6tWrYTAYcPz4cXz//fdXLTfKy8vDG2+8gV69emHkyJF2\nx95++227x6NHj8aLL76IzZs3Y+rUqbjtttuavHZDmqpBu5G0Wi+XPC8RUUvgZxgRtVWt7fPLZeHB\nVjpUny00NFRuVLc9KChIDA4AoFQqMXjwYKxduxZ6vR5qtRoDBgzAvHnzsHjxYowePRoAEBwcjOnT\np2PhwoUOJVMeHh645557AACDBg1CREQEnnnmGWRmZiI8PNxhLEVFRXjyySfRrl07LFu2DFLp1avA\npk2bhl27duHQoUPXFB64YJqIqHn4GUZEbVVrXDDtsvCg1WobLE2ybbXq7+/f4Hk+Pj5QKpXQaDQO\nxzQaDQRBgE6nE4PBww8/jDFjxuD06dNQKBSIiIhAeno6ADjcl6G+QYMGQSqVIisryyE8VFRUIDk5\nGRUVFdi4caNYbnU1HTt2BFBTfkVERERE1Ja4bMF0eHg4fv31V4eyoOPHj4vHGyKVShEREYELFy44\nHCssLIRMJkO7du3s2j08PBAXF4eoqCjIZDIcOHAAWq3W4Z4M9ZlMJlgsFrvdloCa2ZGnnnoKv/32\nGz788MNmzSCcPXsWAODr6+v0OURERERErYHLwkNiYiJMJhPS0tLENqPRiIyMDPTs2VNcTF1QUOCw\nBWpiYiLOnz+P77//XmzT6XTYuXMn4uLi4O7u3ujzZmdn45tvvsGUKVPEMiOdTgej0ejQNz09HYIg\nIDIyUmyzWCyYPn06fvzxRyxbtgw9evRo8HkauqbFYsGHH34IqVTq9F20iYiIiIhaC5eVLcXGxiIx\nMRGLFi1CUVERunTpgszMTBQUFOCf//yn2O/ll1/G4cOHcfr0abFt0qRJSEtLw/PPP4+pU6fC29sb\nW7ZsQUVFBVJSUsR+f/zxB2bOnIn4+HhoNBqcOXMGn3/+Oe68807xxnQA8NNPP2HmzJkYMmQIunbt\nCovFgqNHj+Krr75CZGSk3ULo+fPnY8+ePRg4cCBKS0vtbgCnVqsxaNAgu2sOGzYMXbp0gcFgwM6d\nO3Hy5EkkJyejc+fON+JtJSIiIiK6YVwWHgBgwYIFWLp0KbZu3YqysjKEhYXho48+Qq9evZo8T6VS\nYe3atViwYAE+++wzVFVVITIyEqtXr7Y718vLCxqNBp999hnKysoQEBCA5ORkJCcn293oLTg4GPfe\ney/27duHtLQ0WCwWdOnSBU899ZRD39zcXADA3r17sXfvXrtxBQYGiuEhICAAPXv2xNdff41Lly5B\nKpXi9ttvx/z588XF20REREREbYlEEISbu3UPXRfutkRE1Dz8DCOitqo17rbksjUPRERERETUtjA8\nEBERERGRUxgeiIiIiIjIKQwPRERERETkFIYHIiIiIiJyCsMDERERERE5heGBiIiIiIicwvBARERE\nREROYXggIiIiIiKnMDwQEREREZFTGB6IiIiIiMgpDA9EREREROQUhgciIiIiInIKwwMRERERETmF\n4YGIiIiIiJzC8EBERERERE5heCAiIiIiIqcwPBARERERkVMYHoiIiIiIyCkMD0RERERE5BSGByIi\nIiIicgrDAxEREREROYXhgYiIiIiInMLwQERERERETmF4ICIiIiIipzA8EBERERGRUxgeiIiIiIjI\nKS4ND0ajEQsXLkT//v0RExODCRMm4ODBg06fv337dowbNw49evRA79698fDDD+PEiRN2ffLy8vDM\nM8/gzjvvRFxcHB555BGcPHnS4VqpqakYO3Ys+vTpg5iYGAwZMgTvvvsuDAbDdY07OzsbkyZNQmxs\nLPr164d//OMfqKysdPo1EhERERG1FhJBEARXPXlKSgq+/vprTJkyBcHBwcjMzMTJkyexbt06xMXF\nNXluamoqVq1ahREjRqBnz54wGAzIzc3FoEGDcN999wEA8vPzMWbMGCiVSjz88MNQqVTIyMjAH3/8\ngbS0NHTv3l283mOPPYauXbsiODgY7u7uyM3NRVpaGnr06IG1a9dCIpE0e9w5OTlISkpC9+7dMX78\neBQWFuKTTz5Bv3798MEHH1zTe1ZcrIPVenN/ZFqtF4qKKm7qcxIRtRR+hhFRW+WKzy+pVAI/P89G\nj7ssPJw4cQLjx4/H3LlzMXXqVABAdXU1hg0bBn9/f6xfv77Rc7Ozs/Hggw/inXfeQUJCQqP9Xn31\nVWzZsgVZWVkIDg4GAFRWVmLIkCG44447sGLFiibHuHr1asyfPx/p6emIjo5u9riTk5Nx+vRp7Ny5\nE2q1GgCQlpaGV155BZ9++in69u171fepPoYHIqLm4WcYEbVVrTE8uKxsadeuXVAoFBg/frzY5ubm\nhnHjxuHo0aO4ePFio+euXbsW0dHRSEhIgNVqhV6vb7BfdnY2oqKixOAAACqVCvHx8fjuu++g0+ma\nHGNAQAAAoKLiyg/N2XHrdDocOHAAo0aNEoMDAIwcORIeHh7YuXNnk89NRERERNTauCw85OTkICQk\nxO6LNQDExMRAEATk5OQ0eu7BgwcRHR2NJUuWoFevXujZsyfi4+Oxbds2u35GoxFubm4O57u7u8Nk\nMuHMmTN27RaLBSUlJbhw4QL279+PpUuXwsvLC1FRUc0e9+nTp2E2m+3OBQClUomIiIgmXx8RERER\nUWskd9UTFxUVoUOHDg7tWq0WABqdeSgrK0NpaSmysrIgk8kwa9Ys+Pj4YP369Zg9ezZUKpVYyhQS\nEoJjx47BYDDAw8NDvEZ2dnaDz5GXl4fhw4eLj0NCQrBixQp4e3s3e9xFRUV27fX7/vjjjw2+PiIi\nIiKi1spl4aGqqgoKhcKh3TZTUF1d3eB5tt2PSktLsXnzZsTGxgIAEhISkJCQgPfee08MD5MmTcLe\nvXuRkpKCF154ASqVChs2bBB3W6qqqrK7dlBQEFavXg2DwYDjx4/j+++/dyiJcnbctmsrlcoG+9Z/\nbmc1VYN2I2m1Xi55XiKilsDPMCJqq1rb55fLwoOtdKg+25fvhsqN6rYHBQWJwQGo+ZI+ePBgrF27\nFnq9Hmq1GgMGDMC8efOwePFijB49GgAQHByM6dOnY+HChQ6lRx4eHrjnnnsAAIMGDUJERASeeeYZ\nZGZmIjw8vFnjdnd3B1BTOtVQX9vx5uKCaSKi5uFnGBG1Va1xwbTLwoNWq22wNMlW7uPv79/geT4+\nPlAqldBoNA7HNBoNBEGATqcTg8HDDz+MMWPG4PTp01AoFIiIiEB6ejoA2C2kbsigQYMglUqRlZUl\nhgdnx20rV7K11+/b2OsjIiIiImqtXLZgOjw8HL/++qtDWdDx48fF4w2RSqWIiIjAhQsXHI4VFhZC\nJpOhXbt2du0eHh6Ii4tDVFQUZDIZDhw4AK1Wi27dujU5RpPJBIvFYrfbkrPjDg0NhVwud7ghndFo\nRE5ODiIiIpp8biIiIiKi1sZl4SExMREmkwlpaWlim9FoREZGBnr27CkuSi4oKEBeXp7DuefPn8f3\n338vtul0OuzcuRNxcXFNlgRlZ2fjm2++wZQpUyCVSsVzGyovSk9PhyAIiIyMbPa4vby80LdvX2zd\nutUuaGzduhUGgwGJiYlOvU9ERERERK2Fy8qWYmNjkZiYiEWLFqGoqAhdunRBZmYmCgoK8M9//lPs\n9/LLL+Pw4cM4ffq02DZp0iSkpaXh+eefx9SpU+Ht7Y0tW7agoqICKSkpYr8//vgDM2fORHx8PDQa\nDc6cOYPPP/8cd955p3iDNwD46aefMHPmTAwZMgRdu3aFxWLB0aNH8dVXXyEyMhIjR45s9rgBYMaM\nGZg4cSImT54s3mF69erVuPfee8W1FUREREREbYXL7jAN1CwcXrp0KbZv346ysjKEhYUhJSXF7ov1\n5MmTHcIDULNuYMGCBdi3bx+qqqoQGRmJlJQU3HXXXWKfy5cv469//StOnDiBsrIyBAQEYMSIEUhO\nTrZbkF1YWIjly5fjyJEjuHjxIiwWC7p06YKEhAQkJyc7LKx2Ztw2R44cwaJFi3Dq1Cl4enrigQce\nQEpKit3Wsc3BBdNERM3DzzAiaqta44Jpl4YHaj6GByKi5uFnGBG1Va0xPLhszQMREREREbUtDA9E\nREREROQUhgciIiIiInIKwwMRERERETmF4YGIiIiIiJzisvs8EBEREVHLMJtN0OvLUV1dCavV4urh\nUAu5eFEKq9XaYteTyRTw9GwHlUp99c6NYHggIiIiasPMZhNKSi7Aw8MLvr4dIZPJIJFIXD0sagFy\nuRRmc8uEB0EQYDJVo7T0EuRyBRQK5TVdh2VLRERERG2YXl8ODw8veHq2g1wuZ3CgBkkkEiiV7lCr\n20GnK73m6zA8EBEREbVh1dWVcHe/9jIU+nNxd1fBZDJe8/kMD0RERERtmNVqgUwmc/UwqI2QSmXX\ntS6G4YGIiIiojWOpEjnrev+uMDwQEREREZFTGB6IiIiI6E/pueeewHPPPXHTz23LuFUrEREREbUq\n/fvf6VS/tLRt6NQp4AaPhupieCAiIiKiVmXevDfsHm/evBEXLpzH88+n2LX7+LS/rudJTX3PJee2\nZQwPRERERNSqDB78gN3jb7/djbKyUof2+qqqquDu7u708ygUimsa3/We25ZxzQMRERERtTnPPfcE\npk59EKdOncTTTz+G+Ph+WL9+DQDgP//5FrNnv4iRIxMxcGBfTJgwEp9+ugoWi8XhGnXXLWRnH0H/\n/ndi3749+PTTVRg1agji4+/Biy8+jfz8sy12LgBs2bIZ48ePRHx8PyQnT8Hx48faxDoKzjwQERER\nkYODPxUiY18eisur4efthjEDuqFvZEdXD8tOaellvPTSDNx/fyISE4eiQ4ea8X355Q6oVB5ISnoI\nHh4qHD16BKtWfQC9Xo9nn33xqtdds+ZjSKUyPPjgFFRUlGPjxnV4/fVXsHLlmhY5NzMzHampC9Cj\nR08kJU3C+fPnMXfuLHh5eUGr9b/2N+QmaJHwYDabsXv3bpSVlWHgwIHQarUtcVkiIiIicoGDPxVi\nzc5cGM1WAEBxeTXW7MwFgFYVIC5dKsKcOfMwbNhIu/bXXvsH3NyulC+NGjUOCxe+jczMNCQnPw2l\nUtnkdc1mMz75ZA3k8pqvyt7e7bBs2SL88svPuO227td1rslkwqpV7yMyMhpLl64Q+3Xvfjveeuu1\nWy88LFiwAIcOHcKWLVsAAIIg4NFHH8WRI0cgCAJ8fHywefNmdOnSpcUHS0RERETO+f6/57H/xPlr\nOjevoAxmi2DXZjRbsfrLHHz3Y0GzrtU/phP6RXe6pnFcjbu7OxIThzq01w0OBoMeRqMJsbFx2Lo1\nA7///htuvz20yesOHTpC/FIPALGxPQAABQXnrhoernZubu4plJWV4ZlnRtv1S0hIxPLlS5q8dmvQ\n7PDwn//8B/fcc4/4eM+ePfh//+//4fHHH0dERATefPNNfPTRR/jHP/7RogMlIiIiopujfnC4Wrur\naLX+dl/AbX75JQ8rV76P7Oz/B71eb3dMr9dd9bq28icbLy9vAEBFRcV1n1tYWBPogoI62/WTy+Xo\n1OnGhKyW1OzwUFhYiODgYPHx3r17ERQUhFmzZgEAzpw5g+3bt7fcCImIiIio2fpFX/tv/Gev+B7F\n5dUO7X7ebnj5oZ7XO7QWU3eGwaaiogLPP/8EPDw88dhjTyEwMAhKpRL/+18u3n//HVit1qteVyqV\nNdguCFcPT9dzblvQ7N2WTCaTXcI7dOiQ3UxE586dUVRU1DKjIyIiIqKbbsyAblDK7b8mKuVSjBnQ\nzUUjct6xY0dRVlaGv/3tVUyYMAn9+v0f7rqrjzgD4GodO9YEuvo7MJnNZpw/f21lZjdTs8NDx44d\ncezYMQA1swxnz57FXXfdJR4vLi6Gh4dHy42QiIiIiG6qvpEd8ciQcPh5uwGomXF4ZEh4q1os3Rip\ntObrbd3f9JtMJmRmprlqSHbCw+9Au3btsG1bJsxms9j+zTe7UFFR7sKROafZZUtDhw7FihUrUFJS\ngjNnzsDT0xMDBgwQj+fk5HCxNBEREVEb1zeyY5sIC/VFR8fAy8sbb731GsaNS4JEIsFXX32J1lI1\npFAoMG3aE0hNXYjp05/BwIH34fz589i5czsCA4MgkUhcPcQmNXvm4cknn8To0aPx448/QiKR4F//\n+he8va8sBNmzZw/69u3b4gMlIiIiIrqadu18sGBBKvz8NFi58n1s3PgZ7ryzD5555gVXD000dmwS\npk+fhcLC83jvvWU4fvwY5s9fAk9PLyiVbq4eXpMkQguu3rBardDr9XB3d3fqlt1GoxHLli3D1q1b\nUV5ejvDwcMyYMcPp8LF9+3asWbMGP//8M5RKJUJDQ/HSSy8hJiZG7JOXl4fFixfj8OHDsFgsiImJ\nwezZsxEVFSX2qaysREZGBv7973/jzJkz0Ov16Nq1KyZMmIAJEyZAJruy8GXOnDnIzMxsdEzfffcd\nOnToAACYPHkyDh8+7NDngQceQGpqqlOvsb7iYh2s1psbnbVaLxQVXX13ASKi1oifYXSrKyz8HR07\nBl+9I7VqVqsVw4YlYMCAgXj55VcAAHK5FGbz1Rd4N1dTf2ekUgn8/DwbPbdF7zBtNpvh5eXldP85\nc+bg66+/xpQpUxAcHIzMzEwkJydj3bp1iIuLa/Lc1NRUrFq1CiNGjEBSUhIMBgNyc3PtFmvn5+dj\n0qRJUCqVePzxx6FSqZCRkYHJkycjLS0N3bvX7NN79uxZvPnmm+jbty+mTp0KT09P7N+/H6+99hr+\n+9//4u233xavmZSU5BBuBEHAa6+9hsDAQDE42AQEBGD69Ol2bYGBgU6/R0RERER0a6muroabm/0M\nw65dWSgvL0NcXC8Xjco5zQ4P+/btw4kTJ/D888+LbevXr8fixYtRVVWFIUOGYP78+VedeThx4gSy\nsrIwd+5cTJ06FQAwatQoDBs2DIsWLcL69esbPTc7Oxsffvgh3nnnHSQkJDTab+XKlTAYDEhLSxO3\nl50wYQKGDBmCJUuWYMWKFQAAjUaD7du34/bbbxfPnThxIubOnYstW7bg6aefRufONXvxxsXFOQSb\nI0eOoLKyEsOHD3cYg7e3N0aOHOnQTkRERER/TidO/Ij3338Hf/lLPLy92+F//8tFVtY23HZbNwwc\nOMjVw2tSs9c8fPzxKyG9wAAAIABJREFUx/jll1/Ex3l5eXj77bfh7++Pe+65B19++WWTX/xtdu3a\nBYVCgfHjx4ttbm5uGDduHI4ePYqLFy82eu7atWsRHR2NhIQEsVSqIdnZ2YiKirK7L4VKpUJ8fDy+\n++476HQ1Nwnx9fW1Cw42tmBS9/U2ZMeOHZBIJBg2bFiDx81mc6NjJCIiIqI/l4CAQGg0WqSnf46l\nSxdi//7vkJg4FMuWve9U6b8rNXvm4ZdffrHbXenLL7+Em5sb0tPT4enpiZkzZ+KLL74QZxMak5OT\ng5CQEKjVarv2mJgYCIKAnJwc+Pv7N3juwYMHMXToUCxZsgTr1q2DwWBAYGAgpk+fjhEjRoj9jEYj\nfH19Hc53d3eHyWTCmTNnmiyPunTpEgCgffv2jfYxmUzYuXMn4uLiEBQU5HA8Ly8PPXr0gMlkglar\nxcMPP4wnnnhC3EaMiIiIiP5cAgODsGDBta1/dbVmh4eysjK7L9MHDhzA3XffDU/PmoUVvXv3xr59\n+656naKiIof1AQCg1WoBoNGZh7KyMpSWliIrKwsymQyzZs2Cj48P1q9fj9mzZ0OlUokzBiEhITh2\n7BgMBoPdvSeys7ObfA6gJnisWbMGXbp0sVtcXd/+/ftRWlraYMlS586d0adPH4SFhUGn02HHjh1I\nTU1FQUEB3njjjUavSURERETUGjU7PLRv3x4FBQUAAJ1Oh//+979ISUkRj5vNZlgslqtep6qqqsFp\nGdvikepqx1uiA4DBYAAAlJaWYvPmzYiNjQVQU2KUkJCA9957TwwPkyZNwt69e5GSkoIXXngBKpUK\nGzZswMmTJ8UxNObNN99EXl4eVq5c2eQswY4dO6BQKDBkyBCHY3UXWgPA6NGj8eKLL2Lz5s2YOnUq\nbrvttkav25imVr/fSFqt8wvhiYhaG36G0a3s4kUp5HJWNNyqbsTPViqVXvPnYrPDQ48ePbBp0yZ0\n794d3333HSwWC+69917x+O+//95ouVFdttKh+myhof4KdBtbe1BQkBgcAECpVGLw4MFYu3Yt9Ho9\n1Or/3969h0VVLWwAfxlgcLgoKGNeIbwBcp0R9cNroSh6zAuhhgJSJ0wtTVEzS0+d6qSf4i3TNCiP\nKHbk+iEqpqgnj+IRc0xFARH1KCGIKMhwV+b7w4ed08zggJeBzvt7nv5g7bX2Wnvk2c3LXmttCwwf\nPhzLly/HmjVrMGnSJACAvb095s+fj9WrV2tMmWoQFRWF2NhYLFy4EEOHDtV5DRUVFTh8+DCGDBnS\n6NSmx7311ls4cOAATp061azwwK1aiYiahvcw+qOrr69/Ltt5kuE9r61a6+vrdd4Xn/lWrfPmzUNI\nSIiw/eikSZOELU9VKhXS0tIwcODAJ55HKpVqnTbUsNWqrgBibW0NsVgMW1tbjWO2trZQqVRQKpVC\nMAgKCoK/vz9ycnJgamoKZ2dnxMfHA4DaQuoGiYmJiIiIwPTp0zFz5sxGryEtLU3nLku6dOr06E2N\nZWVlerchIiIiImoJmhweevXqhf3790OhUMDKygr9+/cXjt2/fx8zZszQKzw4OTlhx44dwlOCBufO\nnROOayMSieDs7IyioiKNY4WFhTA2Nka7du3Uys3NzdUWRqenp0MqlaJnz55q9dLS0rBs2TKMGjUK\ny5Yte+I1pKSkwNzcHD4+Pk+s2+DmzZsAoHUhNxERERFRS9asSVTW1tbw8fFRCw4A0K5dO8yYMUPn\nF//H+fn5oa6uDnFxcUJZbW0tEhMTIZfLhcXUBQUFyMvL02h769YtnDhxQihTKpXCrkdt2rTR2a9C\nocChQ4cQEhKitpbh9OnTCA8Ph5eXFyIiIp64G9Ldu3dx8uRJ+Pr6QiKRaBxXKpWora1VK3v48CG2\nbt0KkUik91u0iYiIiIhaima/YfrGjRs4fPiw8Jf07t27Y8SIEbCzs9OrvYeHB/z8/BAREYHi4mLY\n2dkhKSkJBQUFWLFihVBvyZIlyMjIQE5OjlAWGBiIuLg4zJ07F6GhoWjbti0SEhJQXl6utnj7xo0b\nWLhwIXx8fGBra4vc3Fzs3r0bXl5ealvJ/vrrr5g9ezaMjIwwevRopKamqo1VLpcLL4lrsH//fjx4\n8EDnlKWLFy9i4cKFGDduHOzs7FBZWYnU1FRkZmYiLCxM43xERERERC1ds8LD+vXrERkZqbGr0urV\nq/HOO+/g/fff1+s8q1atwvr165GcnIyysjI4Ojri22+/Rb9+jb+WWyKRIDo6GqtWrcLOnTtRXV0N\nFxcXbNu2Ta2tlZUVbG1tsXPnTpSVlaFLly4ICwtDWFgYxGKxUC8/Px/l5Y8WjWjbQnXFihUaX/ZT\nUlLQoUMHDBo0SOsYu3TpArlcjoMHD+LOnTsQiUTo3bs3Vq5cKSzeJiIiIqLnb//+FHz55V8RF7cH\nnTt3AQAEBLwGmawfPv740ya3fVoKxc+YN28WvvpqC+Ryr2dyzhelyeEhPj4eW7ZsgUwmw9tvvy28\nmTk3NxffffcdtmzZgu7du8Pf3/+J5zIzM8OSJUuwZMkSnXV27NihtVwqlWL16tWNnt/GxgbffPPN\nE8cxcOBAtScb+ti9e3ejx7t3746vvvqqSeckIiIiIuCDDxZAoTiNlJRDWqeHA0B4+Hu4ePEC9uw5\nqHOXTkNLS/sRd++WYMqUaYYeyjPT5PCwa9cueHh4YMeOHTAx+a25nZ0dhg8fjunTp2Pnzp16hQci\nIiIiot/z9R2N9PR/4fjxn+Dr66dx/N69uzhz5jRGjRrT7OCwa1fCE9e4Pq3Dhw8iN/eyRnjw9JTj\n8OETWt951tI1+RPLy8vD2LFj1YJDAxMTE4wdO1ZjgTMRERERkb6GDn0FEok50tJ+1Hr8yJE0PHz4\nEKNGaQYLfYnFYq3fZ18EkUgEMzOz5x5enocmf2KmpqbCW561qaioaJUpioiIiIhahjZt2mDo0OE4\nejQN9+/fR9u2bdWOp6X9iA4dOqB7d3tERKzEmTMZKCoqQps2bSCXe+Hdd99/4voEbWserl7Nw/r1\nq5GZeQHt2rXDhAn+sLWVarT917/+iT17knD5cg7u3y+DVNoRY8e+huDgN2FsbAwAeO+9mfjlFwUA\nYMiQR+saOnXqjPj4FJ1rHg4fPoidO/+O//znOszNLTB06DC8885cWFtbC3Xee28mlEol/vKXz7B2\n7SpkZV2ElVVbTJ78BqZPn9G0D7oZmhwe3NzcsHv3bkyePFnjRW0lJSWIjY1Ve/MzEREREVFT+fr6\n4eDBVPzzn4cxfvxvm80UFt5CZuZ5BAS8gaysi8jMPI+RI0dDKu2IW7cK8H//l4C5c9/Bzp1xjW7f\n/3slJXcwb94s1NfXIyhoBtq0kWDPniSt06L2798LicQcU6dOh7m5BGfO/IyoqC2oqKjAu+8+2jho\nxoy3UFVVhaKiW5g799FuoBKJuc7+GxZmu7i4Yfbsebh9uwgJCbtx8WImIiOj1cZx/34ZFi6ch1df\nHYERI0bh6NE0fPPNRvTo0Qve3oP1vubmaHJ4mDNnDkJDQzF27Fi8/vrrwtulr1y5gsTERFRUVCAi\nIuKZD5SIiIiIXpyMQgX25B3AvZpS2JhZY3xPPwzoJH9h/ffvPxDW1jZIS/tRLTykpf0IlUoFX9/R\n6NmzF159daRau8GDh2HWrDfxz38ehp/fn/TuLyZmO8rKShEVtQOOjo/eWTZmzDgEBmrukvnpp1/A\nzOy3YDJxYgBWr/4SSUlxCAubDbFYjP79/weJiXEoKyvF6NFjG+37wYMH+OabjejVqw82btwq7Ara\nt29fLF++FCkpSQgIeEOof/t2ET755AthPci4cRMQEDAO+/YlP/fw0OSJVv3798fGjRthYWGBbdu2\n4eOPP8bHH3+Mbdu2wcLCAl9//TW8vFrXllNERERE9JuMQgV2ZSfgXk0pAOBeTSl2ZScgo1DxwsZg\nYmICH5+R+OUXBe7cuSOUp6UdRLdu3dG3r6vaF/gHDx6grKwU3bp1h6WlFS5fzm5SfydPnoCbm4cQ\nHIBHO3f6+o7RqPt4v5WVFSgtLYWHhwzV1dX4z3+uN6lfAMjOvoR79+7C33+y2usERozwhVTaEenp\nJ9TqW1paYuTI0cLPpqamcHZ2QUHBr03uu6matUrEx8cHr7zyCjIzM5Gfnw/g0dakLi4uiI2Nxdix\nY7F///5nOlAiIiIi0t+pW2dw8tbpZrW9VnYDD1QP1Mrq6usQkxWP9IKMJp3Lu3N/DOzc+Du8dPH1\n9UNiYhyOHDmIKVOm4fr1a7hy5TLefDMMAFBTU40dO/6O/ftTUFx8GyqVSmirVCqb1FdRUSHc3DSn\n3tvZ2WuUXb2ah8jIb6BQnEZFRYXasYqKpvULPJqKpa0vkUiEbt26o6jollp5x44vwcjISK3Myqot\n8vKuNLnvpmr2EnORSAR3d3e4u7urld+7dw/Xrl176oERERERkWH8Pjg8qfx5cXPzQOfOXXHo0AFM\nmTINhw4dAABhus66dauxf38KJk8OhKurGywtLQEY4dNPP1ILEs9SeXk55s6dCXNzS/z5z7PQtWs3\niMViXL6cjW++2Yj6+vrn0u/jRCJjreXP65ofZ5j9qYiIiIjouRrYuV+z/+K/7MSXwpSlx9mYWWO+\nfNbTDq1JRo4chR07tiE//yYOHz4IR0dn4S/0Desa5s5dINSvqalp8lMHAHjppU7Iz7+pUX7jxn/U\nfj579gzKysrwt7+thqfnb2tAbt0q0HJWIy1lmjp16iz09fg5VSoV8vNvwsGhp17neRFa3+ayRERE\nRPRcje/pB1OR+tb7piJTjO/Z/PcqNNeoUY/WHHz99Trk599Ue7eDtr/AJyTsxsOHD5vcj7f3YFy4\ncA45Ob+tlbh37x4OHUpVq9fwbobH/8pfV1eHpKQ4jXNKJBK9goyTU1/Y2LTH//1fPOrq6oTyI0fS\nUFx8G4MGPd9F0E3BJw9EREREpKZhVyVD7rbUwMGhB3r16oPjx49BJBJhxIjfFgoPGjQEP/64HxYW\nlnj5ZQdcvHgBP/+cgXbt2jW5n2nTZuDHH/cjPPxdBAS8ATOzNtizJwkvvdQZSmWuUM/NzR1WVm3x\nt799ioCAqTAyMsKPP+6HthlDjo5OOHgwFRs3roWTU19IJOYYMmSYRj0TExPMnj0XX375V8yd+w5G\njhyF27eLEB+/Gz169MRrr2nu+GQoDA9EREREpGFAJ7lBwoI2o0b54cqVy5DJ+qm9Z+z99xdBJBLh\n0KFU1NTUws3NA+vXb0J4+Nwm92Fra4uvvtqKdetWYceOv6u9JG7lys+Feu3aWWPVqnX4+uv1iIz8\nBlZWbTFq1Bh4eQ1AePh7auecMOF1XL6cjf3792L37l3o1Kmz1vAAAGPHvgaxWIyYmO3YtGkDLCws\nMHr0GMyc+Z7Wd00YipFKj5UV27Zt0/uE6enpOH78OLKysp5qYKRdSYkS9fXPfzHM46RSKxQXl7/Q\nPomInhXew+iPrrDwP+jUSXNHIGr9TExEePDg2S/Abux3RiQyQocOlrrHpE8H//u//9ukAf1+6ygi\nIiIiImr99AoP0dHRz3scRERERETUwukVHgYMGPC8x0FERERERC0ct2olIiIiIiK9MDwQEREREZFe\nGB6IiIiIiEgvDA9ERERERKQXhgciIiKiVk6P13YRAXj63xWGByIiIqJWzNjYFHV1NYYeBrUSdXW1\nMDbWa8NVrRgeiIiIiFoxS8t2KC29g4qKcjx8+IBPIUgrlUqF2toalJYWw9LSutnnaX7sICIiIiKD\nk0gsYGJiCqWyFBUVZaivf2joIdEzIhKJUF9f/8zOZ2xsAisrG0gkFs0+B8MDERERUStnaiqGjU1H\nQw+DnjGp1ArFxeWGHoYaTlsiIiIiIiK9MDwQEREREZFeDBoeamtrsXr1agwZMgTu7u6YMmUKTp48\nqXf7lJQUBAQEwNPTEwMGDEBQUBDOnz+vVicvLw9z5syBl5cXZDIZZsyYgczMTLU6VVVViImJwZtv\nvokhQ4ZAJpNh0qRJ+OGHH/Dwofq8wVOnTsHR0VHrf3l5eRpjVCgUCAwMhIeHBwYPHowvvvgCVVVV\nTfiUiIiIiIhaBoOuefjwww9x8OBBhISEwN7eHklJSQgLC8OOHTsgk8kabbtu3TpERUVh/PjxmDp1\nKiorK5GdnY3i4mKhTn5+PgIDAyEWi/H2229DIpEgMTERwcHBiIuLQ69evQAAN2/exOeffw5vb2+E\nhobC0tISx48fx6effooLFy7gyy+/1Oh/xowZcHFxUSt76aWX1H7OyspCaGgoevXqhQ8//BCFhYX4\n/vvvkZ+fjy1btjT3YyMiIiIiMgiDhYfz589j3759WLp0KUJDQwEAEydOxLhx4xAREYGYmBidbRUK\nBbZu3YqNGzfC19dXZ73IyEhUVlYiLi4O9vb2AIApU6ZgzJgxWLt2LTZv3gwAsLW1RUpKCnr37i20\nfeONN7B06VIkJCRg9uzZ6N69u9q5BwwYgJEjRzZ6jWvXroW1tTV27NgBC4tHq9q7deuGZcuW4eTJ\nk/D29m60PRERERFRS2KwaUsHDhyAqakpJk+eLJSZmZkhICAAZ86cwe3bt3W2jY6OhpubG3x9fVFf\nX4+Kigqt9RQKBVxdXYXgAAASiQQ+Pj44duwYlEolAKB9+/ZqwaFBQzC5evWq1vMrlUo8ePBA57H0\n9HRMnDhRCA4AMGHCBJibmyM1NVXn9RERERERtUQGCw9ZWVlwcHBQ+2INAO7u7lCpVMjKytLZ9uTJ\nk3Bzc8PatWvRr18/yOVy+Pj4YM+ePWr1amtrYWZmptG+TZs2qKurQ25ubqNjvHPnDgDAxsZG49ji\nxYvRr18/eHh44K233kJOTo7a8ZycHDx48ACurq5q5WKxGM7Ozo1eHxERERFRS2SwaUvFxcUaawQA\nQCqVAoDOJw9lZWUoLS3Fvn37YGxsjEWLFsHa2hoxMTFYvHgxJBKJ8MTAwcEBZ8+eRWVlJczNzYVz\nKBSKRvsAHgWP7du3w87OTi0AmJqaYvTo0Rg2bBhsbGyQk5OD77//HtOmTUN8fDwcHByE63v8en5/\njb/88kujnw8RERERUUtjsPBQXV0NU1NTjfKGJwU1NTVa21VWVgIASktLERsbCw8PDwCPphj5+vpi\n06ZNQngIDAzE0aNHER4ejnnz5kEikWDXrl3CbkvV1dU6x/f5558jLy8PkZGREIl+e0Ajl8shl8uF\nn0eMGAEfHx+8/vrr+Prrr7FmzRq1c4vFYq3X2FjfjenQwbJZ7Z6WVGplkH6JiJ4F3sOIqLVqafcv\ng4WHhqlDv9cQGrRNN3q8vFu3bkJwAB59SR89ejSio6NRUVEBCwsLDB8+HMuXL8eaNWswadIkAIC9\nvT3mz5+P1atXa0yZahAVFYXY2FgsXLgQQ4cOfeK1ODk5wdvbG//+97/Vrg949ARD2zU2HG+qkhIl\n6utVzWrbXC3x7YZERPriPYyIWitD3L9EIqNG/1htsPAglUq1ThtqmO7TsaP2V6xbW1tDLBbD1tZW\n45itrS1UKhWUSqUQDIKCguDv74+cnByYmprC2dkZ8fHxAKC2kLpBYmIiIiIiMH36dMycOVPv6+nc\nubNaeGiYrvT41rGPX6Ou6yMiIiIiaqkMtmDayckJ165d09gp6dy5c8JxbUQiEZydnVFUVKRxrLCw\nEMbGxmjXrp1aubm5OWQyGVxdXWFsbIz09HRIpVL07NlTrV5aWhqWLVuGUaNGYdmyZU26nps3b6ot\nrO7Tpw9MTEw0XkhXW1uLrKwsODs7N+n8RERERESGZrDw4Ofnh7q6OsTFxQlltbW1SExMhFwuFxZT\nFxQUaLy52c/PD7du3cKJEyeEMqVSidTUVMhkskanBCkUChw6dAghISFqaxlOnz6N8PBweHl5ISIi\nQu3Y4+7evatR9vPPP+PUqVMYMmSIUGZlZQVvb28kJyerBaTk5GRUVlbCz89P5xiJiIiIiFoiI5VK\n9WIn0D/m/fffx+HDhzFjxgzY2dkhKSkJmZmZ2L59O/r16wcACA4ORkZGhtpWqFVVVfD390dRURFC\nQ0PRtm1bJCQk4Nq1a2ptb9y4gYULF8LHxwe2trbIzc3F7t274eHhgaioKGEx86+//ooJEyagrq4O\nH3zwASwt1ed5yeVy4SVxISEhkEgkkMlksLGxEc5pZWWF+Ph4dOnSRWh38eJFvPHGG+jduzcmT56M\nwsJCbNu2DQMHDkRkZGSzPjOueSAiahrew4iotWqJax4MGh5qamqwfv16pKSkoKysDI6OjggPD8eg\nQYOEOtrCA/Bo3cCqVavw008/obq6Gi4uLggPD0f//v2FOvfu3cNHH32E8+fPo6ysDF26dMH48eMR\nFhamtiD71KlTCAkJ0TnOFStWwN/fH8CjF9SlpKTgxo0bUCqVaN++PYYMGYK5c+eqBYcGP//8MyIi\nInDp0iVYWlpi7NixCA8PV9s6tikYHoiImob3MCJqrRge6KkxPBARNQ3vYUTUWrXE8GCwNQ9ERERE\nRNS6MDwQEREREZFeGB6IiIiIiEgvDA9ERERERKQXhgciIiIiItILwwMREREREemF4YGIiIiIiPTC\n8EBERERERHpheCAiIiIiIr0wPBARERERkV4YHoiIiIiISC8MD0REREREpBeGByIiIiIi0gvDAxER\nERER6YXhgYiIiIiI9MLwQEREREREemF4ICIiIiIivTA8EBERERGRXhgeiIiIiIhILwwPRERERESk\nF4YHIiIiIiLSC8MDERERERHpheGBiIiIiIj0wvBARERERER6YXggIiIiIiK9MDwQEREREZFeGB6I\niIiIiEgvJobsvLa2Fhs2bEBycjLu378PJycnLFiwAN7e3nq1T0lJwfbt23HlyhWIxWL06dMHH3zw\nAdzd3YU6eXl5WLNmDTIyMvDw4UO4u7tj8eLFcHV1FepUVVUhMTERaWlpyM3NRUVFBV5++WVMmTIF\nU6ZMgbGxsVD3/PnzSEpKwqlTp1BQUABra2vIZDLMnz8f9vb2auMLDg5GRkaGxrjHjh2LdevWNfXj\nIiIiIiIyKIOGhw8//BAHDx5ESEgI7O3tkZSUhLCwMOzYsQMymazRtuvWrUNUVBTGjx+PqVOnorKy\nEtnZ2SguLhbq5OfnIzAwEGKxGG+//TYkEgkSExMRHByMuLg49OrVCwBw8+ZNfP755/D29kZoaCgs\nLS1x/PhxfPrpp7hw4QK+/PJL4ZxRUVFQKBTw8/ODo6MjiouLERMTg4kTJyI+Ph49e/ZUG2eXLl0w\nf/58tbKuXbs+7UdHRERERPTCGalUKpUhOj5//jwmT56MpUuXIjQ0FABQU1ODcePGoWPHjoiJidHZ\nVqFQYNq0adi4cSN8fX111vvkk0+QkJCAffv2CU8FqqqqMGbMGPTt2xebN28GANy9exclJSXo3bu3\nWvulS5cKTyS6d+8u9O3q6gqxWCzUu379Ol577TX86U9/wsqVK4Xy4OBg3L9/H8nJyU37cBpRUqJE\nff2L/SeTSq1QXFz+QvskInpWeA8jotbKEPcvkcgIHTpY6j7+Asei5sCBAzA1NcXkyZOFMjMzMwQE\nBODMmTO4ffu2zrbR0dFwc3ODr68v6uvrUVFRobVewxf9x6cTSSQS+Pj44NixY1AqlQCA9u3bawQH\nAEIwuXr1qlAml8vVggMAvPzyy+jduzfy8vK0juPBgwc6x0hERERE1FoYLDxkZWXBwcEBFhYWauXu\n7u5QqVTIysrS2fbkyZNwc3PD2rVr0a9fP8jlcvj4+GDPnj1q9Wpra2FmZqbRvk2bNqirq0Nubm6j\nY7xz5w4AwMbGptF6KpUKd+7c0VovLy8Pnp6ekMvlGDJkCLZs2YL6+vpGz0dERERE1BIZbM1DcXEx\nXnrpJY1yqVQKADqfPJSVlaG0tBT79u2DsbExFi1aBGtra8TExGDx4sWQSCTCEwMHBwecPXsWlZWV\nMDc3F86hUCga7QN4FDy2b98OOzs7tcXV2uzZswdFRUVYsGCBWnn37t0xcOBAODo6QqlUYu/evVi3\nbh0KCgrw2WefNXpOXRp7jPQ8SaVWBumXiOhZ4D2MiFqrlnb/Mlh4qK6uhqmpqUZ5w5OCmpoare0q\nKysBAKWlpYiNjYWHhweAR1OMfH19sWnTJiE8BAYG4ujRowgPD8e8efMgkUiwa9cuZGZmCmPQ5fPP\nP0deXh4iIyMhEul+QJOXl4fPPvsM/fr1w4QJE9SOPb7QGgAmTZqE999/H7GxsQgNDUWPHj10nlcX\nrnkgImoa3sOIqLXimofHNEwd+r2G0KBtutHj5d26dROCAwCIxWKMHj0a2dnZwvqC4cOHY/ny5Th1\n6hQmTZoEPz8//PTTT8LuR7+fMtUgKioKsbGxCA8Px9ChQ3VeQ3FxMd555x20a9cOGzZsaDRkNHjr\nrbegUqlw6tSpJ9YlIiIiImpJDPbkQSqVap021LDVaseOHbW2s7a2hlgshq2trcYxW1tbqFQqKJVK\nIRgEBQXB398fOTk5MDU1hbOzM+Lj4wFA470MAJCYmIiIiAhMnz4dM2fO1Dn+8vJyhIWFoby8HD/8\n8IMw3epJOnXqBODR9CsiIiIiotbEYE8enJyccO3aNY1diM6dOycc10YkEsHZ2RlFRUUaxwoLC2Fs\nbIx27dqplZubm0Mmk8HV1RXGxsZIT0+HVCrVeCdDWloali1bhlGjRmHZsmU6x15TU4NZs2bh+vXr\n2Lp1a5OmH928eRPAox2eiIiIiIhaE4OFBz8/P9TV1SEuLk4oq62tRWJiIuRyubCYuqCgQGMLVD8/\nP9y6dQsnTpwQypRKJVJTUyGTydCmTRud/SoUChw6dAghISFq04xOnz6N8PBweHl5ISIiQucUpIcP\nH2L+/Pn45ZdfsGHDBnh6emqtp1QqUVtbq9F269atEIlEer9Fm4iIiIiopTDYtCUPDw/4+fkhIiIC\nxcXFsLOzQ1I6SGHPAAAaUklEQVRSEgoKCrBixQqh3pIlS5CRkYGcnByhLDAwEHFxcZg7dy5CQ0PR\ntm1bJCQkoLy8HOHh4UK9GzduYOHChfDx8YGtrS1yc3Oxe/dueHl5CS+mA4Bff/0Vs2fPhpGREUaP\nHo3U1FS1scrlcuElcStXrsSRI0fw6quvorS0VO0FcBYWFhg5ciQA4OLFi1i4cCHGjRsHOzs7VFZW\nIjU1FZmZmQgLCxPOR0RERETUWhgsPADAqlWrsH79eiQnJ6OsrAyOjo749ttv0a9fv0bbSSQSREdH\nY9WqVdi5cyeqq6vh4uKCbdu2qbW1srKCra0tdu7cibKyMnTp0gVhYWEICwtTe9Fbfn4+yssfrWTX\ntoXqihUrhC/72dnZAICjR4/i6NGjavW6du0qhIcuXbpALpfj4MGDuHPnDkQiEXr37o2VK1di0qRJ\nzfi0iIiIiIgMy0ilUr3YfT/pqXCrViKipuE9jIhaK27VSkRERERErRbDAxERERER6YXhgYiIiIiI\n9MLwQEREREREemF4ICIiIiIivTA8EBERERGRXhgeiIiIiIhILwwPRERERESkF4YHIiIiIiLSC8MD\nERERERHpheGBiIiIiIj0wvBARERERER6YXggIiIiIiK9MDwQEREREZFeGB6IiIiIiEgvDA9ERERE\nRKQXhgciIiIiItILwwMREREREemF4YGIiIiIiPTC8EBERERERHpheCAiIiIiIr0wPBARERERkV4Y\nHoiIiIiISC8MD0REREREpBeGByIiIiIi0gvDAxERERER6cWg4aG2tharV6/GkCFD4O7ujilTpuDk\nyZN6t09JSUFAQAA8PT0xYMAABAUF4fz582p18vLyMGfOHHh5eUEmk2HGjBnIzMxUq1NVVYWYmBi8\n+eabGDJkCGQyGSZNmoQffvgBDx8+fKpxKxQKBAYGwsPDA4MHD8YXX3yBqqoqva+RiIiIiKilMFKp\nVCpDdR4eHo6DBw8iJCQE9vb2SEpKQmZmJnbs2AGZTNZo23Xr1iEqKgrjx4+HXC5HZWUlsrOzMXLk\nSIwYMQIAkJ+fD39/f4jFYgQFBUEikSAxMRE3btxAXFwcevXqBQC4fPkyxo8fD29vbwwePBiWlpY4\nfvw4Dh06hNdffx1ffvlls8adlZWFqVOnolevXpg8eTIKCwvx/fffY/DgwdiyZUuzPrOSEiXq61/s\nP5lUaoXi4vIX2icR0bPCexgRtVaGuH+JREbo0MFS53GDhYfz589j8uTJWLp0KUJDQwEANTU1GDdu\nHDp27IiYmBidbRUKBaZNm4aNGzfC19dXZ71PPvkECQkJ2LdvH+zt7QE8esowZswY9O3bF5s3bwYA\n3L17FyUlJejdu7da+6VLlyIxMRFpaWno3r17k8cdFhaGnJwcpKamwsLCAgAQFxeHZcuW4e9//zu8\nvb2b9qGB4YGIqKl4DyOi1qolhgeDTVs6cOAATE1NMXnyZKHMzMwMAQEBOHPmDG7fvq2zbXR0NNzc\n3ODr64v6+npUVFRoradQKODq6ioEBwCQSCTw8fHBsWPHoFQqAQDt27fXCA4AhGBy9erVJo9bqVQi\nPT0dEydOFIIDAEyYMAHm5uZITU1t9PMhIiIiImppDBYesrKy4ODgoPbFGgDc3d2hUqmQlZWls+3J\nkyfh5uaGtWvXol+/fpDL5fDx8cGePXvU6tXW1sLMzEyjfZs2bVBXV4fc3NxGx3jnzh0AgI2NTZPH\nnZOTgwcPHsDV1VWtnlgshrOzc6PXR0RERETUEpkYquPi4mK89NJLGuVSqRQAdD55KCsrQ2lpKfbt\n2wdjY2MsWrQI1tbWiImJweLFiyGRSIQnBg4ODjh79iwqKythbm4unEOhUDTaB/AoeGzfvh12dnZq\nAUDfcRcXF6uV/77uL7/8orNvIiIiIqKWyGDhobq6GqamphrlDU8KampqtLarrKwEAJSWliI2NhYe\nHh4AHk0x8vX1xaZNm4TwEBgYiKNHjyI8PBzz5s2DRCLBrl27hN2WqqurdY7v888/R15eHiIjIyES\n/faARt9xN5xbLBZrrdtY341pbA7a8ySVWhmkXyKiZ4H3MCJqrVra/ctg4aFh6tDvNXz51jbd6PHy\nbt26CcEBePQlffTo0YiOjkZFRQUsLCwwfPhwLF++HGvWrMGkSZMAAPb29pg/fz5Wr16tMfWoQVRU\nFGJjY7Fw4UIMHTq0WeNu06YNgEdPMLTVbTjeVFwwTUTUNLyHEVFr1RIXTBssPEilUq3Thhqm+3Ts\n2FFrO2tra4jFYtja2mocs7W1hUqlglKpFIJBUFAQ/P39kZOTA1NTUzg7OyM+Ph4A1BZSN0hMTERE\nRASmT5+OmTNnNnvcDdOVGsp/X1fX9RERERERtVQGWzDt5OSEa9euaeyUdO7cOeG4NiKRCM7Ozigq\nKtI4VlhYCGNjY7Rr106t3NzcHDKZDK6urjA2NkZ6ejqkUil69uypVi8tLQ3Lli3DqFGjsGzZsqca\nd58+fWBiYqLxQrra2lpkZWXB2dlZ6/mJiIiIiFoqg4UHPz8/1NXVIS4uTiirra1FYmIi5HK5sCi5\noKAAeXl5Gm1v3bqFEydOCGVKpRKpqamQyWSNTglSKBQ4dOgQQkJC1NYynD59GuHh4fDy8kJERITa\nseaM28rKCt7e3khOTlYLGsnJyaisrISfn58+HxMRERERUYthsGlLHh4e8PPzQ0REBIqLi2FnZ4ek\npCQUFBRgxYoVQr0lS5YgIyMDOTk5QllgYCDi4uIwd+5chIaGom3btkhISEB5eTnCw8OFejdu3MDC\nhQvh4+MDW1tb5ObmYvfu3fDy8hJe8AYAv/76K2bPng0jIyOMHj1a4x0McrlceEmcvuMGgAULFuCN\nN95AcHCw8Ibpbdu2YdiwYRg0aNCz/DiJiIiIiJ47g71hGni0cHj9+vVISUlBWVkZHB0dER4ervbF\nOjg4WCM8AI/WDaxatQo//fQTqqur4eLigvDwcPTv31+oc+/ePXz00Uc4f/48ysrK0KVLF4wfPx5h\nYWFqC7JPnTqFkJAQneNcsWIF/P39mzTuBj///DMiIiJw6dIlWFpaYuzYsQgPD1fbOrYpuGCaiKhp\neA8jotaqJS6YNmh4oKZjeCAiahrew4iotWqJ4cFgax6IiIiIiKh1YXggIiIiIiK9MDwQEREREZFe\nGB6IiIiIiEgvDA9ERERERKQXhgciIiIiItILwwMREREREemF4YGIiIiIiPTC8EBERERERHpheCAi\nIiIiIr0wPBARERERkV4YHoiIiIiISC8MD0REREREpBeGByIiIiIi0gvDAxERERER6YXhgYiIiIiI\n9MLwQEREREREejEx9ACo5cooVGBP3gGU1pTC2swa43v6YUAnuaGHRUSkF97DiKi1asn3L4YH0iqj\nUIFd2Qmoq68DANyrKcWu7AQAaDG/vEREuvAeRkStVUu/fxmpVCqVoQdB+ispUaK+/vn/ky078SXu\n1ZRqlJsYmcChnd1z75+I6GlcK7uBB6oHGuW8hxFRS6fr/mVjZo0vBn/03PsXiYzQoYOl7uPPfQTU\nKmkLDgC0/jITEbU0uu5VvIcRUUun6z6l67vZi8ZpS6SVjZm11l9SGzNrzJfPMsCIiIj0p+vpKe9h\nRNTSNXb/agn45IG0Gt/TD6YiU7UyU5Epxvf0M9CIiIj0x3sYEbVWLf3+xScPpFXDgpyWutKfiKgx\nvIcRUWvV0u9fXDDdyryoBdOPk0qtUFxc/kL7JCJ6VngPI6LWyhD3Ly6YJiIiIiKiZ4LhgYiIiIiI\n9GLQNQ+1tbXYsGEDkpOTcf/+fTg5OWHBggXw9vbWq31KSgq2b9+OK1euQCwWo0+fPvjggw/g7u4u\n1MnLy8OaNWuQkZGBhw8fwt3dHYsXL4arq6vaufbv348jR47gwoULuH79OgYMGIAdO3Zo9BkcHIyM\njAyt4zExMcHFixeFn318fPDrr79q1AsLC8OiRYv0ukYiIiIiopbCoOHhww8/xMGDBxESEgJ7e3sk\nJSUhLCwMO3bsgEwma7TtunXrEBUVhfHjx2Pq1KmorKxEdnY2iouLhTr5+fkIDAyEWCzG22+/DYlE\ngsTERAQHByMuLg69evUS6v7www/IzMyEq6srSkt176M7a9YsBAQEqJVVVVXhk08+weDBgzXqu7i4\nYMaMGWplffr0afTaiIiIiIhaIoOFh/Pnz2Pfvn1YunQpQkNDAQATJ07EuHHjEBERgZiYGJ1tFQoF\ntm7dio0bN8LX11dnvcjISFRWViIuLg729vYAgClTpmDMmDFYu3YtNm/eLNRdtWoVOnbsCGNjY0yY\nMEHnObUFhOTkZADAa6+9pnGsU6dOjZ6PiIiIiKi1MNiahwMHDsDU1BSTJ08WyszMzBAQEIAzZ87g\n9u3bOttGR0fDzc0Nvr6+qK+vR0VFhdZ6CoUCrq6uQnAAAIlEAh8fHxw7dgxKpVIo79y5M4yNjZt1\nLXv37oW5uTlGjBih9XhtbS2qqqqadW4iIiIiopbCYOEhKysLDg4OsLCwUCt3d3eHSqVCVlaWzrYn\nT56Em5sb1q5di379+kEul8PHxwd79uxRq1dbWwszMzON9m3atEFdXR1yc3Of+jru3r2L9PR0jBgx\nAubm5hrHT5w4AU9PT3h6emLkyJHYvXv3U/dJRERERGQIBpu2VFxcjJdeekmjXCqVAoDOJw9lZWUo\nLS3Fvn37YGxsjEWLFsHa2hoxMTFYvHgxJBKJMJXJwcEBZ8+eRWVlpdoXe4VC0WgfTbF//348ePBA\n65SlPn36wMvLCy+//DLu3buH2NhY/OUvf0FZWRlmzpz51H0TEREREb1IBgsP1dXVMDU11ShveFJQ\nU1OjtV1lZSUAoLS0FLGxsfDw8AAA+Pr6wtfXF5s2bRLCQ2BgII4ePYrw8HDMmzcPEokEu3btQmZm\npjCGp7V37160b99e61qILVu2qP3s7++PadOmYfPmzQgMDISVlVWT+2vspR3Pk1Ta9LESEbUUvIcR\nUWvV0u5fBgsPDVOHfq8hNGibbvR4ebdu3YTgAABisRijR49GdHQ0KioqYGFhgeHDh2P58uVYs2YN\nJk2aBACwt7fH/PnzsXr1ao0pU0118+ZNnD17FkFBQTAxefJHaWxsjBkzZmDBggU4e/Yshg0b1uQ+\n792reOFvmO7QwRIlJconVyQiaoF4DyOi1soQ9y+RyAg2Nrq/IxssPEilUq3Thhq2Wu3YsaPWdtbW\n1hCLxbC1tdU4ZmtrC5VKBaVSKQSDoKAg+Pv7IycnB6ampnB2dkZ8fDwAqC2kbo6UlBQA2ndZ0qVT\np04AHk2/ao7G/jGfJ0M98SAiehZ4DyOi1qql3b8MtmDayckJ165d09gp6dy5c8JxbUQiEZydnVFU\nVKRxrLCwEMbGxmjXrp1aubm5OWQyGVxdXWFsbIz09HRIpVL07Nnzqa5h7969sLOzg6enp95tbt68\nCQBo3779U/VNRERERPSiGSw8+Pn5oa6uDnFxcUJZbW0tEhMTIZfLhcXUBQUFyMvL02h769YtnDhx\nQihTKpVITU2FTCZDmzZtdParUChw6NAhhISEQCRq/uVfunQJeXl5GDdunNbjpaWlqK+vVyurqanB\nd999BwsLiyYFDiIiIiKilsBg05Y8PDzg5+eHiIgIFBcXw87ODklJSSgoKMCKFSuEekuWLEFGRgZy\ncnKEssDAQMTFxWHu3LkIDQ1F27ZtkZCQgPLycoSHhwv1bty4gYULF8LHxwe2trbIzc3F7t274eXl\nJbyYrsHp06dx+vRpAEBJSQnKy8uFl8j5+PhoPAl50pSlI0eOYMuWLRg9ejS6du2K0tJSJCUl4fr1\n6/j000+fer0FEREREdGLZrDwADx6q/P69euRnJyMsrIyODo64ttvv0W/fv0abSeRSBAdHY1Vq1Zh\n586dqK6uhouLC7Zt26bW1srKCra2tti5cyfKysrQpUsXhIWFISwsDGKxWO2c//73v/H111+rlW3Y\nsAHAo3UKj4eH+vp67Nu3Dy4uLujRo4fWMfbp0wc9evRAcnIy7t69C7FYDBcXF3z44Yd49dVXm/Q5\nERERERG1BEYqlerFbt1DREREREStksHWPBARERERUevC8EBERERERHpheCAiIiIiIr0wPBARERER\nkV4YHoiIiIiISC8G3aqVWq7bt28jOjoa586dQ2ZmJiorKxEdHY2BAwcaemhERI06f/48kpKScOrU\nKRQUFMDa2hoymQzz58+Hvb29oYdHRKTThQsXsGXLFly6dAklJSWwsrKCk5MT3n33XcjlckMPDwDD\nA+lw7do1REZGwt7eHo6Ojjh79qyhh0REpJeoqCgoFAr4+fnB0dERxcXFiImJwcSJExEfH4+ePXsa\neohERFrdvHkTDx8+xOTJkyGVSlFeXo6UlBQEBQUhMjISgwcPNvQQ+Z4H0k6pVKKurg42NjZIS0vD\nu+++yycPRNQqKBQKuLq6qr0M9Pr163jttdfwpz/9CStXrjTg6IiImqaqqgojR46Eq6srtm7daujh\n8MkDaWdpaWnoIRARNYu2R/svv/wyevfujby8PAOMiIio+SQSCdq3b4/79+8beigAuGCaiIj+C6hU\nKty5cwc2NjaGHgoR0RMplUrcvXsXV69exdq1a3H58mV4e3sbelgA+OSBiIj+C+zZswdFRUVYsGCB\noYdCRPREH330EX788UcAgKmpKd544w3MmjXLwKN6hOGBiIj+0PLy8vDZZ5+hX79+mDBhgqGHQ0T0\nRO+++y6mTp2KwsJCJCcno7a2FnV1dWpruQyF05aIiOgPq7i4GO+88w7atWuHDRs2QCTi//aIqOVz\ndHTE4MGD8frrr+O7777DxYsXsXTpUkMPCwDDAxER/UGVl5cjLCwM5eXliIqKglQqNfSQiIiazNTU\nFCNGjMDBgwdRXV1t6OEwPBAR0R9PTU0NZs2ahevXr2Pr1q3o0aOHoYdERNRs1dXVUKlUqKioMPRQ\nGB6IiOiP5eHDh5g/fz5++eUXbNiwAZ6enoYeEhGRXu7evatRplQq8eOPP6Jz587o0KGDAUaljgum\nSafNmzcDgLAvenJyMs6cOYO2bdsiKCjIkEMjItJp5cqVOHLkCF599VWUlpYiOTlZOGZhYYGRI0ca\ncHRERLrNnz8fZmZmkMlkkEqluHXrFhITE1FYWIi1a9caengA+IZpaoSjo6PW8q5du+LIkSMveDRE\nRPoJDg5GRkaG1mO8fxFRSxYfH4/k5GRcuXIF9+/fh5WVFTw9PfHWW29hwIABhh4eAIYHIiIiIiLS\nE9c8EBERERGRXhgeiIiIiIhILwwPRERERESkF4YHIiIiIiLSC8MDERERERHpheGBiIiIiIj0wvBA\nRERERER6YXggIiJ6guDgYPj4+Bh6GEREBmdi6AEQEdF/p1OnTiEkJETncWNjY1y6dOkFjoiIiJ6E\n4YGIiAxq3LhxGDZsmEa5SMSH40RELQ3DAxERGVTfvn0xYcIEQw+DiIj0wD/rEBFRi5afnw9HR0ds\n3LgRe/fuxWuvvQY3Nze88sor2LhxIx48eKDRJjs7G++++y4GDhwINzc3jB07FpGRkXj48KFG3eLi\nYnzxxRcYMWIEXF1d4e3tjTfffBMnTpzQqFtUVITw8HD0798fHh4e+POf/4xr1649l+smImqJ+OSB\niIgMqqqqCnfv3tUoF4vFsLS0FH4+cuQIbt68ienTp8PW1hZHjhzB119/jYKCAqxYsUKod+HCBQQH\nB8PExESoe/ToUURERCA7Oxtr1qwR6ubn5yMwMBAlJSWYMGECXF1dUVVVhXPnziE9PR2DBw8W6lZW\nViIoKAgeHh5YsGAB8vPzER0djTlz5mDv3r0wNjZ+Tp8QEVHLwfBAREQGtXHjRmzcuFGj/JVXXsHW\nrVuFn7OzsxEfHw8XFxcAQFBQEN577z0kJiZi6tSp8PT0BAD87W9/Q21tLf7xj3/AyclJqDt//nzs\n3bsXAQEB8Pb2BgD89a9/xe3btxEVFYWhQ4eq9V9fX6/287179/DnP/8ZYWFhQln79u2xevVqpKen\na7QnIvojYnggIiKDmjp1Kvz8/DTK27dvr/bzoEGDhOAAAEZGRnj77beRlpaGQ4cOwdPTEyUlJTh7\n9ix8fX2F4NBQd/bs2Thw4AAOHToEb29vlJaW4l//+heGDh2q9Yv/7xdsi0Qijd2h/ud//gcA8J//\n/IfhgYj+KzA8EBGRQdnb22PQoEFPrNezZ0+Nsl69egEAbt68CeDRNKTHyx/Xo0cPiEQioe6NGzeg\nUqnQt29fvcbZsWNHmJmZqZVZW1sDAEpLS/U6BxFRa8cF00RERHpobE2DSqV6gSMhIjIchgciImoV\n8vLyNMquXLkCAOjevTsAoFu3bmrlj7t69Srq6+uFunZ2djAyMkJWVtbzGjIR0R8OwwMREbUK6enp\nuHjxovCzSqVCVFQUAGDkyJEAgA4dOkAmk+Ho0aO4fPmyWt1vv/0WAODr6wvg0ZSjYcOG4dixY0hP\nT9foj08TiIg0cc0DEREZ1KVLl5CcnKz1WEMoAAAnJyfMmDED06dPh1QqxeHDh5Geno4JEyZAJpMJ\n9T7++GMEBwdj+vTpmDZtGqRSKY4ePYrjx49j3Lhxwk5LALB8+XJcunQJYWFhmDhxIlxcXFBTU4Nz\n586ha9euWLx48fO7cCKiVojhgYiIDGrv3r3Yu3ev1mMHDx4U1hr4+PjAwcEBW7duxbVr19ChQwfM\nmTMHc+bMUWvj5uaGf/zjH/jqq6/www8/oLKyEt27d8eiRYvw1ltvqdXt3r07EhISsGnTJhw7dgzJ\nyclo27YtnJycMHXq1OdzwURErZiRis9liYioBcvPz8eIESPw3nvvYe7cuYYeDhHRfzWueSAiIiIi\nIr0wPBARERERkV4YHoiIiIiISC9c80BERERERHrhkwciIiIiItILwwMREREREemF4YGIiIiIiPTC\n8EBERERERHpheCAiIiIiIr0wPBARERERkV7+H9CqpmSIlzBmAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zdKwFWsQsZ-5",
        "colab_type": "text"
      },
      "source": [
        "# Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3hvIeuts3ysN",
        "colab_type": "code",
        "outputId": "bb50193e-7e08-4139-a7aa-f9c905313796",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print('Predicting labels for {:,} test sentences...'.format(len(test_dl) * batch_size))\n",
        "\n",
        "model.eval()\n",
        "\n",
        "total_accuracy_test = 0\n",
        "\n",
        "for batch in test_dl:\n",
        "        \n",
        "    # unpack current batch's input and labels\n",
        "    cur_input_ids = batch[0].to(device)\n",
        "    cur_input_mask = batch[1].to(device)\n",
        "    cur_labels = batch[2].to(device)\n",
        "\n",
        "    # no need to calculate and trace gradient\n",
        "    with torch.no_grad():\n",
        "        loss, logits = model(cur_input_ids,\n",
        "                            token_type_ids=None,\n",
        "                            attention_mask=cur_input_mask,\n",
        "                            labels=cur_labels)\n",
        "                    \n",
        "    # no need to calculate prediction & labels in gpu\n",
        "    # good practice when involves with large-scale dataset\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    label_ids = cur_labels.to('cpu')\n",
        "        \n",
        "    # calculate this batch's accuracy & loss and accumulate with other \n",
        "    # batches' accuracies & loss\n",
        "    total_accuracy_test += get_accuracy_hamming_loss(logits, label_ids)\n",
        "        \n",
        "\n",
        "print('Testing Accuracy: {:.2f}'.format(total_accuracy_test/len(test_dl)))\n",
        "print('Testing Completed')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicting labels for 1,472 test sentences...\n",
            "Testing Accuracy: 0.87\n",
            "Testing Completed\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}